<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[多线程爬虫]]></title>
    <url>%2F2019%2F01%2F08%2F%E5%A4%9A%E7%BA%BF%E7%A8%8B%E7%88%AC%E8%99%AB%2F</url>
    <content type="text"><![CDATA[前言​ 目前我们所学的爬虫都是单线程爬虫，比如在爬取一个url_list时，先爬取完list中的第一个后才开始第二个url的爬取。 ​ 那多线程是什么呢？在爬取一个url_list时，在爬取第一个url的同时爬取第二个url，第三个……同时爬几个取决于有几个线程。所以，多线程爬虫在爬取速度上有很大提升。 ​ 在这里还要简单介绍下线程和进程的关系： 打开一个应用程序就像是打开了一个进程，一个进程中至少会有一个或多个线程。比如播放视频，可能就包含两个线程，一个线程播放视频，一个线程播放声音。也就是说，一个进程是由若干线程组成的。 实现多线程爬虫​ 那既然多线程爬虫在效率上有很大提升，有必要学习一下！！！直接上代码： 123456789101112131415161718192021222324252627from multiprocessing.dummy import Poolimport requestsimport timeurl_list = []for i in range(50): url_list.append('https://www.baidu.com')def getsource(url): html = requests.get(url) return html.status_codetime1 = time.time()for i in url_list: print(i) getsource(i)time2 = time.time()print(f'单线程耗时：&#123;"%.2f" % (time2-time1)&#125;秒')pool = Pool(4) # 生成4个线程time3 = time.time()results = pool.map(getsource, url_list) # 开始多线程# print(results)pool.close() # 关闭多线程pool.join()time4 = time.time()print(f'并行耗时：&#123;"%.2f" % (time4-time3)&#125;秒') 这短短的二三十行代码就能体现多线程爬虫的性能。 首先从processing.dummy中引入Pool线程池。 然后定义了一个列表url_list存放待爬取的url，这里直接使用了往里面添加了50个百度首页 这里就以请求百度首页为例 然后定义一个函数请求url获得源码 先使用单线程爬取百度首页50次，计算时间 在使用多线程爬取百度首页50次，结果如下： 图中很清晰的表达了多线程爬虫在速度上的优势！ 这里要说一下这个pool.map函数，它有两个参数：第一个参数为请求函数，就是请求网页的函数，第二个参数是url列表，必须要是可迭代的类型。 我猜想在map函数内部应该会迭代第二个参数，然后放到第一个参数(定义的请求函数)中使用。 要注意第一个参数仅仅是函数的名字，不要带括号，带括号变成调用这个函数了。 然后这个pool.map会的返回值是一个列表，列表中的每一项是请求函数的返回值。]]></content>
      <categories>
        <category>爬虫</category>
      </categories>
      <tags>
        <tag>爬虫</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JD手机爬虫+评论分析+Flask]]></title>
    <url>%2F2019%2F01%2F06%2FJD%E6%89%8B%E6%9C%BA%E7%88%AC%E8%99%AB-%E8%AF%84%E8%AE%BA%E5%88%86%E6%9E%90-Flask%2F</url>
    <content type="text"><![CDATA[前言​ 暂时没想好咋写！等项目进一步完善再说！]]></content>
      <categories>
        <category>爬虫</category>
      </categories>
      <tags>
        <tag>爬虫</tag>
        <tag>Flask</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[2018年度总结]]></title>
    <url>%2F2019%2F01%2F03%2F2018%E5%B9%B4%E5%BA%A6%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[​ 本来这篇日志在元旦前就应该写好了，但是我太懒了。假期绝不会去想学习的事情。。。 ​ 2018年对我来说应该是挺重要的一年，在这之前，我从没考虑过未来，没有规划过未来。上半年，在学校里浑浑噩噩的过去了。在暑假时，由于下半年要出去实习了，我不得不认真考虑下未来要干什么，我仔细思考了一下自己会什么，然后发现我原来是个什么都不会的废物。为了以后能有一技之长，我选择了来培训，思索再三，终于决定在8.16号再次回到了郑州，报了培训班。一个人来到陌生的环境，孤独是一种常态，因为我本来就是比较内向的性格。很长一段时间都是这样。后来才慢慢慢慢慢的认识了几个同学。我决定要好好学习编程，认真尝试一次去做好一件事。我发现我认真起来也能做好一件事情，学习过程中遇到的问题都能一一解决，这无疑给了我很大的鼓励。就这样过了半年，这半年里，我有了个人博客，我自己完成了第一个web项目，虽然很low。 ​ 2019年，我要继续努力学习编程。 新年flag： 自律自律自律！！！ 掌握scrapy（拖了好久，一直不能静下心来研究它。。。） 继续学习英语 学会Linux 找到工作（最重要的）]]></content>
      <categories>
        <category>私密博客</category>
      </categories>
      <tags>
        <tag>日志</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python Yield解析]]></title>
    <url>%2F2019%2F01%2F02%2Fpython-Yield%E8%A7%A3%E6%9E%90%2F</url>
    <content type="text"><![CDATA[可迭代对象mylist是一个可迭代的对象。当使用一个列表生成式来简历一个列表的时候，就建立了一个可迭代对象： 123456mylist = [x*x for x in range(3)]for i in mylist: print(i)014 在这里所有的值都存在内存当中，所以并不适合大量数据。在python中，list,tuple,dict和set都是可迭代的对象，字符串也是可迭代对象。 生成器特点： 可迭代 只能读取一次 实时生成数据，不全存在内存中 123456mygenerator = (x*x for x in range(3))for i in mygenerator: ptint(i)014 这个生成器只能使用一次for循环来遍历，之后就不能使用了 yield关键字 yield是一个类似return的关键字，只是这个函数返回的是个生成器 当你调用这个函数的时候，函数内部的代码并不立马执行，这个函数只是返回一个生成器对象 当你使用for进行迭代的时候，函数中的代码才会执行 123456789def createGenerator(): mylist = range(3) for i in mylist: yield i*imygenerator = createGenerator() # 创建一个生成器print(mygenerator)# 打印出来显示mygenerator是一个对象for i in mygenerator： # 使用for调用生成器对象 print(i) 第一次迭代中createGenerator函数才会执行，从开始到达yield关键字，然后返回yield后的值作为第一次迭代返回的值，然后，每次执行这个函数都会继续执行你在函数内部定义的那个循环的下一次，再返回那个值，直到没有值可以返回的。 控制生成器的穷尽1234567891011121314class Bank(): crisis = False def create_atm(self): while not self.crisis: yield "$100"hsbc = Bank()corner_street_atm = hsbc.create_atm()print(corner_street_atm.__next__())# print([corner_street_atm.__next__() for i in range(5)])hsbc.crisis = True # 当crisis为True，停止迭代print(corner_street_atm.__next__())]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux学习2-vi编辑器]]></title>
    <url>%2F2018%2F12%2F27%2FLinux%E5%AD%A6%E4%B9%A02-vi%E7%BC%96%E8%BE%91%E5%99%A8%2F</url>
    <content type="text"><![CDATA[vi的工作方式vi有三种工作方式：命令模式、文本输入模式和最后行模式。不同的工作模式下操作方式有所不同，但三种模式之间可以相互转换。 命令模式命令模式是启动vi后进入的工作模式，并可转化为文本输入模式和最后行模式。在命令模式下，从键盘上输入的任何字符都被当做编辑命令来解释，而不会在屏幕上显示。如果输入的字符是合法的vi命令，则vi完成相应的动作，否则vi会抛出警告。在命令模式时，屏幕底行不显示信息 文本输入模式文本输入模式用于字符编辑。在命令模式下输入i（插入命令）、a（附加命令）、o（打开命令）或s（替换命令）等命令后进入文本输入模式。此时，输入的任何字符都被vi当成文件内容，并将其显示在屏幕上。在文本输入模式想返回到命令模式，按Esc键就可以。 最后行模式在命令模式下，用户按“ : ”键就可以进入最后行模式，此时vi会在屏幕的底部显示一个“ ： ”最为最后行模式的提示符，等待用户输入命令。命令执行完毕后，vi自动回到命令模式。另外，用户在最后行模式下按Del键或者按“←”键删除输入的命令也可以回到命令模式。多数文件管理命令都是在最后行模式下执行的。 vi的启动和退出启动vi文本编辑器的命令格式是： vi [目录名][目录] 如果不指定文件，则新建议文本文件，退出时必须指定文件名。(wq /root/test.txt)如果启动vi时指定文件，但工作目录中没有该文件名，则新建指定文件，反之是打开指定的文件。输入vi file1命令，打开file1文件，此时vi处于命令模式，正在等待用户输入命令。此时输入的字母都将作为命令来解释。 光标停在屏幕上第一行的其实位置。如果行首有“~”符号，则表示此行为空行。 在命令模式下连续按两次Z键，将保存编辑的内容并退出vi。与文件处理相关的命令，大多在最后行模式下才能执行。 文本输入要输入文本，必须首先将工作模式转换为文本编辑模式，在命令模式下键入i,I,a,A,o,O等命令中的任意一个即可。此时在状态、命令去出现INSERT。各命令的作用如下所示： 命令 作用 i 从当前的光标位置开始输入字符 I 光标移动到当前行的行首，开始输入字符 a 从当前光标的下一个位置，开始输入字符 A 光标移动到当前行的行尾，开始输入字符 o 在光标所在行之下新增一行 O 在光标所在上之上新增一行 r 替换当前字符 R 替换当前字符及其后的字符，直至按下Esc键 s 从当前光标位置处开始，以输入的文本替代指定数目的字符 S 删除指定数目的行，并以所输入文本替代之 ncw或nCW 修改指定数目的字 n1,n2 co n3 将n1行到n2行之间的内容拷贝到第n3行下 n1,n2 m n3 将n1行到n2行之间的内容移至第n3行下 n1,n2 d 将n1行到n2行之间的内容删除 在文本编辑模式下可输入文本内容，可以插入任意多行，但在每行的结尾处都要按Enter键，并且可以使用上下左右方向键移动光标，当光标移动到文件的边界上而无法移动时，计算机会发出嘟嘟声来提醒用户，按Del键和BackSpace键可删除字符，按Esc键回到命令模式。 打开文件文件的打开与读取操作，常用命令如下表所示： 命令 作用 :vi filename 打开或新建文件名为filename的文件到vi编辑器中，并将光标置于第一行首 :vi +n filename 打开文件，并将光标置于第n行首 :vi +filename 打开文件，并将光标置于最后一行首 :vi + /pattern filename 打开文件，并将光标置于第一个与pattern匹配的地方 :vi filename···filename 打开多个文件，依次进行编辑 :w 将工作缓冲区的变化写入默认文件中 :w filename 将工作缓存区的变化写入名为filename的文件中 :e filename 打开文件filename进行编辑 :r filename 读取文件内容到当前vi编辑器中 保存文件文件保存与另存为操作，常用命令如下所示 :w 保存但不退出 :w [newfile] 保存为指定的文件 :ZZ 保存退出 :e 不保存当前修改，回到初始版本文件 :q 退出不保存 :v 另存为文件 将vi编辑器中的内容另存为指定文件名 q! 不保存文件，直接退出vi wq 存盘并退出vi 移动光标要将文件内容进行修改，首先必须把光标移动到指定位置。移动光标的最简单的方式是按键盘的上下左右箭头键。除了这种最原始的方法之外，用户还可以在命令模式下利用vi提供的众多字符组合键在正文中移动光标，迅速到达指定的行或列，实现定位。 光标移动和翻页操作，如下所示： 光标移动： h 向左移动光标 j 向下移动光标 k 向上移动光标 l 向右移动光标 翻页 Ctrl + f 向前翻整页，相当于pagedown ctrl + b 向后翻整页，相当于pageup ctrl + u 向前翻半页 ctrl + d 向后翻半页 文件内快速跳转： 行内快速跳转 ^ 将光标快速跳转到本行的行首字符 $ 将光标快速跳转到本行的最后一个字符 w 将光标快速跳转到当前光标所在位置的后一个单词的首字母 b 将光标快速跳转到当前光标所在位置的前一个单词的首字母 e 将光标快速跳转到当前光标所在位置的后一个单词的尾字母 文本修改删除操作键 x 删除光标处的单个字符 dd 删除光标所在行 dw 删除当前字符到单词尾(包括空格)的所有字符 de 删除当前字符到单词尾(不包括单词尾部的空格)的所有字符 d$ 删除当前字符到行尾的所有字符 d^ 删除当前字符到行首的所有字符 J 删除光标所在行行尾的换行符，相当于合并当前行和下一行的内容 在编辑文档的过程中，为消除某个错误的操作，可以用撤销命令。另外，用户可以在新的光标位置重复前面执行过得编辑命令。与撤销操作相关的命令如下： u 取消最近一次的操作，并恢复操作结果，可以多次使用u命令恢复已进行的多步操作 U 取消对当前行进行的所有操作 Ctrl + r 对使用u命令撤销的操作进行恢复 从正文中删除的内容并没有真正的丢失，而是被剪切并复制到一个内存缓存区中，用户可以将其粘贴到正文中的指定位置，与之相关的命令如下： yy 复制当前行整行的内容到vi缓存区 yw 复制当前光标的单词尾字符的内容到vi缓存区 y$ 复制当前光标到行尾的内容到vi缓冲区 y^ 复制当前光标到行首的内容到vi缓存区 p 读取vi缓冲区中的内容，并粘贴到光标当前的位置（不覆盖文件已有的内容），小写字母p是将缓冲区的内容粘贴到当前字符的右侧，而大写字母P则是将缓冲区中的内容粘贴到当前字符的左侧]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>vi</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux学习1-配置python和基本命令]]></title>
    <url>%2F2018%2F12%2F26%2FLinux%E5%AD%A6%E4%B9%A01-%E9%85%8D%E7%BD%AEpython%E5%92%8C%E5%9F%BA%E6%9C%AC%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[Linux学习linux下搭建python开发环境安装python3.7 1.安装编译相关工具 123yum -y groupinstall &quot;Development tools&quot;yum -y install zlib-devel bzip2-devel openssl-devel ncurses-devel sqlite-devel readline-devel tk-devel gdbm-devel db4-devel libpcap-devel xz-develyum install libffi-devel -y 2.下载安装包解压 123cd #回到用户目录wget https://www.python.org/ftp/python/3.7.0/Python-3.7.0.tar.xztar -xvJf Python-3.7.0.tar.xz 3.编译安装 1234mkdir /usr/local/python3 #创建编译安装目录cd Python-3.7.0./configure --prefix=/usr/local/python3make &amp;&amp; make install 4.创建软连接 12ln -s /usr/local/python3/bin/python3 /usr/local/bin/python3ln -s /usr/local/python3/bin/pip3 /usr/local/bin/pip3 安装pycharm 1.下载pycharm软件包 网页下载：http://www.jetbrains.com/pycharm/download/#section=linux wget直接下载：curl https://download.jetbrains.8686c.com/python/pycharm-professional-2018.1.4.tar.gz 2.解压软件包 tar -xf pycharm-professional-2018.1.4.tar.gz 3.进入解压后的bin目录执行安装命令 ./pycharm.sh 4.给pycharm.sh加入应用工程序列表，并创建快捷方式 vim /usr/share/applications/pycharm.desktop #!/usr/bin/env xdg-open[Desktop Entry]Encoding=UTF-8Name=PycharmComment=pycharm-2018.1.1Exec=/mytest/pycharm-2018.1.4/bin/pycharm.shIcon=/mytest/pycharm-2018.1.4/bin/pycharm.pngTerminal=falseStartupNotify=trueType=Application Categories=Application; chmod a+x /usr/share/applications/pycharm.desktop 转载自CSDN 常用Linux命令 系统的登录退出超级用户：root 进入图形界面：init5 进入字符界面：init3 获得帮助命令： help：help提供内部命令的帮助 格式：命令 –help man：man和info提供外部命令的帮助 格式：man &lt;命令&gt; info：info命令获取系统中info文档的帮助信息， 格式： info [OPTION] whatis：对命令的基本描述 格式：whatis &lt;命令&gt; pwd 命令 格式： pwd [选项] 功能：列出当前工作目录所处的完整路径 more、less命令 格式： more/less &lt;文件1&gt;&lt;文件2&gt;…&lt;文件n&gt; 功能：显示文件内容，如果一个文本文件太长了，超过一个屏幕的画面，用cat来显示实在是不理想，这样就需要选择more和less两个命令。more命令可以是超过一页的文件临时停留在屏幕，等待用户按任何一个键后，才继续显示，即分页显示文件内容。而les除了有more的功能以外，还可以用方向键往上或往下滚动文件，所以用户浏览、阅读文章时，less是个非常好的选择。而more命令只能向后翻页查看文件。 clear命令 用来清屏，不需要任何参数，就可以清楚屏幕上的信息。 wc命令： 格式：wc[选项]&lt;文件1&gt;&lt;文件2&gt;…&lt;文件n&gt; 功能：对文件中的字、行、字符进行计数。该命令选项的参数有： -w 对字数进行统计 -l 对行数进行统计 -c 对字符数进行统计 -m 仅显示字符数 – help 显示帮助信息。 – version 显示版本信息 who、last和su命令 who命令： 格式：who [选项] 功能：列出当前正在使用系统的所有用户清单，包括用户名、登录时间以及某个用户的终端号的用户信息。各选项的含义如下： -a, – all 同时选中-b -d -login -p -r -t -T -u。 -b, – boot 显示系统前一次的启动时间。 -d, –dead 显示已经终止的程序 -H 显示每个烂尾的标题行 -l, – login 显示系统登录程序 -m 只显示和当前用户相关的登录信息。 -p 显示由init激活的程序 -q 仅显示登录系统的账号名和总的用户数 -r 显示当前执行的等级 -s 简洁模式；仅显示名字、行和时间 -t 现实上次系统是中的改变。 -T,-w,-mesg 显示用户的状态信息，状态标识有“+”、“-”或“？” -u 列出登录的用户 – message， –writable 同-T选徐昂 – help 显示帮助信息 –version 显示版本信息 last命令： 格式：last [选项] 功能：查看最近系统使用者登录的相关信息。各选项的含义如下： -a 在最后一栏显示主机名。 -d 对于非本地登录，linux系统不仅保存了远程主机的主机名，还保存了远程主机的IP地址，通过该选项将IP地址转换成主机名。 -f &lt;记录文件&gt; 指定记录的文件，而不是默认的目录 -i 与选项-d像是，但是现实远程主机的IP地址，不是主机名。 -n &lt;现实列数&gt; 设定last命令现实的行数 - 同一n 设定显式地行数为num。 -o 读取一个就类型的wtmp文件 -R 不显示登录系统的主机名或IP地址 -t YYYYMMDDHHMMSS 根据指定的时间显示登录状态 -x 显示关机、重启和执行等级等更改信息 eg：查询最后登录的5位用户的信息。 last -5 su命令： 格式：su [选项] 功能：变更为其它使用者的身份（超级用户除外），但需要键入该使用者的密码。主要参数的含义如下： -f 不必读启动文件，仅用于csh或tcsh两种Shell。 -l， –login 加了这个参数之后，就好像是重新登录为该使用者一样，大部分环境变量都是以该使用者为主，并且工作目录也会改变。如果没有指定USER，默认情况是root -m，-p 执行su时不改变环境变量。 -c 变更账号为USER的使用者，并执行命令后再变回原使用者 head与tail命令 head命令： 格式：head [选项] 功能：从文件头开始，输出指定行数的内容到标准输出。 eg：以默认方式显示文件file1的内容（默认前十行） ​ head file1 显示文件file1的前五行内容 ​ head -5 file1 tail命令： 格式 tail [选项] 功能： 从文件末尾开始，输出文件后面指定部分的内容到标准输出 history命令 格式： history [选项] 功能：显示之前是用过的命令 eg：显示最近5次所输入的命令 history 5 bc与scale命令 格式： bc scale=n 功能：bc计算机指令；scale设置精度命令，scale=n（当输入这条命令时，除法运算可以保留n位小数） date命令 格式：date[选项] 功能：显示和设定系统的日期和时间 eg：显示当前日期。 date 如要显示当前日期，并且以MM/DD/YY的形式显示， date + %D 如要显示时间的秒数： date + %S clock或hwclock命令 格式：hwclock [选项] clock[选项] 功能：查看或者设置硬件时间，设置硬件实践和系统时间的同步 查看硬件时间：hwclock –show 设置硬件时间：hwclock –set –date=”07/07/18/ 10:19”(月/日/年 时:分:秒) 设置时间同步：clock –systohc]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[BeautifulSoup4的简单学习]]></title>
    <url>%2F2018%2F12%2F20%2FBeautifulSoup4%E7%9A%84%E7%AE%80%E5%8D%95%E5%AD%A6%E4%B9%A0%2F</url>
    <content type="text"><![CDATA[介绍BeautifulSoup4（BS4）是Python的一个第三方库，用来从HTML和XML中提取数据。BeautifuSoup4在某些方面比Xpath移动，但是不如Xpath简介，而且由于它是使用Python开发的，因此速度比XPathman。 使用12345678910111213141516from bs4 import BeautifulSoupimport requestshtml = requests.get('http://exercise.kingname.info/exercise_bs_1.html').content.decode()soup = BeautifulSoup(html, 'lxml') # 第一个参数为要解析的内容，第二个为解析器，可以选择lxml，也可以选择html.parser，但是要注意，第二个参数是解析器名称的字符串。info = soup.find(class_='useful')info1 = info.find_all('li')for content in info1: print(content.string) print(content['class']) # 如果需要获取某个属性值，可以将返回的bs4对象看做是一个字典 # ，把属性名当做key，来获取属性值。# 注意，如果需要使用先抓大后抓小的策略，要先使用find方法，因为find_all方法返回的是一个列表# ，不能再次使用bs4解析。 上面的find()和find_all()的不同点： find_all返回的是BeautifulSoup Tag对象组成的列表，如果没有找到任何满足要求的标签，就会返回空列表 find返回的是一个BeautifulSoup Tag桂香，如果有多个符合条件的HTML标签，则返回第一个对象，如果找不到就返回Noe find_all()和find()的参数完全相同，以find_all为例来说： 1find_all(name, attrs, recursive, text, **kwargs) name就是HTML的标签名，类似以body、div、ul、li attrs参数的值是一个字典，字典的Key是属性名，字典的Value是属性值，例如attrs={&#39;class&#39;: &#39;useful&#39;}，使用这种写法，class就不需要加下划线。 recursive的值为Ture或者False，当他为Fasle的时候，BS4不会搜索子标签。 text可以是一个字符串或者正则表达式，用于搜索标签里面的文本信息。example： 123info1 = soup.find_all(text=re.compile('我需要'))for content in info1: print(content.string) BS4可以直接使用标签的属性名来获取标签内容，如果标签属性足够特殊，可以省略标签名 所以上面的info = soup.find(class_=’useful’)的全写是： 1info = soup.find(div ,class_=)'useful' 因为这里的属性class和python的类class可能会有冲突，所以BS4规定class写成class_。]]></content>
      <categories>
        <category>爬虫</category>
      </categories>
      <tags>
        <tag>爬虫</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Django学习4-表单处理]]></title>
    <url>%2F2018%2F12%2F18%2FDjango%E5%AD%A6%E4%B9%A04-%E8%A1%A8%E5%8D%95%E5%A4%84%E7%90%86%2F</url>
    <content type="text"><![CDATA[介绍本文从Django3结尾的地方讲起，我们将继续编写投票应用，专注于简单的表单处理并且精简我们的代码。 表单处理编写一个简单的表单让我们更新一下在上一个教程中编写的投票详细页面的模板(polls/detail.html),让它包含一个HTML（from）元素： 123456789101112&lt;h1&gt;&#123;&#123; question.question_text &#125;&#125;&lt;/h1&gt;&#123;% if error_message %&#125;&lt;p&gt;&lt;strong&gt;&#123;&#123; error_message &#125;&#125;&lt;/strong&gt;&lt;/p&gt;&#123;% endif %&#125;&lt;form action="&#123;% url 'polls:vote' question.id %&#125;" method="post"&gt;&#123;% csrf_token %&#125;&#123;% for choice in question.choice_set.all %&#125; &lt;input type="radio" name="choice" id="choice&#123;&#123; forloop.counter &#125;&#125;" value="&#123;&#123; choice.id &#125;&#125;"&gt; &lt;label for="choice&#123;&#123; forloop.counter &#125;&#125;"&gt;&#123;&#123; choice.choice_text &#125;&#125;&lt;/label&gt;&lt;br&gt;&#123;% endfor %&#125;&lt;input type="submit" value="Vote"&gt;&lt;/form&gt; 说明： 上面的模板在Question的每个Choice前添加一个单选按钮。每个单选按钮的value属性是对应的各个Choice的ID。每个单选按钮的name是choice。这意味着，当有人选择一个按钮并提交表单请求时，它将发送一个POST数据choice=#，其中#为选择的choice的ID。这是HTML表单的基本概念。 我们设置表单的action为（% url ‘polls:vote’ question.id %）并设置method为POST。使用method=”POST”是非常重要的，因为这个提交表单的行为会改变服务器端的数据。无论何时，当你需要创建一个改变服务器端数据的表单时，请使用method=&quot;POST&quot;。这不是Django的特定技巧；这是优秀的网站开发技巧。 forloop.counter指示for标签已经循环多少次。 由于我们创建一个POST表单（它具有修改数据的作用），所以我们需要小心跨站点请求伪造。你不必太过担心，因为Django已经拥有一个用来防御csrf的非常容易使用的系统。简而言之，所有针对内部URL的POST表单都应该使用(% csrf_token %)模板标签。 现在，让我们来创建一个Django视图来处理提交的数据。在前一节中，我们为投票应用创建了一个URLconf： 12polls/urls.pypath('&lt;int:question_id&gt;/vote/', views.vote, name='vote') 我们还创建了一个vote()的视图函数。现在让我们来改进这个视图函数： 1234567891011polls/viewsdef vote(request, question_id): question = get_object_or_404(Question, pk=question_id) try: selected_choice = question.choice_set.get(pk=request.POST['choice']) except(KeyError, Choice.DoesNotExist): return render(request, 'polls/detail.html', &#123;'question': question, 'error_message': "没有这个选项"&#125;) else: selected_choice.votes += 1 selected_choice.save() return HttpResponseRedirect(reverse('polls:results', args=(question.id,))) 以上代码有些内容还未在本教程中提到过： request.POST是一个类字典独享，让你通过关键字的名字获取提交的数据。像是flask中的request.form。这个例子中，request.POST[‘Choice’]以字符串形式返回选择的Chouce的ID。request.POST的值永远是字符串。注意，Django还以同样的方式提供requtst.GET用于访问GET数据–但我们在代码中显示地使用request.POST，以保证数据只能通过POST调用改动。 如果再request.POST[‘Choice’]数据中没有提供choice，POST将引发一个KeyError。上面的代码检查KetError，如果没有给出choice将重新显示Question表单和一个错误信息。 在增加Choice的得票数之后，代码返回一个HttpResponseRedirect而不是常用的HttpResponse，HttpResponseRedirect只接受一个参数：用户将要被重定向的URL。正如上面的Python注释所指出的，在成功处理POST数据之后，应该始终返回HttpResponseRedirect。这个技巧并不是Django特有的;这只是很好的Web开发实践。类似flask中的redirect重定向。 在这个例子中，我们在HttpResponseRedirect的构造函数中使用reverse()函数。这个函数避免了我们在视图函数中硬编码URL。他需要我们给出想要跳转的视图的名字和该视图所对应的UTL模式中需要给该视图提供的参数。在上面这个例子中，reverse()调用将返回一个这样的字符串： 1&apos;polls/3/results/&apos; 其中3是qeustion.id的值。重定向的URL将调用‘results’视图来显示最终的页面。 HttpRequest是一个HttpRequest对象。 当有人对问题进行投票后，vote()视图将重新重定向到问题的结果界面。让我们来编写这个视图并创建一个前端页面results.html： 1234567891011121314polls/views.pydef results(request, question_id): question = get_object_or_404(Question, pk=question_id) return render(request, 'polls/results.html', &#123;'question': question&#125;)polls/templates/polls/results.html&lt;h1&gt;&#123;&#123; question.question_text &#125;&#125;&lt;/h1&gt;&lt;ul&gt; &#123;% for choice in question.choice_set.all %&#125; &lt;li&gt;&#123;&#123; choice.choice_text &#125;&#125;——&#123;&#123; choice.votes &#125;&#125;票数&#123;&#123; choice.votes|pluralize &#125;&#125;&lt;/li&gt; &#123;% endfor %&#125;&lt;/ul&gt;&lt;a href="&#123;% url 'polls:detail' question.id %&#125;"&gt;再次投票&lt;/a&gt; 现在，在你的浏览器中访问/polls/1/然后为Question投票。你应该看到一个投票结果页面，并且在你每次投票之后都会更新。如果你图教师没有选择任何Choice，你应该看到错误信息。 使用通用视图：代码还是少点好detail()和results()视图都很简单——并且，想上面提到的那样，存在冗余问题。用来显示一个投票列表的index()视图和他们类似。 这些视图反应基本的Web开发中的一个常见情况：根据URL中的参数从数据库中获取数据、载入模板文件然后返回渲染后的模板。由于这种情况特别常见，Django提供一种快捷方式，叫做“通用视图”系统。 通用视图将常见的模式抽象画，可以是你在编写应用是甚至不需要编写Python代码。让我们将我们的投票应用转换成使用通用视图系统，这样我们可以删除许多我们的代码。我们仅仅需要做一下几步来完成转换： 转换URLconf。 删除一些旧的、不在需要的视图 基于Django的通用视图引入新的视图。 为什么要重构代码？一般来说，当编写一个Django应用是，你应该先评估一下通用视图是否可以解决你的问题，你应该在一开始使用它，而不是进行到一般是重构代码。本教程目前为止是有意将重点放在“以艰难的方式”编写视图，这是为将重点放在核心概念上。 改良URLconf首先，打开polls/urls.py这个URLconf并将它修改成： 1234567891011polls/urls.pyfrom django.urls import pathfrom . import viewsapp_name = 'polls'urlpatterns = [ path('', views.IndexView.as_view(), name='index'), path('&lt;int:pk&gt;/', views.DetailView.as_view(), name='detail'), path('&lt;int:pk&gt;/results/', views.ResultsView.as_view(), name='results'), path('&lt;int:question_id&gt;/vote/', views.vote, name='vote'),] 注意，第二个和第三个匹配准则中，路径字符创中酦醅模式的名称已经由&lt;question_id&gt;改为 改良视图下一步，我们将删除旧的index,detail和results视图，并用Django的通用视图代替。打开polls/views.py文件： 123456789101112131415161718192021222324252627282930polls/views.pyclass IndexView(generic.ListView): template_name = 'polls/index.html' context_object_name = 'latest_question_list' def get_queryset(self): """返回最近的五个问题列表latest_question_list""" return Question.objects.order_by('-pub_date')[:5]class DetailView(generic.DetailView): model = Question template_name = 'polls/detail.html'class ResultsView(generic.DetailView): model = Question template_name = 'polls/results.html'def vote(request, question_id): question = get_object_or_404(Question, pk=question_id) try: selected_choice = question.choice_set.get(pk=request.POST['choice']) except(KeyError, Choice.DoesNotExist): return render(request, 'polls/detail.html', &#123;'question': question, 'error_message': "没有这个选项"&#125;) else: selected_choice.votes += 1 selected_choice.save() return HttpResponseRedirect(reverse('polls:results', args=(question.id,))) 我们在这里使用两个通用视图:ListView和DetailView。这两个视图分别抽象“显示一个对象列表”和“显示一个特定类型对象的详细信息页面”这两种概念。 每个通用视图需要知道它将作用与哪个模型。这由model属性提供。 DetailView期望从URL中捕获名为“PK”的主键值，所以我们为通用视图从Question_id改成PK 默认情况下，通用视图DetailView使用一个叫做&lt;app name&gt;/&lt;model name&gt;_detail.html的模板。在我们的例子中，他将使用”polls/question_detail.html”模板。template_name属性使用来告诉Django使用一个指定的模板名字，而不是自动生成的默认名字。我们也为results列表视图制定了template_name——这确保results视图和detail视图在渲染师具有不同的外观，即使它们在后台都是同一个DetailView 类似地，ListView 使用一个叫做 &lt;app name&gt;/&lt;model name&gt;_list.html 的默认模板；我们使用 template_name 来告诉 ListView使用我们创建的已经存在的 &quot;polls/index.html&quot; 模板。 在之前的教程中，提供模板文件时都带有一个包含question和latest_question_list变脸的context。对于DetailView，question变量会自动提供——因为我们使用Django的模型（Question），Django能够为context比那两决定一个合适的名字。然而对于ListView，自动生成的context变量时question_list。为了覆盖这个行为，我们提供context_object_name属性，表示我们想使用latest_question_list。作为一种替换方案，你可以改变你的模板来匹配新的context变量——这是一种更便捷的方法，告诉django使用你想使用的变量名。 小结本节主要学习的是Django的表单处理，因为在处理投票信息时要使用表单向路由传递信息，修改数据库字段，为votes加上1 因为表单会改变数据库字段，所以我们在表单中要使用(% csrf_token %)字段方式跨站点请求伪造。 在表单中，input name=的作用是为input标签起一个名字，让后台可以通过这个name值来获取传递的信息 input value=的作用是定义向后端传递的值。 在后端中定义了vote()视图函数来处理投票计数， 视图首先使用get_object_or_404()来获取一个Question对象, 然后使用request.POST[‘choice’]来获取用户提交的数据，然后通过Question对象查询到这个选项， 这里使用了try except来捕获异常，如果没有获取到Choice选项，则会返回一个错误信息给前端detail页面 如果没有异常就对Choice的votes字段+1，然后调动.save()方法保存到数据库中。 然后重定向到问题的results页面，并且携带一个参数args=（question.id，）让结果页面根据question.id显示Question的票数情况。 通用视图 要使用通用视图首先要评估一下是否适合你的项目，通用视图将常见的模式抽象化，让你用更少的代码来编写你的视图。但是通用视图还是有些麻烦，学习起来需要更多时间。]]></content>
      <categories>
        <category>Django</category>
      </categories>
      <tags>
        <tag>Django</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Django学习3-视图]]></title>
    <url>%2F2018%2F12%2F17%2FDjango%E5%AD%A6%E4%B9%A03-%E8%A7%86%E5%9B%BE%2F</url>
    <content type="text"><![CDATA[介绍有了前面的学习基础之后，我迫不及待的想要做出漂亮的界面了。把前端页面从后端返回到路由中，这就是视图函数所要做的事。 在我们的投票应用中，我们需要下列几个视图： 问题索引页——展示最近的几个投票问题 问题详情页——展示某个投票的问题和不带结果的选项列表。 问题结果页——展示某个投票的结果。 投票处理器——用于响应用户为某个问题的待定选项投票的操作 在Django中，网页和其它内容都是从视图派生而来。每一个视图表现为一个简单的Python函数或者方法。Django将会根据用户请求的URL来选择使用哪个视图（更准确的说，是根据URL中域名之后的部分）。 URL有两种方式来实现分页，一种是URL部分可变，一种是URL传参的方式(问号传参) 编写视图函数现在向polls/views.py里添加更多视图。这些视图有一些不同，因为他们接受参数： 12345678910polls/views.pydef detail(request, question_id): return HttpResponse("You're looking at question %s" % question_id) def results(request, question_id): response = "You're looking at the results of question %s." return HttpResponse(response % question_id)def vote(request, question_id): return HttpResponse("You're voting on question %s." % question_id) 把这些新视图添加进polls.urls模块里，只需要添加几个url()函数调用就行： 1234567891011121314151617from django.urls import pathfrom .import viewsurlpatterns = [ # http://ip:port/polls/ path('', views.index, name='index'), # 首页问题列表 /polls/index/ path('index/', views.index, name='index'), # 问题详情页 ex:/polls/1/ path('&lt;int:question_id&gt;/', views.detail, name='detail'), # 投票结果页 path('&lt;int:question_id&gt;/results/', views.results, name='results'), # 去投票，选项计数加一/polls/5/vote path('&lt;int:question_id&gt;/vote/', views.vote, name='vote'),] 然后在浏览器中输入相应的路由即可查看这些视图函数的返回值。 写一个真正有用的视图上面的视图函数虽然能被正确访问，但是并没什么用，只是测试而已，现在，照着官方文档编写一个真正有用的视图把 每个视图函数必须要做的只有两件事：返回一个包含被请求页面内容的HttpResponse对象，或者抛出一个异常，比如Http404。至于其它的看你的选择了。 你的视图可以从数据库里读取记录，可以使用一个模板引擎，可以生成一个PDF文件，可以输出一个XML，创建一个ZIP文件，你可以做任何你想做的是，使用任何你想用的python库。 Django只要求返回的是一个HttpResponse，或者抛出一个异常。 因为Django自带的数据库API很方便，所以我们可以在视图函数里使用它。我们在index()函数里插入了一些新内容，让它能展示数据库里以发布日期排序的最近5个投票问题，以空格分割： 1234567891011polls/views.pyfrom django.http import HttpResponsefrom .models import Questiondef index(request): latest_quest_list = Question.objects.order_by('-pub_date0')[:5] output = ', '.join([q.question_text for q in lastest_question_list]) return HttpResponse(output)# 这里使用了列表生成式，先迭代出q,然后访问q的question_属性# 然后使用字符串的.join方法把列表生成式中迭代出来的项用, 分割组合成一个新字符串。 现在，这个视图函数就会返回最近的问题啦。但是还有问题，页面的设计写死在视图函数的代码。如果你想改变页面的样子，你需要编辑python代码。所以让我们通过使用Django的魔板系统，只要创建一个视图，就可以将页面的设计从代码中分离出来。 首先，在你的polls目录里创建一个templates目录。Django将会在这个目录里查找模板文件。 你项目的TEMPLATES配置项描述了Django如何载入和渲染末班。默认的设置文件设置了DjangoTemplates后端，并将APP_DIRS设置成了True。这一选项将会让DjangoTemplates在每个INSTALLED_APPS文件夹中寻找templates子目录。 在你刚刚创建的templates目录里，再创建一个目录polls，然后再其中新建一个文件index.html。换句话说，你的模板文件的路径应该是polls/templates/polls/index.html。因为Django会寻找到对应的app_directories，所以你只需要使用polls/index.html就可以引用到这一模板了。 将下面的代码输入到刚刚创建的模板文件中(index.html)： 123456789&#123;% if latest_question_list %&#125; &lt;ul&gt; &#123;% for question in latest_question_list %&#125; &lt;li&gt;&lt;a href=&quot;/polls/&#123;&#123; question.id &#125;&#125;/&quot;&gt;&#123;&#123; question.question_text &#125;&#125;&lt;/a&gt;&lt;/li&gt; &#123;% endfor %&#125; &lt;/ul&gt;&#123;% else %&#125; &lt;p&gt;No polls are available.&lt;/p&gt;&#123;% endif %&#125; 然后，让我们更新一下polls/views.py里的index视图来使用模板： 12345678910111213from django.http import HttpResponsefrom django.template import loaderfrom .models import Questiondef index(request): latest_question_list = Question.objects.order_by('-pub_date')[:5] template = loader.get_template('polls/index.html') context = &#123; 'latest_question_list': latest_question_list, &#125; return HttpResponse(template.render(context, request)) 上面代码的作用是，载入polls/index.html模板文件，并且向它传递一个上下文context。这个上下文是一个字典，他将模板内的变量映射为python对象。 现在访问/polls/，你将会看见一个无需列表，链接指向这个投票的详情页。 一个快捷函数： render()载入模板，填充上下文，再返回由它生成的HttpResponse对象是一个非常常用的操作流程。于是Django提供了一个快捷函数，我们用它来重写index()视图： 12345678polls/views.pyfrom django.shortcuts import renderfrom .models import Questiondef index(request): latest_question_list = Question.objects.order_by('-pub_date')[:5] context = &#123;'latest_question_list': latest_question_list&#125; return render(request, 'polls/index.html', context) 抛出404错误现在我们来处理投票详情视图–它会显示投票的问题标题： 12345678910polls/views.pydef detail(request, question_id): """ 显示一个问题的详细信息，问题内容、问题发布时间、选项内容、每个选项投票数。 """ try: question = Question.objects.get(pk=question_id) except Question.DoesNotExist: raise Http404("Question不存在") return render(request, 'polls/detail.html', &#123;'question': question&#125;) 在detail.html里先写入: 1&#123;&#123; question &#125;&#125; 一个快捷函数：get_object_or_404()尝试用get()函数获取一个对象，如果不存在就跑出Http404错误也是一个普遍的流程。Django也提供了一个快捷函数，下面是修改后的详情detail()视图代码： 1234567polls/views.pyfrom django.shortcuts import get_object_or_404, renderfrom .models import Questiondef detail(request, question_id) question = get_object_or_404(Question, pk=question_id) return render(request, 'polls/detail.html', &#123;'question': question&#125;) get_object_or_404()函数将Django模型作为其第一个参数和任意数量的关键字参数，并将这些参数传递给模型管理器的get()函数。如果对象不存在，它将引发Http404。 使用模板系统detail()视图向模板传递了上下文变量question。他是一个Question对象，下面我们来改进detail.html 123456&lt;h1&gt;&#123;&#123; question.question_text &#125;&#125;&lt;/h1&gt;&lt;ul&gt;&#123;% for choice in question.choice_set.all %&#125;&lt;li&gt;&#123;&#123; choice &#125;&#125;&lt;/li&gt;&#123;% endfor %&#125;&lt;/ul&gt; 模板系统统一使用点符号来访问变量的属性。在实例quesion.question_text 中，首先Django尝试对question对象使用字典查找（也就是objects.get(str)操作），如果失败了就尝试属性查找（也就是obj.str操作），结果是成功了。如果这一操作也失败的话，将会尝试列表查找(obj[int]操作)。 在% for %循环中发生的函数调用：question.choice_set.all被解释为python代码question.choice_set.all()，将会返回一个可迭代的Choice对象，这一对象在for标签内部使用。 去除模板中的硬编码URL我们在polls/index.html里编写投票连接时，链接是硬编码的： 1&lt;li&gt;&lt;a href="/polls/&#123;&#123; question.id &#125;&#125;/"&gt;&#123;&#123; question.question_text &#125;&#125;&lt;/a&gt;&lt;/li&gt; 问题在于，硬编码和强耦合的链接，对于一个包含很对应用的项目来说，修改起来是十分困难的。然而，因为你在polls.urls的url()函数中通过name参数为URL定义了名字，你可以使用% url %标签代替它： 12&lt;li&gt;&lt;a href="&#123;% url 'detail' question.id %&#125;"&gt;&#123;&#123; question.question_text &#125;&#125;&lt;/a&gt;&lt;/li&gt;# 通过url的name指向url，像上面一样传入一个qeustion_id来构造url，构造每个问题的详情页url 这个标签的工作方式是在polls.urls模块的URL定义中寻具有指定名字的条目。detail的url是这样定义的： 12path('&lt;int:question_id&gt;/', views.detail, name='detail'),... 将链接修改成这样的好处是：如果你想改变投票详情页视图的URL，比如像改成polls/xxx/1/，你不用在模板里修改任何东西（包括其他模板），只要在polls/urls.py里稍微修改一下就行： 12path('xxx/&lt;int:qeustion_id&gt;', view.detail, name='detail'),... 为URL名称添加命名空间官方文档教程项目只有一个应用：polls。但是在一个真是的Django项目中，可能会有五个、十个、二十个，甚至是更多应用。Django如果分辨重名的URL呢？举个例子，polls应用里有detail视图，可能另一个博客应用里也有同名的视图。Django如何知道%url%标签到底对应那个一个应用的URL呢？ 答案是：在根URLconf中添加命名空间。在polls/urls.py文件中稍作修改，加上app_name设置命名空间： 1234567891011polls/urls.pyfrom django.urls import pathfrom .import viewsapp_name = 'polls'urlpatterns = [ # http://ip:port/polls/ path('', views.index, name='index'), ...# 在这个文件中，设置app_name 然后，编辑polls/index.html文件，修改为指向具有命名空间的详细视图： 12polls/templates/polls/index.html&lt;li&gt;&lt;a href="&#123;% url 'polls:detail' question.id %&#125;"&gt;&#123;&#123; question.question_text &#125;&#125;&lt;/a&gt;&lt;/li&gt; 小结视图函数的作用就是从后端返回一些信息到前端页面，然后编写相应的url路由引入这些视图。 在polls/views.py中编写视图，在polls/urls.py中编写路由 为了方便HttpResponse对象使用模板，Django提供了一个快捷函数render()render函数有三个参数，第一个参数为request，第二个参数为要引用的模板，第三个参数为传入的上下文对象context字典。注意，在Django中写视图函数，默认都要传入一个reqeust参数，否则不能正常工作。 在处理请求时，经常会抛出404错误，在这个应用中，如果问题ID所对应的问题不存在，就需要抛出一个http404异常。起先，我们在detail视图里使用try except来抛出http404异常，但是这样写太麻烦了。Django提供了一个快捷函数get_object_or_404()。get_object_or_404()函数将Django模型作为其第一个参数和任意数量的关键字参数，并将这些参数传递给模型管理器的get()函数。如果对象不存在，它将引发Http404。 在一个完整的Django项目中，可能会有很多应用。每个应用都包含很多URL，难免会出现重复的URL，为了区分它们，可以每个应用的urls中加上app_name设置命名空间，然后在别处引入URL时（比如在html页面中指向url，）在路由url前加上命名空间即可。]]></content>
      <categories>
        <category>Django</category>
      </categories>
      <tags>
        <tag>Django</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Django学习2-数据库API和管理页面]]></title>
    <url>%2F2018%2F12%2F17%2FDjango%E5%AD%A6%E4%B9%A02%2F</url>
    <content type="text"><![CDATA[数据库APIdjango创建了各种API。打开python命令行进入 1python manage.py shell 我们使用这个命令而不是简单的python是因为manage.py会设置DJANGO_SETTINGS_MODULE环境变量，这个变量会让Django根据mysite/settings文件来设置python包的导入路径。 成功进入命令行后，来试试database API吧： 12345678910111213141516171819202122232425262728from polls.models import Choice, Question # 引入两个类Question.objects.all() # 获取Question表全部记录from django.utils import timezone # django内置生成时间的方法，可以生成带时区的时间q = Question(question_text="What's new", pub_date=timezone.now()) # 新加一条记录q.save() # 保存记录q.id # 查看id字段q.question_text # 查看question_text字段q.pub_date # 查看时间字段q.question_text = "'what's up" # 通过类.属性来改变question_text值，然后调用save方法保存到数据库中q.save()Question.objects.all()结果：&lt;QuerySet [&lt;Question: Question object (1)&gt;]&gt;# 这样返回的信息对于我们了解这个对象的细节并没有什么帮助。我们可以通过便捷Question模型的代码来修复这个问题。给Question和Choice类增加__str__()方法。polls/models.pyfrom django.db import modelsclass Question(models.Model): # ... def __str__(self): return self.question_test class Choice(models.Model): # ... def __str__(self): return self.choice_text# 给模型增加__str__()方法是很重要的，这不仅能给你命令行里使用带来方便，Django自动生成的admin里也使用这个方法来表示对象。 这些方法都是常规的python方法。让我们添加一个自定义的方法。这只是为了演示： 123456789polls/models.pyimport datetimefrom django.db import modelsfrom django.utils import timezoneclass Qusetion(models.Model): # ... def was_published_recently(self): return self.pub_date &gt;= timezone.now() - datetime.timedelta(days=1) 新加入的 import datetime和from django.utils import timezone分别导入了python标准的datetime模块和Django中和时区相关的django.utils.timezone工具模块。 再次打开python交互式命令行： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253from polls.models import Choice, Qution# 再次打印全部记录Question.objects.all()# 会发现返回值包含了刚才定义的str方法里的返回值# django通过关键字参数提供了丰富的数据库APIQuestion.object.filter(id=1) # 返回id=1的记录Question.objects.filter(question_text_startwith='What') # 返回question_text以What开头的记录# 看看今年发布的问题from django.utils import timezonecurrent_year = timezone.now().yearQuestion.objects.get(pub_date=current_year) # 调用在Question类中自定义的方法，返回今年发布的问题。# 请求一个不存在的ID，会出现错误。Question.objects.get(id=9999)会抛出一些错误栈# 主键查找是最常见的情况，所以Django为主键精确查找提供了一个快捷方式。# 下面的查找与Question.objects.get(id=1)结果一样Question.objects.get(pk=1)# 确认我们自定义的方法有效q = Question.objects.get(pk=1)q.was_published_recently()→True# 给这问题几个选项。create调用一个构造新的选项对象，执行INSERT语句# 将选项添加到集合中，并返回新的Choice对象。Django创建持有外键关系的# 另一方的集合（例如：问题的选择）可以通过API访问x = Question.objects.get(pk=1)# 显示来自相关对象集的任何选项——到目前为止还未添加任何选项x.choice_set.all()# 创建三个选项q.choice_set.create(choice_text='Not much'， votes=0)q.choice_set.create(choice_text='The sky', votes=0)c = q.choice_set.create(choice_text='Just hacking again', votes=0)# Choice 对象可以通过API访问他们的Questionc.question # 通过choice对象查看question对象.question方法→ &lt;Question: What's up?&gt;# 反之亦然，Question对象可以访问Choice对象。q.choice_set.all() # Question对象通过choice_set.all()返回全部Choice选项q.choice_set.count() # 计算有几个选项#API会根据您的需要自动跟踪关系。使用双下划线分隔关系。#这可以在你想要的深度上工作;是没有限制的。#找到任何问题的所有选项，其pub_date在今年#(重用我们在上面创建的'current_year'变量)。choice.objects.filter(question_pub_date_year=current_year) # 返回今年的问题# 使用delete()方法删除一个选项， z = q.choice_set.filter(choice_text_starwith='Just hacking')c.delete() # 删除以just hacking开头的选项 Django管理页面介绍Django全自动的根据模型创建了后台管理页面，让你的增删改查更方便 管理界面是为网站管理员使用的。 创建一个管理员账号首先，我们需要创建一个能大能管理页面的用户。 1python mange.py createsupetuser 输入你想使用的用户名，然后按下回车键： 1Username: admin 然后提示你输入想要使用的邮箱地址： 1Email address: admin@exmple.com 最后一步是输入密码。会要求你输入两次密码。 这些步骤完成后会在数据库auto_user表中添加一行记录 开启服务现在开启服务来体验Django的管理界面吧 输入刚才注册的管理员用户登录 第一次进入，管理界面只有组和用户管理员来管理，它们是由django.contrib.auth提供的，这是Django开发的认证框架。 我们的投票应用并没有在页面中显示，现在，我们需要告诉管理页面。问题对象Question和Choice对象需要被管理。打开polls/admin.py文件： 12345from django.contrib import adminfrom polls.models import Question, Choiceadmin.site.register(Qusetion)admin.site.register(Choice) 现在就可以在管理界面自由的修改数据库中的信息啦。 小结Django提供了丰富的数据库API Question.onjects.all() →查看问题 x = Question.objects.get(id=1) x.Choice_set.create(choice=’New choice’, votes=0) →为问题添加choice x.choice_set.all() →查看问题所有Choice y = Choice.objects.get(id=1) →查看一个选项 y.question →查看选项对应的问题 y.delete() →删除一个选项 要使用Django生成的后台管理页面 首先需要创建一个超级用户python manage.py createsuperuser 然后在admin.py中告诉管理页面要被管理的对象models]]></content>
      <categories>
        <category>Django</category>
      </categories>
      <tags>
        <tag>Django</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Django学习1]]></title>
    <url>%2F2018%2F12%2F14%2FDjango%E5%AD%A6%E4%B9%A01%2F</url>
    <content type="text"><![CDATA[编写第一个django应用django是一个成熟的web框架，学习起来比flask要难，本文主要根据django官方文档撰写，仅供个人参考。 第一部分官方教程会创建一个基本的投票应用程序。 它有两部分组成： 一个让人们查看和投票的公共站点。 一个让你能添加、修改和删除投票的管理站点。 安装了django之后，运行py-m django --version查看django版本。目前最新的版本是2.1.4. 创建项目要开始学习django，首先要从如果创建一个项目开始。 1django-admin startproject mysite 运行上面这个命令，django会创建一个名为mysite的项目。 startprojects会创建一些文件和目录。 1234567mysite/ manage.py mysite/ __init__.py settings.py urls.py wsgi.py 这些东西的作用是： 最外层的mysite根目录只是你项目的容器 manage.py一个让你用各种方式管理django项目的命令行工具。 里面一层的mysite目录包含你的项目，它是一个纯python包。 mysite/__init_ _.py：一个空文件，告诉python 这个目录应该被认为是一个python包。 mysite/settings.py：django项目的配置文件。包含一些配置信息。 mysite/urls.py：django项目的URL声明，就行你网站的目录 mysite/wsgi.py：作为你的项目运行在WSGI兼容的web服务器上的入口。 一个用于开发的建议服务器django自带了一个简易的服务器，他是一个纯python写的轻量级的web服务器。这个服务器内置在django中是为了方便我们快速的开发出想要的东西。 运行python manage.py runserver命令会启动这个服务器，现在，服务默认运行在本地8000端口上，浏览器访问本地8000端口，会看到一个django初始的页面。 更换端口：py manage.py runserver 8080 监听ip：py manage.py runserver 0:8080(0是0.0.0.0的缩写) 创建一个应用现在开发环境已经配置好了，可以开始创建一个应用了 在django中，每一个应用都是一个python包，并且遵循着相同的约定。django自带一个工具，可以帮你生成应用的基础目录建构。 在这个教程中，我们将在manage.py同级目录下创建投票应用。这样它就可以作为顶级米块倒入，而不是mysite的子模块。 cd到manage.py所在的目录下，然后运行 py manage.py startapp polls 运行之后将会创建一个polls目录。 编写第一个视图打开polls/view.py，输入以下代码 1234from django.http import HttpResponsedef index(request): return HttpResponse(&quot;hllo,world.Your&apos;re at the polls index&quot;) 这是django中最简单的视图。如果想看见效果，我们需要将一个URL映射到他–这就是我们需要URLconf的原因了。 为了创建URLconf，请再polls目录里新建一个urls.py。 在polls/urls.py中： 123456from fjango.urls import pathfrom . import viewsurlpatterns = [ path('', views.index, name='index')] 下一步是要在跟URLconf文件中指定我们创建的polls.urls模块。在mysite/urls.py的文件的urlpatterns列表里插入一个include() 12345678from django.contrib import adminfrom django.urls import include, pathurlpatterns = [ path('polls/', include('polls.urls')), path('admin/', admin.site.urls)]## 这个就是django的顶级路由，这里定义的polls/会接收来自http://127.0.0.1:8000/polls的请求。path的第二个参数指向这个路由的地址。注意，和flask不同，这里的/是路由的结尾。如果要定义主页路由，第一个参数写成''，就可以了。 函数include()允许引用其他的URLconfs。 何时使用include()：当包括其他URL模式时你应该总是使用include()，admin.site.urls是唯一例外。 现在把index视图添加进了URLconf。要看效果，开启服务器：py manage.py runserver 现在访问http:127.0.0.1:8000/polls将会看到我们在视图函数里面定义的返回值。 path（）函数path()函数具有四个参数，两个必须参数：route和view，两个可选参数kwaigs和name。 path()参数：route route是一个匹配URL的准则。当django响应一个请求时，它会从urlpatterns的第一项开始，按顺序依次匹配列表中的项，直到找到匹配的项。 这些准则不会匹配GET和POST参数或域名。例如URLconf在处理请求http://www.example.com/myapp/时，它会尝试匹配myapp/。处理请求http://www.example.com/myapp/?page=3时，也只会尝试匹配myapp/。 path()参数：view 当django找到了一个匹配的准则，就会调用这个特定的视图函数，并传入一个HttpRequest对象作为第一个参数，被捕获的参数以关键字的形式传入。 path()：参数kwargs 任意个关键字参数可以作为一个字典传递给目标视图函数。 path()：参数name 为你的URL取名能使你在Django的任意地方唯一地引用它，尤其是在模板中。这个有用的特性允许你只改一个文件就能全局地修改某个URL模式。 第二部分：数据库配置在这一部分中，我们将创建第一个模型，并关注Django提供的自动生成的管理页面。 数据库配置现在，打开mysite/settings.py。这是个包含了django项目设置的python模块。 通常，这个配置文件使用SQLite作为默认数据库。如果需要使用其他的数据库，就需要安装合适的database bindings，然后改变设置文件中DATABASES’defaule’的一些键值： ENGINE 可选值有django.db.backends.sqlite3,django.db.backends.postgresql,django.db.backends.mysql或django.db.backends.oracle。 NAME：数据库的名称。如果使用的是SQLite，数据库将是你电脑上的一个文件，在这种情况下，NAME应该是此文件的绝对路径，包括文件名。默认值os.path.join(BASE_DIR, ‘db.sqlite3’)将会把数据库文件储存在项目的根目录。 如果不适用SQLite，则必须添加一些额外设置，比如USER、PASSWORD、HOST等等。 如果使用SQLite以外的数据库，请确认在使用前已经创建了数据库。 编辑mysite/settings.py文件前，先设置TIME_ZONE为你自己的时区。 INSTALLED_APPS设置项。这里包括了会在你项目中启用的所有Django应用。应用能在多个项目中使用，你也可以打包并且发布应用，让别人使用它们。 INSTALLED_APPS自带应用： django.contrib.admin -管理员站点 django.contrib.auth -认证授权系统 django.contrib.contenttypes -内容类型框架。 django.contrib.sessions -会话框架 django.contrib.messages -消息框架 django.contrib.staticfiles -管理静态文件的框架。 这些应用默认启用是为了给常规项目提供方便。 默认开启的某些应用需要至少一个数据表，所以在使用它们之前需要在数据库中创建一些表。 python manage.py migrate 这个migrate命令检查INSTALLED_APPS设置，为其中的每个应用创建需要的数据表，至于会创建什么，这取决于你的mysite/settings.py设置文件和每个应用的数据库迁移文件。这个命令所执行的每个迁移操作都会在终端中显示出来。 创建模型在django里写一个数据库驱动的web应用的第一步是定义模型 也就是数据库结构设计和附加的其它元数据。 在这个简单投票应用中，需要创建两个模型：问题Question和选项Choice。Question模型包括问题描述和发布时间。Choice模型有两个字段，选项描述和当前得票数。每个选项属于一个问题。 这些概念可以通过一个简单的python类来描述。按照下面的例子来编辑polls/models.py文件： 12345678910from django.db import modelsclass Question(model.Model): question_text = models.CharField(max_length=200) pub_date = models.DateTimeField('date published') class Choice(models.Model): question = models.ForeignKey(Question, on_delete=models.CASCADE) choice_text = models.CharField(max_length=200) votes = models.IntegerFiele(default=0) 代码非常直白。每个模型被表示为django.db.model.Model类的子类。每个模型有一些类变量，它们都表示模型里的一个数据库字段。每个字段都是Field的实例-比如，字符字段被表示为CharField，日期时间字段被表示为DateTimeField。这将告诉python每个字段要处理的类型。 每个Field类实例变量的名字也是字段名，所以最好使用对机器友好的格式。你将会python代码里使用它们，而数据库会将它们作为列明。 你可以使用可选的选项来为Field定义一个人类可读的名字。这个功能在很多django内部组成部分中都被使用了，而且作为文档的一部分。如果某个字段没有提供此名称，django将会使用对机器有好的名称，也就是变量名。在上面的例子中，我们只为Question.pub_date定义了对人类有好的名字。 激活模型上面的一小段用于创建模型的代码给了Django很多信息，通过这些信息，django可以： 为这个应用创建数据库schema（生成CREATE TABLE语句） 创建可以与Question和Chioce对象进行江湖的python数据库的API。 但是首先得把polls应用安装到我们的项目里。 为了在我们的工程中包含这个应用，我们需要在配置类INSTALLED_APPS中添加设置。因为PollsConfig类卸载文件polls/apps.py中，所以他的点式路径是polls.apps.PollsConfig。在文件mysite/settings.py中INSTALLED_APPS子项添加点式路径后，它看起来像这样： 123INSTALLED_APPS = [ &apos;polls.apps.PollsConfig&apos;,] 现在你的django项目会包含polls应用。接着运行下面的命令 python manage.py makemigrations polls 通过运行makemigratetions命令，django会检测你对模型文件的修改，并且把修改的部分储存为一次迁移。 迁移是django对于模型定义（也就是你的数据库结构）的变化的储存形式。django有一个自动执行数据库迁移并同步管理你的数据库结构的命令-这个命令式migrate。可以运行 python manage.py sqlmigrate polls 0001 看看迁移命令会执行哪些SQL语句。sqlmigrate命令接收一个迁移的名称，然后返回对应的SQL。 请注意以下几点： 输出的内容和你使用的数据库有关 数据库的表名是由应用名和模型名的小写形式连接而来，（可以自定义此行为） 主键（ID）会被自动创建 默认的，django会在外键字段明后追加字符串_id 外键关系由FOREIGN KEY生成。 生成的SQL语句是为你所用的数据库定制的，所以那些和数据库有关的字段类型，比如auto_inctement，django会帮你自动处理。那些和引号相关的事情-例如，是单引号还是双引号，django也一样会被自动处理。 这个sqlmigrate命令并没有真正在你的数据库中的执行迁移-它只是把命令输出到屏幕上，让你看看django到底准备做什么，或者当你是数据库管理员，需要写脚本来批量处理数据库时会很有用 如果你感兴趣，你也可以试试运行python manage.py check;这个命令帮助你检查项目中的问题，并且在检查过程中不会对数据库进行任何操作。 现在，再次运行migrate命令，在数据库里创建定义的类型的数据库： python manage.py migrate 这个migrate命令选中所有还没有执行过的迁移并应用在数据库上，也就是将对你模型的更改过同步到数据库结构上。 迁移是非常强大的功能，它能让你在开发过程中持续的改变数据库结构而不需要重新删除和创建表-它专注于使数据库平滑升级而不会丢失数据。改变模型需要三步： 编辑models.py，改变模型 运行python manage.py makemigrations 为模型的改变生成迁移文件。 运行python manage.py migrate来应用数据库迁移 数据库迁移被分解成生成和应用两个命令式为了让你能够在代码控制系统上提交迁移数据并使其能在多个应用里使用；这不仅仅会让开发更简单，也给别的开发者和生产环境中的使用带来方便。 小结到此，已经初步了解了django的使用方式以及项目和应用的关系，还有如何生成数据库。 django-admin startproject mysite 创建项目 python manage.py startapp polls 创建应用 python manage.py migrate 为应用创建数据表 python manage.py makemigratetions polls 为polls应用生成迁移文件 数据表模型在models.py文件中，通过ORM对数据库进行操作 settings.py中存放一些配置信息，INSTALLED_APPS设置项。这里包括了会在你项目中启用的所有Django应用。 mysite\urls.py是顶级路由，polls\urls.py是为应用创建的路由，需要在顶级路由中引用应用路由 polls\views.py中是应用的视图函数编写视图函数的返回值是一个HttpResponse。 接下来会继续学习django的admin管理应用。]]></content>
      <categories>
        <category>Django</category>
      </categories>
      <tags>
        <tag>Django</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[正则表达式的使用]]></title>
    <url>%2F2018%2F12%2F12%2F%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F%E7%9A%84%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[正则表达式正则表达式在爬虫中被广泛使用，正则和Xpath各有各的优点。虽然以前学习过正则表达式，但现在还总是迷迷糊糊的，今天有所顿悟。 re.search()和re.match()re.match决定RE是否在字符串刚开始的位置匹配。//注：这个方法并不是完全匹配。当pattern结束时若string还有剩余字符，仍然视为成功。想要完全匹配，可以在表达式末尾加上边界匹配符’$’ re.search函数会在字符串内查找模式匹配,只要找到第一个匹配然后返回，如果字符串没有匹配，则返回None。 match和search一旦匹配成功，就是一个match object对象，而match object对象有以下方法： group() 返回被RE匹配的字符串 start() 返回匹配开始的位置编号 end() 返回匹配结束的位置编号 span() 返回一个元组包含匹配（开始，结束）的位置编号 group() 返回re整体匹配的字符串，可以一次输入多个组号，对应组号匹配的字符串 re.search()后使用group()不加参数表示返回被匹配的整体字符串，group()加上一个参数1表示取出匹配的第一组字符，可以输入多个组号。 eg.: 12345import restr1 = '&lt;h1&gt;hello world&lt;/h1&gt;你好世界&lt;/h1&gt;'x = re.search('&lt;h1&gt;(.*?)&lt;/h1&gt;(.*?)&lt;/h1&gt;', str1).group(1,2)print(x)结果：('hello world', '你好世界') re.compile和re.findallre.compile是对正则表达式进行预编译，返回一个对象的模式，主要作用是把常用的正则表达式编译成正则表达式对象，这样可以提高一点效率。 格式：re.compile(pattern,flags=0) pattern：编译时用的表达式字符串 flags：编译标志位，用于修改正则表达式的匹配方式，模式修正符。 常用的flags模式修正符有： re.S：使.匹配包括换行符在内的所有字符 re.I：使匹配不区分大小写 re.L：做本地化识别匹配 re.M：多行匹配，影响^和$ re.X：该标志通过给予更灵活的格式一遍将正则表达式写的更易于理解 re.U：根据Unicode字符集解析字符，这个标志影响\w,\W,\b,\B re.findall遍历匹配，可以获取字符串中所有匹配的字符串，返回一个列表。 格式：re.findall(pattern, string, flags=0) pattern为表达式字符串， strings为要匹配的字符串 flags为模式修正符 所以可以看到： 在findall中包含了compile，为了简洁，一般我都不适用compile。 re.finditerre.finditer() 搜索string，返回一个顺序访问每一个匹配结果（Match对象）的迭代器。找到 RE 匹配的所有子串，并把它们作为一个迭代器返回。 格式和findall()一样，返回的是一个迭代器，要使用for循环迭代取值，由于他返回的是一个Match对象，所以还要使用.group()函数来取出字符串。 re.split按照能够匹配的子串将string分割后返回列表。 可以使用re.split来分割字符串，如：re.split(r’\s+’, text)；将字符串按空格分割成一个单词列表。 格式： re.split(pattern, string[, maxsplit]) maxsplit用于指定最大分割次数，不指定将全部分割。 eg. 123print(re.split('\d+','one1two2three3four4five5'))执行结果如下：['one', 'two', 'three', 'four', 'five', ''] re.supre.sup使用re替换string中每一个匹配的子串后返回替换后的字符串。 eg. 1re.sup(&apos;[\n ]&apos;, &apos;&apos;, str) 上面这个例子会吧str中所有的换行符和空格去除。 一些要注意的地方re.match与re.search与re.findall的区别： re.match只匹配字符串的开始，如果字符串开始不符合正则表达式，则匹配失败，函数返回None；而re.search匹配整个字符串，直到找到一个匹配。 12345678910a=re.search('[\d]',"abc33").group()print(a)p=re.match('[\d]',"abc33")print(p)b=re.findall('[\d]',"abc33")print(b)执行结果：3None['3', '3'] 贪婪匹配与非贪婪匹配 ?,+?,??,{m,n}? 前面的,+,?等都是贪婪匹配，也就是尽可能匹配，后面加?号使其变成惰性匹配 12345678910111213141516171819202122232425a = re.findall(r"a(\d+?)",'a23b')print(a)b = re.findall(r"a(\d+)",'a23b')print(b)执行结果：['2']['23']a = re.match('&lt;(.*)&gt;','&lt;H1&gt;title&lt;H1&gt;').group()print(a)b = re.match('&lt;(.*?)&gt;','&lt;H1&gt;title&lt;H1&gt;').group()print(b)执行结果：&lt;H1&gt;title&lt;H1&gt;&lt;H1&gt;a = re.findall(r"a(\d+)b",'a3333b')print(a)b = re.findall(r"a(\d+?)b",'a3333b')print(b)执行结果如下：['3333']['3333']#######################这里需要注意的是如果前后均有限定条件的时候，就不存在什么贪婪模式了，非匹配模式失效。 本篇博客借鉴CNBLOGS]]></content>
      <categories>
        <category>爬虫</category>
      </categories>
      <tags>
        <tag>爬虫</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[第一个web应用]]></title>
    <url>%2F2018%2F12%2F04%2F%E7%AC%AC%E4%B8%80%E4%B8%AAweb%E5%BA%94%E7%94%A8%2F</url>
    <content type="text"><![CDATA[介绍学习完flask和数据库之后，在老师的指导下制作了我的第一个web应用。 数据库使用的是MongoDB，前端部分使用了bootstrap框架 To Do应用类似备忘录 主要功能 实现了用户登录、注册等 每个用户都有不同的主页 可以跳过登录 新建to do包含创建时间，点击完成后，会记录完成时间 未完成和已完成以不同的表格颜色区分 效果 首页用户登录 跳过登录效果 新建todo 登录后页面 注册页面 主要功能实现数据库结构设计在MongoDB的todo库中主要有两个集合，第一个content集合主要用来记录数据，第二个user集合主要记录注册用户的信息。 content集合主要有5个字段： content：主要内容 create_time：创建时间 status：主要用来辨别完成状态，1代表已完成，2代表未完成 finish_time：记录完成时间 time：生成一个时间戳 user集合有两个字段： user：用户名 password：密码 每个用户都有一个独立的集合，登录过后再flask中通过创建集合的方式来生成，字段等和content集合一样 主页设计首先实现主页面的显示，连接MongoDB数据库，将查询结果传到前端页面。 在前端主页中主要使用表格来显示数据，MongoDB查询结果是一个数据对象，可以使用for循环展开，在前端页面中使用jinja2的for循环语法来实现数据的展示。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546&lt;table border="1px" style="border: solid red 1px;font-size: 18px;" class="table"&gt; &lt;tr&gt; &lt;th&gt;序号&lt;/th&gt; &lt;th&gt;内容&lt;/th&gt; &lt;th&gt;创建时间&lt;/th&gt; &lt;th&gt;状态&lt;/th&gt; &lt;th&gt;完成时间&lt;/th&gt; &lt;th&gt;修改&lt;/th&gt; &lt;th&gt;删除&lt;/th&gt; &lt;th&gt;完成&lt;/th&gt; &lt;/tr&gt;&#123;% for d in data %&#125; &#123;% if d.status == 1 %&#125; &lt;tr bgcolor="#90ee90" align="center"&gt; &lt;td&gt;&#123;&#123; loop.index &#125;&#125;&lt;/td&gt; &lt;td&gt;&#123;&#123; d.content &#125;&#125;&lt;/td&gt; &lt;td&gt;&#123;&#123; d.create_time &#125;&#125;&lt;/td&gt; &#123;% if d.status == 1 %&#125; &lt;td&gt;已完成&lt;/td&gt; &#123;% else %&#125; &lt;td&gt;未完成&lt;/td&gt; &#123;% endif %&#125; &lt;td&gt;&#123;&#123; d.finish_time &#125;&#125;&lt;/td&gt; &lt;td&gt;&lt;a href="&#123;&#123; url_for('update', id=d.content) &#125;&#125;"&gt;修改内容&lt;/a&gt;&lt;/td&gt; &lt;td&gt;&lt;a href="&#123;&#123; url_for('delete', id=d.content) &#125;&#125;"&gt;×&lt;/a&gt;&lt;/td&gt; &lt;td&gt;&lt;a href="&#123;&#123; url_for('finish', id=d.content) &#125;&#125;"&gt;√&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &#123;% else %&#125; &lt;tr align="center"&gt; &lt;td&gt;&#123;&#123; loop.index &#125;&#125;&lt;/td&gt; &lt;td&gt;&#123;&#123; d.content &#125;&#125;&lt;/td&gt; &lt;td&gt;&#123;&#123; d.create_time &#125;&#125;&lt;/td&gt; &#123;% if d.status == 1 %&#125; &lt;td&gt;已完成&lt;/td&gt; &#123;% else %&#125; &lt;td&gt;未完成&lt;/td&gt; &#123;% endif %&#125; &lt;td&gt;&#123;&#123; d.finish_time &#125;&#125;&lt;/td&gt; &lt;td&gt;&lt;a href="&#123;&#123; url_for('update', id=d.content) &#125;&#125;"&gt;修改内容&lt;/a&gt;&lt;/td&gt; &lt;td&gt;&lt;a href="&#123;&#123; url_for('delete', id=d.content) &#125;&#125;"&gt;×&lt;/a&gt;&lt;/td&gt; &lt;td&gt;&lt;a href="&#123;&#123; url_for('finish', id=d.content) &#125;&#125;"&gt;√&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &#123;% endif %&#125;&#123;% endfor %&#125; &lt;tr align="right" bgcolor="#f5deb3"&gt;&lt;td colspan="8"&gt;&lt;a href="&#123;&#123; url_for('add') &#125;&#125;"&gt;新建todo&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;/table&gt; 为了实现表格以完成状态来变色的功能，在html中增加了一个if判断，判断status字段值为1的话代表已完成，就更换一个颜色。 增删改查当点击表格中的x号时，会跳转到delete路由并且会携带content值，在delete路由中以content值来删除记录。 当点击完成时，会跳转到finish路由并且会携带content值，在finish路由中修改字段status为1，用来表示已完成。 当点击修改内容时，会跳转到update路由并且携带content值，在update路由中修改content字段即完成了修改内容。 点击新建todo时，会跳转到add路由中，在add路由中新建一条记录。 用户登录模块设计要使每个用户拥有不同的主页就要创建不同的表，在flask 路由中是用cookie来判别登录用户是否登录。用户登录就是与数据库用户表比对。用户登录之后会设置一个设置了一个cookie，在后面的请求中都会携带cookie。flask路由接收cookie， 用来判断用户登录状态。已登录和未登录返回不同的页面。 app.py: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183from flask import Flask, render_template, url_for, request, redirect, make_responsefrom pymongo import MongoClientfrom datetime import datetimeimport timeapp = Flask(__name__)# 连接数据库client = MongoClient()db = client['todo']collection = db['content']@app.route('/')def index(): """返回登录页面""" return render_template('sign_in.html')@app.route('/testa')def testa(): cookie = request.cookies # 接收cookie if cookie: # 如果有cookie就是已登录状态 x = cookie['username'] print(x) # 切换数据库集合，让不同用户操作 collection = db[f'&#123;x&#125;'] data = collection.find(&#123;&#125;).sort([('status', 1)]) # 返回登录后的页面 return render_template('aftersign.html', data=data, user=x) else: # 如果没有cookie则返回index.html collection = db['content'] data = collection.find(&#123;&#125;).sort([('status', 1)]) return render_template('index.html', data=data)@app.route('/add', methods=['GET', 'POST'])def add(): """添加todo记录，接收两种请求，GET请求返回add.html页面，同样使用cookie来判断用户登录状态返回不同的页面""" cookie = request.cookies if request.method == 'GET': if cookie: user = cookie['username'] return render_template('afteradd.html', user=user) else: return render_template('add.html') else: """提交后返回testa路由""" content = request.form u_content = content['u_content'] print(u_content) if cookie: user = cookie['username'] collection = db[f'&#123;user&#125;'] collection.insert_one(&#123;'content': u_content, 'create_time': datetime.now(), 'status': 0, 'finish_time': '', 'time': time.time()&#125;) return redirect(url_for('testa')) else: collection = db['content'] collection.insert_one(&#123;'content': u_content, 'create_time': datetime.now(), 'status': 0, 'finish_time': '', 'time': time.time()&#125;) return redirect(url_for('testa'))@app.route('/finish')def finish(): """更改状态为已完成""" cookie = request.cookies if cookie: user = cookie['username'] collection = db[f'&#123;user&#125;'] args = request.args id = args['id'] print(id) collection.update(&#123;'content': id&#125;, &#123;'$set': &#123;'status': 1, 'finish_time': datetime.now()&#125;&#125;) return redirect(url_for('testa')) else: collection = db['content'] args = request.args id = args['id'] print(id) collection.update(&#123;'content': id&#125;, &#123;'$set': &#123;'status': 1, 'finish_time': datetime.now()&#125;&#125;) return redirect(url_for('testa'))@app.route('/delete')def delete(): """删除记录""" cookie = request.cookies args = request.args time = args['id'] if cookie: user = cookie['username'] collection = db[f'&#123;user&#125;'] collection.delete_one(&#123;'content': time&#125;) return redirect(url_for('testa')) else: collection = db['content'] collection.delete_one(&#123;'content': time&#125;) return redirect(url_for('testa'))@app.route('/update', methods=['GET', 'POST'])def update(): """更新内容""" if request.method == 'GET': args = request.args global x x = args['id'] print(x) return render_template('update.html', a=x) else: cookie = request.cookies form = request.form con = form['modify'] if cookie: user = cookie['username'] collection = db[f'&#123;user&#125;'] collection.update(&#123;'content': x&#125;, &#123;'$set': &#123;'content': con&#125;&#125;) print(con) return redirect(url_for('testa')) else: collection = db['content'] collection.update(&#123;'content': x&#125;, &#123;'$set': &#123;'content': con&#125;&#125;) print(con) return redirect(url_for('testa'))@app.route('/about')def about(): """about页面""" return render_template('about.html')@app.route('/sign_in', methods=['POST', 'GET'])def sign_in(): """用户登录""" if request.method == 'GET': return render_template('sign_in.html') else: form = request.form user = form['user'] password = form['password'] print(user) print(password) collection = db['user'] a = collection.find_one(&#123;'user': user&#125;) if user == a['user'] and password == a['password']: collection = db[f'&#123;user&#125;'] data = collection.find(&#123;&#125;).sort([('status', 1)]) resonse = make_response(render_template('aftersign.html', user=user, data=data)) print(user) resonse.set_cookie('username', user) resonse.set_cookie('password', password) return resonse else: return '用户名或密码输错'@app.route('/delete_cookie')def delete_cookie(): """用户注销，删除cookie""" response = make_response(redirect(url_for('index'))) response.delete_cookie('username') response.delete_cookie('password') return response@app.route('/sign_up', methods=['GET', 'POST'])def sign_up(): """用户注册""" if request.method == 'GET': return render_template('sign_up.html') else: form = request.form username = form['username'] password = form['password'] collection = db['user'] collection.insert_one(&#123;'user': username, 'password': password&#125;) return render_template('sign_in.html')if __name__ == '__main__': app.run()]]></content>
      <categories>
        <category>Flask</category>
      </categories>
      <tags>
        <tag>Flask</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Git学习]]></title>
    <url>%2F2018%2F11%2F30%2FGit%E5%AD%A6%E4%B9%A0%2F</url>
    <content type="text"><![CDATA[Git简介​ Git是一个分布式版本控制系统，也是一个程序员必需的技能之一。什么是版本控制系统呢？ 比如我使用word写论文，写着写着突然想修改某一段落，但又怕将来出错，找不回来，所以你就将当前文件复制一份后再修改。过了几天，你想找回被修改的段落，只能回到那个副本中去找，这样很麻烦。git就是帮助你简化这个操作的软件，他不仅能轻松回到任一版本，还能记录下你每次文件的改动。 Git安装​ 在Windows上使用Git，可以从Git官网直接下载安装程序，（网速慢的同学请移步国内镜像），然后按默认选项安装即可。 安装完成后，在开始菜单里找到“Git”-&gt;“Git Bash”，蹦出一个类似命令行窗口的东西，就说明Git安装成功！ 安装完成后，还需要最后一步设置，在命令行输入： 12$ git config --global user.name &quot;Your Name&quot;$ git config --global user.email &quot;email@example.com&quot; 因为Git是分布式版本控制系统，所以，每个机器都必须自报家门：你的名字和Email地址。你也许会担心，如果有人故意冒充别人怎么办？这个不必担心，首先我们相信大家都是善良无知的群众，其次，真的有冒充的也是有办法可查的。 注意git config命令的--global参数，用了这个参数，表示你这台机器上所有的Git仓库都会使用这个配置，当然也可以对某个仓库指定不同的用户名和Email地址。 使用Git创建版本库新建一个文件夹，然后打开右键打开git bush here运行git init命令 这时已经创建了一个版本库，如果你打开查看隐藏文件，会看到这个文件夹下会多出一个.git文件夹，这个文件夹就记录了你每次的操作。 把文件添加到版本库git可以跟踪文件的改动，但是只能跟踪文本文件的改动，比如md文件、TXT、网页、代码等等，无法跟踪二进制文件的改动。git可以告诉你每次的改动，比如在第5行加了一个单词“Linux”，在第8行删了一个单词“Windows”。而图片、视频这些二进制文件，虽然也能由版本控制系统管理，但没法跟踪文件的变化，只能把二进制文件每次改动串起来，也就是只知道图片从100KB改成了120KB，但到底改了啥，版本控制系统不知道，也没法知道。 所以我们先新建一个test.txt用来学习git。 然后在里面写上hello world。然后： 使用git add命令告诉git，把文件添加到仓库 git add test.txt 使用git commit命令提交到仓库 12345Administrator@2013-20181114VC MINGW64 ~/Desktop/gitxuexi (master)$ git commit -m '第一次提交'[master (root-commit) 77b32e4] 第一次提交 1 file changed, 1 insertion(+) create mode 100644 test.txt git commit命令就是提交，后面的参数-m后面输入的是本次提交的说明，可以输入任何内容 git commit命令执行成功后会告诉你，1 file changed：1个文件被改动（我们新添加的readme.txt文件）；1 insertions：插入了一行内容（readme.txt有一行内容）。 创建版本库阅读: 1859219什么是版本库呢？版本库又名仓库，英文名repository，你可以简单理解成一个目录，这个目录里面的所有文件都可以被Git管理起来，每个文件的修改、删除，Git都能跟踪，以便任何时刻都可以追踪历史，或者在将来某个时刻可以“还原”。 所以，创建一个版本库非常简单，首先，选择一个合适的地方，创建一个空目录： $ mkdir learngit$ cd learngit$ pwd/Users/michael/learngitpwd命令用于显示当前目录。在我的Mac上，这个仓库位于/Users/michael/learngit。 如果你使用Windows系统，为了避免遇到各种莫名其妙的问题，请确保目录名（包括父目录）不包含中文。 第二步，通过git init命令把这个目录变成Git可以管理的仓库： $ git initInitialized empty Git repository in /Users/michael/learngit/.git/瞬间Git就把仓库建好了，而且告诉你是一个空的仓库（empty Git repository），细心的读者可以发现当前目录下多了一个.git的目录，这个目录是Git来跟踪管理版本库的，没事千万不要手动修改这个目录里面的文件，不然改乱了，就把Git仓库给破坏了。 如果你没有看到.git目录，那是因为这个目录默认是隐藏的，用ls -ah命令就可以看见。 也不一定必须在空目录下创建Git仓库，选择一个已经有东西的目录也是可以的。不过，不建议你使用自己正在开发的公司项目来学习Git，否则造成的一切后果概不负责。 把文件添加到版本库首先这里再明确一下，所有的版本控制系统，其实只能跟踪文本文件的改动，比如TXT文件，网页，所有的程序代码等等，Git也不例外。版本控制系统可以告诉你每次的改动，比如在第5行加了一个单词“Linux”，在第8行删了一个单词“Windows”。而图片、视频这些二进制文件，虽然也能由版本控制系统管理，但没法跟踪文件的变化，只能把二进制文件每次改动串起来，也就是只知道图片从100KB改成了120KB，但到底改了啥，版本控制系统不知道，也没法知道。 不幸的是，Microsoft的Word格式是二进制格式，因此，版本控制系统是没法跟踪Word文件的改动的，前面我们举的例子只是为了演示，如果要真正使用版本控制系统，就要以纯文本方式编写文件。 因为文本是有编码的，比如中文有常用的GBK编码，日文有Shift_JIS编码，如果没有历史遗留问题，强烈建议使用标准的UTF-8编码，所有语言使用同一种编码，既没有冲突，又被所有平台所支持。 使用Windows的童鞋要特别注意： 千万不要使用Windows自带的记事本编辑任何文本文件。原因是Microsoft开发记事本的团队使用了一个非常弱智的行为来保存UTF-8编码的文件，他们自作聪明地在每个文件开头添加了0xefbbbf（十六进制）的字符，你会遇到很多不可思议的问题，比如，网页第一行可能会显示一个“?”，明明正确的程序一编译就报语法错误，等等，都是由记事本的弱智行为带来的。建议你下载Notepad++代替记事本，不但功能强大，而且免费！记得把Notepad++的默认编码设置为UTF-8 without BOM即可： set-utf8-notepad++ 言归正传，现在我们编写一个readme.txt文件，内容如下： Git is a version control system.Git is free software.一定要放到learngit目录下（子目录也行），因为这是一个Git仓库，放到其他地方Git再厉害也找不到这个文件。 和把大象放到冰箱需要3步相比，把一个文件放到Git仓库只需要两步。 第一步，用命令git add告诉Git，把文件添加到仓库： $ git add readme.txt执行上面的命令，没有任何显示，这就对了，Unix的哲学是“没有消息就是好消息”，说明添加成功。 第二步，用命令git commit告诉Git，把文件提交到仓库： $ git commit -m “wrote a readme file”[master (root-commit) eaadf4e] wrote a readme file 1 file changed, 2 insertions(+) create mode 100644 readme.txt简单解释一下git commit命令，-m后面输入的是本次提交的说明，可以输入任意内容，当然最好是有意义的，这样你就能从历史记录里方便地找到改动记录。 嫌麻烦不想输入-m “xxx”行不行？确实有办法可以这么干，但是强烈不建议你这么干，因为输入说明对自己对别人阅读都很重要。实在不想输入说明的童鞋请自行Google，我不告诉你这个参数。 git commit命令执行成功后会告诉你，1 file changed：1个文件被改动（我们新添加的readme.txt文件）；2 insertions：插入了两行内容（readme.txt有两行内容）。 为什么Git添加文件需要add，commit一共两步呢？因为commit可以一次提交很多文件，所以你可以多次add不同的文件，比如： $ git add file1.txt$ git add file2.txt file3.txt$ git commit -m “add 3 files.” 版本回退现在我们已经提交了一个文件，接着修改文件在文件第二行插入hello china 然后运行git status 123456789101112Administrator@2013-20181114VC MINGW64 ~/Desktop/gitxuexi (master)$ git statusOn branch masterChanges to be committed: (use &quot;git reset HEAD &lt;file&gt;...&quot; to unstage) modified: test.txtAdministrator@2013-20181114VC MINGW64 ~/Desktop/gitxuexi (master)$ git commit -m &apos;第二次提交&apos;[master eef364a] 第二次提交 1 file changed, 2 insertions(+), 1 deletion(-) 会提示修改文件 然后再次提交说明第二次提交 git status就是查看仓库当前的状态，当没有文件修改或修改已全部提交时，运行这个命令Git会告诉我们当前没有需要提交的修改，而且，工作目录是干净（working tree clean）的。 接下来，我想要回到第一次提交的版本，也就是文本里面只有hello world。 我们使用git log命令查看历史记录： git log命令显示从最近到最远的提交日志，我们可以看到3次提交，最近的一次是append GPL，上一次是add distributed，最早的一次是wrote a readme file。commit 后面跟的一串长字符就是那一次提交的id 如果嫌输出信息太多，看得眼花缭乱的，可以试试加上--pretty=oneline参数。 现在我们准备回到第一个版本，在git中，用HEAD表示当前版本，也就是最新提交的 eef364…，上一个版本就是HEAD^ 上上个版本就是HEAD^^ ,当然往上100个版本写100个^比较容易数不过来，所以写成HEAD~100。 现在我们使用git reset命令回到上一版本： 12$ git reset --hard HEAD^HEAD is now at 77b32e4 第一次提交 现在在回去看test.txt可以发现其中的内容果然回到了第一次提交时候的内容 也可以使用git reset --hard eef364命令来回到某一版本。 现在我又想回到第二次提交那个版本怎么办，使用git log命令发现只有第一次提交的记录了。 这时候可以使用git reflog来查看第二次提交的id 然后在使用git reset --hard commit_id来回到第二次提交的版本啦。 工作区和暂存区其实我们执行的git add命令就是把文件提交到了暂存区，工作区就是我们当前所在的目录，暂存区存在git创建的.git版本库中。所以我们Git add之后要使用 git commit命令来吧改动提交到版本库中。 分支管理分支就是在当前主目录上在新拷贝一份，这两份文件互不影响，一个文件被我复制了一份，然后我在复制的文件上进行的修改不会影响源文件。 使用git branch new创建一个分支new，然后在使用git checkout new切换到new分支上，这两个命令也可以合并成git checkout -b new 然后我们现在就处于new分支上，现在在对文件进行任何操作都不会影响主分支master上的文件，我们可以试试：新建一个文本文件test2.txt并运行git add和git commit 命令提交。 然后我使用git checkout master切换到主分支发现在new分支上创建的test2.txt文件不见了。 这个就是分支的基本使用，假如new分支上的东西我都配置好了，我想把它合并到master上： 可以使用git merge 分支名 -m &#39;说明&#39;命令来。这样new分支上的东西就合并到主分支了 然后可以使用git branch -d new来删除new分支啦。 git 连接远程仓库连接远程github仓库，可以吧本地仓库推送到github远程仓库 注册github账号 新建一个仓库 本地运行git bush，使用ssh-keygen -t rsa -C “youremail@example.com”把其中的邮件地址换成自己的邮件地址，然后一路回车(这里的主目录一般是指Administrator目录) 在本地用户主目录下找到.ssh文件夹，把其中的id_rsa.pub添加到github SSH中 运行git remote add origin git@github.com:用户名/仓库名 运行git push -u origin master推送到远程仓库 OK!]]></content>
      <categories>
        <category>日志</category>
      </categories>
      <tags>
        <tag>Git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Flask上传文件]]></title>
    <url>%2F2018%2F11%2F22%2FFlask%E4%B8%8A%E4%BC%A0%E6%96%87%E4%BB%B6%2F</url>
    <content type="text"><![CDATA[介绍上传文件在web中经常用到，本文就介绍在Flask中怎么上传文件！ 方法新建一个Flask项目 在app.py中写路由： 1234567891011121314@app.route('/upload', methods=['GET', 'POST'])def upload(): if request.method == 'GET': return render_template('upload.html') elif request.method == 'POST': file = request.files['file'] print(file.filename) base_path = os.path.dirname(__file__) save_path = os.path.join(base_path, 'static/files/', secure_filename(file.filename)) print(save_path) file.save(save_path) return '上传完成' else: pass 在templates下新建upload.html写一个上传表单 1234&lt;form action="&#123;&#123; url_for('upload') &#125;&#125;" method="post" enctype="multipart/form-data"&gt; &lt;input type="file" name="file"&gt; &lt;input type="submit" value="上传"&gt;&lt;/form&gt; 代码解释app.py:在app.py中写了一个路由用来处理upload的请求，在路由中指明了接收那些请求类型：GET和POST。下面使用了if、else来处理这两个类型的请求，GET请求返回upload.html。post请求就处理上传的文件（保存文件）。 这个POST请求，有很多需要注意的地方。 首先使用了request对象获取用户上传的文件。并赋值给变量file。 然后使用os包来构造一个文件保存路径,base_path使用了os.path.dirname来获取当前文件所在的路径，后面的参数123456789101112131415161718os.path.join的第三个参数本来可以直接使用file.name，但是因为文件名可能会包含特殊字符，所以使用werzeug.uril中的secure_name方法来对文件特殊字符进行转义。最后使用file.save()方法保存用户上传的文件到刚才构造的文件路径中。并返回一个上传完成的信息给用户。## upload.html这个页面就是一个普通的上传文件表单需要注意的就一点，注意需要在表单中声明上传地址、提交请求类型和enctype=”multipart/form-data”。enctype=”multipart/form-data”，上传文件时必须声明，指明了这个表单submit时会上传二进制文件。# 遇到的错误我在学习这个示例的时候，也遇到了很多错误。这些错误大部分都是因为粗心大意，没有深入理解它的原理造成的。下面记录几个容易出错的地方```base_path = os.path.dirname(__file__) 这行代码是为了获取当前文件所在的路径，后面的__file__表示当前这个app.py文件，然后去掉这个文件，就获得了一个基础路径 save_path = os.path.join(base_path, &#39;static/files/&#39;, secure_filename(file.filename)) 这行代码拼装了一个路径来保存文件，需要注意secure_filename(file.filename)使用secure_filename来对文件名转义。 file.filename本质上是request.files[file].filename使用了请求上下文request对象来获取用户上传的文件名。]]></content>
      <categories>
        <category>Flask</category>
      </categories>
      <tags>
        <tag>Flask</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Flask入门]]></title>
    <url>%2F2018%2F11%2F21%2FFlask%E5%85%A5%E9%97%A8%2F</url>
    <content type="text"><![CDATA[介绍Flask是一个使用python编写的轻量级web应用框架。其http部分来自Werkzeug,模板引擎使用jinja2。flask使用简单的核心，用扩展来正价其它功能。flask没有默认使用的数据库、表单工具。 众多的扩展提供了数据库集成、表单验证、上传处理、开放认证技术等功能。flask也许是微小的，但少即是多，它已准备好在需求繁杂的生产环境中投入使用。 其它框架： Django：大而全，最出名的python框架，最出名的是它全自动化的管理后台：只需要使用ORM，做简单的对象定义，他就能自动生成数据库结构、以及全功能的管理后台 web2py：是一个为python语言提供的全功能web应用框架，旨在敏捷快速的开发web应用，具有快速安全以及可一直的数据库驱动的应用。 Tornado：特点是异步web框架，适合做长连接，他不仅是web框架，还是一个web server，同时提供了异步库。 Sanic：他是一个类似flask的异步web框架，基于Python3.5的 async/await 原生异步语法实现的。根据官方文档所说，性能非常高 选择： 综合考虑，我们应该学习的是flask和django框架。一个小而微，一个大而全。但它们两者原理是非常相似的。flask足够流行，通过添加扩展能做复杂的项目，因为其核心简单，适合web学习入门和进阶。掌握了flask在学习其他框架也不是问题。 环境准备1pip install flask 安装flask包 虽然只install flask，但还出现了其它几个包。它们是flask的依赖包，flask的一些功能基于它们。它们的大概作用是： Flask：flask的核心组成 Jinja2：前端模板渲染 MarkupSafe、itsdangerous：安全相关，防CSRF攻击等 pycryptodome: 加密 Werzeug：http封装 flask项目Hello World1234567891011from flask import Flaskapp = Flask(__name__)@app.route('/')def hello() return 'hello world'if __name__ == '__main__' app.run() 这就是最简单的hello world 第一行引入了Flask，第二行实例化Flask并赋值给app，接下来使用装饰器写了一个路由，这个路由表明了处理那些url，路由以’/‘开头。 下面定义了一个视图函数，用来处理URL这个视图函数就是返回hello world。 模板渲染当视图函数需要返回很多内容时，比如返回一个完整的网页，如果再在返回值里面写的话，会很麻烦，这时候就需要引入模板渲染了 123456789from flask import Flask, render_templatesapp = Flask(__name__)@app.route('/')def index(): return render_templates('index.html')if __name__ == '__main__' app.run() render_templates就是引入模板函数，参数是html文件名，html文件放在flask项目目录下的templates文件夹下 这是一个完整的flask项目，static文件夹下放css、js等文件，templates文件夹下放html模板。 传入变量修改上面的代码在函数return后面添加一个变量： 1return render_templates('index.html',user=小花) 在index.html文件中 123&lt;body&gt; &lt;h1&gt;你好：&#123;&#123; user &#125;&#125;&lt;/h1&gt;&lt;/body&gt; 这样前端html就可以使用后端的变量了。运行后会在浏览器上看到：你好：小花 写路由flask提供了url_for函数构造地址，首先在app.py中引入url_for 12345678910111213141516from flask import Flask, url_for, render_template, requestapp = Flask(__name__)@app.route('/')# @app.route('/test') # 多个url指向一个路由def index(): return render_template('index.html')@app.route('/test/&lt;no&gt;')@app.route('/test/', defaults=&#123;'no': '小花'&#125;) # 参数默认值def test1(no): print(no) return f'&lt;h1&gt;HELLO,&#123;no&#125;&lt;h1&gt;' 这里多写了一个路由，在前端页面index 1&lt;h1&gt;&lt;a href="&#123;&#123; 'test' &#125;&#125;"&gt;学习&lt;/a&gt;&lt;/h1&gt; 这里的a标签链接指向了路由test，这时，这个完整的链接是http://127.0.0.1:5000/test(假如flask只监听本地，运行在5000端口)，视图函数test会处理这个请求，返回hello小花，这里是一个变量，是一个可变的url，当输入/test/xxx时就会返回hello,xxx。在视图函数中给了它一个默认值小花，当输入/test/会默认返回hello，小花。 引入css等文件html页面当然少不了css，那么怎么引入css呢？ 12345&lt;head&gt; &lt;meta charset="UTF-8"&gt; &lt;title&gt;学习&lt;/title&gt; &lt;link rel="stylesheet" href="&#123;&#123; url_for('static', filename='test.css') &#125;&#125;"&gt;&lt;/head&gt; 方法是在头部引入css这和我们平时引入css不太一样，这里使用了url_for函数来引入，第一个参数是文件夹名字，第二个参数是css文件键值对形式。这样写，当收到请求的时候，他就会在static文件夹中找到css文件。 总结url_forurl_for函数， 构造url:endpoint端点参数，填写方法名。注意参数对应的是函数名，跟路由的url没关系。 当ip、port发生变化时，不用前端页面 引用css js之类的静态资源。flask框架会对url进行预处理，前端html页面引用资源时不能写成相对路径。前端url_for()返回结果/static/index,css,flask框架内置相关路由。 url_for引用方法时候，参数写方法名，引用css js之类的资源时有两个参数，第一个参数是文件夹名，第二个是filename=文件名 eg. url_for(‘static’, filename=test) 请求上下文、POST请求Flask从客户端收到请求时，要让视图函数能访问一些对象，这样才能处理请求。请求对象就是一个很好的例子，它封装了客户端发送的HTTP请求。要想让视图函数能够访问请求对象，一种直截了当的方式是将其作为参数传入视图函数，不过这会导致应用中的每个视图函数都多出一个参数。除了访问请求对象，如果视图函数在处理请求时还要访问其他对象，情况会变得更糟。为了避免大量可有可无的参数把视图函数弄得一团糟，Flask使用上下文临时把某些对象变为全局可访问。有了上下文，便可以像下面这样编写视图函数： 12345from flask import request@app.route('/')def index():user_agent = request.headers.get('User-Agent')return '&lt;p&gt;Your browser is &#123;&#125;&lt;/p&gt;'.format(user_agent) 注意，在这个视图函数中我们把request当作全局变量使用。事实上，request不可能是全局变量。试想，在多线程服务器中，多个线程同时处理不同客户端发送的不同请求时，每个线程看到的request对象必然不同。Flask使用上下文让特定的变量在一个线程中全局可访问，与此同时却不会干扰其他线程。 在Flask中有两种上下文：应用上下文和请求上下文: 应用上下文：current_app g 请求上下文：request session 这4个变量很有用，今天先研究request这个对象。 request是一个请求对象，它封装了客户端发出的HTTP请求中的内容： 有了这些属性和方法，我们就能做很多事情了。 eg. 写一个路由处理表单和POST请求 app.py 12345678910111213141516171819@app.route('/post', methods=['GET', 'POST'])def post(): if request.method == 'GET': return render_template('post.html') elif request.method == 'POST': args = request.args form = request.form username = form['user_name'] password = form['phone_number'] var = form['var'] print(username, password, var) print(type(form)) print(args) page = args['page'] print(page) # print(args['cat']) return "&lt;h1'&gt;你好，崽种&lt;/h1&gt;" else: pass post.html 1234567891011121314body&gt; &lt;div class="form1"&gt; &lt;form action="&#123;&#123; url_for('post',page=1,cag='sport') &#125;&#125;" method="post"&gt; &lt;p&gt;姓名:&lt;/p&gt; &lt;input type="text" name="user_name" placeholder="Input your name"&gt; &lt;p&gt;手机号:&lt;/p&gt; &lt;input type="text" name="phone_number" placeholder="Input your phone number"&gt; &lt;p&gt;验证码:&lt;/p&gt; &lt;input type="text" name="var" placeholder="Input validation code"&gt; &lt;input type="submit" value="提交"&gt; &lt;input type="reset" value="重置"&gt; &lt;/form&gt; &lt;/div&gt;&lt;/body&gt; 首先，定义了这个表单提交方式method是POST定义了action提交地址是post路由，并且在这里我设置了一个带参数的url。然后在路由中指明了接收什么样的请求，如果不指明接收POST请求，在表单提交时会出错。 然后，使用了request这个对象的method属性获取请求方式，如果是GET就返回post.html如果是POST请求就返回“你好，崽种”。 在这个POST请求中我使用了request.args来获取请求url中的参数，就是我在上面设置的带参数的url； 然后使用了request.form来获取提交的表单数据。 这里在后台就打印出了url的参数和我提交的数据。 flask的这些上下文对象非常有用，正式有了request这样的上下文对象，我们才能想上面那样写路由和视图函数。 今天仅仅是认识了这些对象，在接下来的学习中，我们还会更加深刻的理解这些对象并掌握它们的用法。 容易出错的地方带参数的url url的？号是参数，匹配的不是路由，在浏览器中输入url在？后面输入参数，参数是键值对的形式，在视图函数中使用request.args可以捕获到这些参数。这点容易迷惑 带参数的路由： 12345@app.route('/x/&lt;test&gt;')@app.route('/x/', defaults=&#123;'test': 'hello'&#125;)def test(test): print(test) return f'&#123;test&#125;:nihao' 这两者很容易迷惑，路由匹配的是url，上面那个匹配的是参数。 带参数的路由在视图函数中必须要接收这个参数。 上面的代码中路由匹配到了127.0.0.1/x/，然后后面的test是路由的参数，下面给了这个参数一个默认值，默认进入到x这个页面携带参数test=hello。 路由的参数和url的参数不一样，url的参数写在？后面，路由的参数些在/后面。 本文参考： 杨铮老师的博客 《Flask Web开发：基于Python的Web应用开发实践(第二版)》——人民邮电出版社]]></content>
      <categories>
        <category>Flask</category>
      </categories>
      <tags>
        <tag>Flask</tag>
        <tag>WEB</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python闭包和装饰器]]></title>
    <url>%2F2018%2F11%2F19%2Fpython%E9%97%AD%E5%8C%85%E5%92%8C%E8%A3%85%E9%A5%B0%E5%99%A8%2F</url>
    <content type="text"><![CDATA[闭包返回函数函数作为返回值 告诫函数除了可以接受函数作为参数外，还可以吧函数作为结果值返回。 定义一个可变参数的求和： 12345def calc_sum(*args): ax = 0 for n in args: ax = ax + n return ax 但是如果不需要立即求和，而是在后面的代码中，根据需要在计算怎么办？可以不返回求和的结果，而是返回求和的函数： 1234567def lazy_sum(*args): def sum(): ax = 0 for n in args: ax = ax +n return ax return sum 当我们调用lazy_sum时，返回的并不是求和结果，而是求和函数： 123&gt;&gt;&gt; f = lazy_sum(1, 3, 5, 7, 9)&gt;&gt;&gt; f&lt;function lazy_sum.&lt;locals&gt;.sum at 0x101c6ed90&gt; 调用函数f时，才真正计算求和的结果： 12&gt;&gt;&gt; f()25 在这个例子中，我们在lazy_sum中又定义了函数sum，并且，内部函数sum可以引用外部函数lazy_sum的参数和局部变量，当lazy_sum函数返回sum时，相关函数和变量都保存在函数中，这种称为‘’闭包“的程序结构拥有极大的为例。 请再注意一点，当我们调用lazy_sum()时，每次调用都会返回一个新的函数，即使传入相同的参数： 1234&gt;&gt;&gt; f1 = lazy_sum(1, 3, 5, 7, 9)&gt;&gt;&gt; f2 = lazy_sum(1, 3, 5, 7, 9)&gt;&gt;&gt; f1==f2False f1()和f2()的调用结果互不影响。 返回的函数在其定义内部引用了局部变量args，所以，当一个函数反悔了一个函数后，其内部的变量还能被新函数引用，所以，闭包用起来简单，实现起来可不容易。 另一个需要注意的问题是，返回的函数并没有被立刻执行，而是直到调用了f()才执行。我们来看一个例子： 123456789def count(): fs = [] for i in range(1,4): def f(): return i*i fs.append(f) return fs f1,f2,f3 = count() 直接打印f1/f2/f3得到的是一个返回函数对象，需要调用这个函数才能够获取到值。 还有一点，按理来说这个函数最终的返回值应该是1,4,9但实际结果却是9。 原因就在于返回的函数引用了变量 i，但并没l立即执行。等到3个函数都返回时，他们所引用的变量 i 已经变成了3，因此最终结果为9。 返回闭包时牢记一点：返回函数不要引用任何循环变量，或者后续会发生变化的变量。 如果一定要引用循环变量怎么办？方法是再创建一个函数，用该函数的参数绑定循环变量当前的值，无论该循环变量后续如何更改，已绑定到函数参数的值不变： 123456789def conut(): def f(j): def g(): return j*j return g fs = [] for i in range(1,4): fs.append(i) return fs 匿名函数当我们再传入函数式，有些时候，不需要显式地定义函数，直接传入匿名函数更方便。 匿名函数关键字lambda，匿名函数有个限制，就是只能有一个表达式，不用写return，返回值就是该表达式的结果。 12def f(x): return x*x 匿名函数lambda x:x * x就相当于f(x)函数 用匿名函数有个好处，因为函数没有名字，不必担心函数名冲突。此外，匿名函数也是一个函数对象，也可以把匿名函数赋值给一个变量，再利用变量来调用该函数: 123f = lambda x :x * xf(5)→25 同样的也可以把匿名函数作为返回值返回 12def build(x,y): return lambda: x * x + y * y 装饰器由于函数也是一个对象，而且函数对象可以被赋值给其它变量，所以，通过变量也能调用该函数。 12345def now(): print('2018-3-25')f = nowf()→2018-3-25 函数对象有一个1234```pythonnow.__name__&apos;now 现在假设我们要增强now()函数的功能，比如，在函数调用前后自动打印日志，但又不希望修改now()函数的定义，这种在代码运行期间动态增加功能的方式，称之为装饰器 本质上，装饰器就是一个返回函数的高阶函数。所以，我们要定义一个能打印日志的装饰器，可以定义如下 123456789def log(func): def wrapper(*args,**kw): print('call %s():' % func.__name__ ) return func(*args,**kw) return wrapper # 终于明白了func(*args, **kw)是什么意思了：# log函数接受一个函数作为参数，然后在内部调用这个函数，并添加想应功能# func(*args, **kw)其实相当于now()，之所以这样写，是因为函数有可能是会变的，这样写，这个函数就可以接收有任何参数的函数了。 理解装饰器12345678# 理解：函数的装饰器其实就是在一个函数外又写了一个函数，比如上面的now函# 数的装饰器，我们需要对这个函数添加功能()，而又不想修改now()函数内部，# 这时，我们就可以写一个装饰器，装饰器的内部是wrapper()，这个函数可以# 接受任何参数，然后在wrapper()函数内部添加我们想要实现的新功能，即打印# 函数日志，然后这个函数的返回值调用now()函数。# 为了下面调用方便，我们把它又加上了一层函数封装log()，这样在下面的函数# 定义时前面加上@log在调用的时候即默认调用了装饰器，实际上我们在调用now# 函数的时候调用的是log()函数的内部。 观察上面的log，因为它是一个装饰器，所以接受一个函数作为参数，并返回一个函数。我们要借助python的@语法，把装饰器至于函数的定义处： 123@logdef now(): print('2018-3-25') 嗲用now()函数，不仅会运行函数本身，还会在运行now()函数前打印一行日志： 123&gt;&gt;&gt; now()call now():2015-3-25 把@log放到now()函数的定义处，相当于执行了语句： 1now = log(now) 由于log()是一个装饰器，返回一个函数，所以，原来的now()函数仍然存在，只是现在同名的now变量指向了新的函数，于是调用now()将执行新函数，即在log()函数中返回的wrapper()函数。 wrapper()函数的参数定义是(*args,**kw)，因此，wrapper()函数可以接受任意参数的调用。在wrapper()函数内，首先打印日志，再接着调用原始函数。 如果装饰器本身需要传入参数，那就需要一个返回解释器的高阶函数，写出来会更复杂。比如要自定义log的文本： 1234567def log(text): def decorator(func): def wrapper(*args, **kw): print('%s %s():' % (text, func.__name__)) return func(*args, **kw) return wrapper return decorator 这个3层嵌套的decorator用法如下： 123@log('execute')def now(): print('2015-3-25') 执行结果如下： 123&gt;&gt;&gt; now()execute now():2015-3-25 和两层嵌套的decorator相比，3层嵌套的效果是这样的： 1&gt;&gt;&gt; now = log('execute')(now) 我们来剖析上面的语句，首先执行log(‘execute’)，返回的是decorator()函数，再调用返回的函数，参数是now函数，返回值最终是wrapper函数。 以上两种装饰器的定义都没有问题，但还差最后一步。因为我们讲了函数也是对象，它有1234```python&gt;&gt;&gt; now.__name__&apos;wrapper&apos; 因为返回的那个wrapper()函数名字就是wrapper，所以，需要把原始函数的__name__等属性复制到wrapper()函数中，否则，有些依赖函数签名的代码执行就会出错。 不需要编写wrapper.__name__ = func.__name__这样的代码，Python内置的functools.wraps就是干这个事的，所以，一个完整的decorator的写法如下： 12345678import functoolsdef log(func): @functools.wraps(func) def wrapper(*args, **kw): print('call %s():' % func.__name__) return func(*args, **kw) return wrapper 或者针对带参数的decorator： 12345678910import functoolsdef log(text): def decorator(func): @functools.wraps(func) def wrapper(*args, **kw): print('%s %s():' % (text, func.__name__)) return func(*args, **kw) return wrapper return decorator]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>学习</tag>
        <tag>笔记</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[hexo重新部署]]></title>
    <url>%2F2018%2F11%2F15%2Fhexo%E9%87%8D%E6%96%B0%E9%83%A8%E7%BD%B2%2F</url>
    <content type="text"><![CDATA[前言：昨天换了电脑，原电脑里很多重要的文件资料都要重新弄，很烦！最重要的是我的博客啊，苦心经营了那么久的博客，难道就因为换了电脑没有了？然后我就在百度上找怎么重新部署、继续维护博客的方法。找了半天都没有找到有效可行的方法，大部分都是说从github上下载项目，创建分支什么的，我觉得还是很麻烦。终于，我在简书上面找到了最佳答案： 具体操作复制原博客为了方便，直接把原博客的所有文件直接复制。 环境部署 安装git，可以从git官网上下载git 打开git bash，设置用户名称和邮件地址 12$ git config --global user.name &quot;username&quot;$ git config --global user.email &quot;username@example.com&quot; 在用户主目录下运行：ssh-keygen -t rsa -C “youremail@example.com” 把其中的邮件地址换成自己的邮件地址，然后一路回车(这里的主目录一般是指Administrator目录) 最后完成后，会在用户主目录下生成.ssh目录，里面有id_rsa和id_rsa.pub两个文件，这两个就是SSH key密钥对，id_rsa是私钥，千万不能泄露出去，id_rsa.pub是公钥，可以放心地告诉任何人。 登陆GitHub，打开「Settings」-&gt;「SSH and GPG keys」，然后点击「new SSH key」，填上任意Title，在Key文本框里粘贴公钥id_rsa.pub文件的内容（千万不要粘贴成私钥了！），最后点击「Add SSH Key」，你就应该看到已经添加的Key。 安装node.js(从官网上下载)这里有两个版本，一般选择LTS 安装hexo：打开git bash客户端，输入 npm install hexo-cli -g，开始安装hexo 更新博客环境都设置好了之后，到这里一般就没问题了。 把原博客文件复制到新电脑里，然后在这个目录下运行git bash 其它操作都和以前一样了，第一次更新hexo g -d的时候可能会出现一个提示框 输入yes点ok就完事啦！！！]]></content>
      <categories>
        <category>HEXO</category>
      </categories>
      <tags>
        <tag>hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hello World]]></title>
    <url>%2F2018%2F11%2F15%2Fhello-world%2F</url>
    <content type="text"><![CDATA[Hello,this is my blog,i’m Yu deqiang. nice to meet you!]]></content>
      <tags>
        <tag>hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SQL语法]]></title>
    <url>%2F2018%2F11%2F12%2FSQL%E8%AF%AD%E6%B3%95%2F</url>
    <content type="text"><![CDATA[SQL语句对数据库进行操作，我们主要使用的是SQL语句。SQL语句包括最基本的增删改查和高级功能比如各种约束、高级查询等。 创建数据库、表CREATE DATABASE 数据库名 用来创建数据库 CREATE TABLE 表名(字段1 定义类型(长度),字段2 定义类型(长度)) eg.：创建学生库，学生表，有id和name两个字段，类型都为varchar，长度为20，id为主键 12CREATE DATABASE studentsCREATE TABLE students(id VARCHAR(20) PRIMARY KEY,name VARCHAR(20)) 增删改查查询语句：SELECT 字段 FROM 表名 比如从学生表中查询所有学生信息： SELECT * FROM students 在python中，查询语句执行完成后需要使用fetchall或者fetchone来接收这个查询结果，fetchall返回所有数据，fetchone返回一条数据。eg： cursor.excute(“SELECT * FROM students”) data = cursor.fetchall() 这两句话也可以合成一句话： data = cursor.excute(‘SELECT * FROM students’).fetchall() 返回的数据类型是列表嵌套元组形式，可以通过下标访问取值。 SQL SELECT DISTINCT在表中，可能会包含重复值。有时，我们只需要列出不同的值。这是可以使用 SELECT DISTINCT语句。 eg：查询学生表中所有不同的行。 1SELECT DISTINCT * FROM students WHERE 语句如果需要有条件的从表中选取数据，可将WHERE子句添加到SELECT语句： 1SELECT 列名称 FROM 表名称 WHERE 列 运算符 值 下面这些运算符可以在WHERE子句中使用。 操作符 描述 = 等于 &lt;&gt; 不等于 &gt; 大于 &lt; 小于 &gt;= 大于等于 &lt;= 小于等于 BETWEEN 在某个范围内 LIKE 搜索某种模式 注释：在某些版本的 SQL 中，操作符 &lt;&gt; 可以写为 !=。 eg：假如学生列表中有id、年龄、姓名和性别列。我们希望选择性别为男的所有行 1SELECT * FROM students WHERE sex='男' eg:选择所有年龄&gt;10的学生 1SELECT * FROM students WHERE age&gt;10 这里需要提醒一下：当字段值为数字型时，不要使用引号，是字符串是，要使用引号，尽量都使用单引号！和我们学习python的str和int规则一样。 SQL AND&amp;OR 运算符AND和OR运算符用于一个以上的条件对记录进行过滤。 AND和OR可在WHERE子语句中把两个或多个条件结合起来。 如果第一个条件和第二个条件都成立，则AND运算符显示一条记录 如果第一个和第二个条件只要有一个城里，则OR运算符显示一条记录。 AND eg：选择id为1并且name为m4a1的人 1SELECT * FROM students WHERE id=1 AND name='m4a1' OR eg：选择id为1或者name为m4a1的人 1SELECT * FROM students WHERE id=1 OR name='m4a1' AND和OR也可以结合起来组成复杂的表达式： eg：选择id为1或者name为m4a1并且age=10的人 1SELECT * FROM students WHERE (id=1 OR name='m4a1')AND age=10 SQL ORDER BY 语句有时候我们需要对查询返回结果进行排序，在MongoDB中有sort方法，那么在SQL中使用什么呢？ 答案是使用ORDER BY。 ORDER BY语句用于根据指定的列对结果进行排序，默认按照升序进行排序；如果希望按照降序排序，可以使用DESC关键字。 eg：查询所有学生行并以id顺序排序 123SELECT * FROM students ORDER BY id#降序排列可以添加DESC关键字SELECT * FROM students ORDER BY id DESC 增加INSERT INTO 表名(列名1,列名2) VALUES(‘值1’,’值2’) 比如在学生列表中添加一条记录 1INSERT INTO student(id,name) VALUES (1,'aK47') 修改修改使用的是update语句： UPDATE 表名 SET 列名 = 新值 WHERE 列名称 = 某值 列的概念： eg:将学生表中id为1的name改为m4a1 12UPDATE students SET name = 'm4a1' WHERE id = 1UPDATE students SET name = 'scar',id=2 WHERE id = 1#修改多列注意使用,号分割 删除DELETE语句用于删除表中的行： DELETE FROM 表名称 WHERE 列名称 = 值 eg:删除student表id为1的那一行 1DELETE FROM student WHERE id = 1 删除所有行 123DELETE FROM student#或者DELETE * FROM student 高级语法SQL TopTOP子句用于规定要返回的记录的数目。对于拥有很多条记录的大型表来说，TOP子句是非常有用的。 MySQL中的top语法:从学生表中返回10条信息 1SELECT * FROM student LIMIT 10 eg：从students表中选取前两条记录 1SELECT TOP 2 * FROM students eg：从students表中选取50%的记录 1SELECT TOP 50 PERCENT * FROM students SQL LIKELIKE操作符用于在WHERE字句中搜索列中的指定模式。有点像是使用正则筛选数据 eg：我们希望从学生表中选取name以X开始的人： 12SELECT * FROM students WHERE name LIKE 'X%'#%号用于定义通配符（模式中缺少的字母） eg：从学生表中选取name以X结尾的人 1SELECT * FROM students WHERE neme LIKE '%X' eg：从学生表中选取name包含x的人 1SELECT * FROM students WHERE name LIKE '%X%' eg:使用NOT关键字，可以从学生表中选择name不包含x的人 1SELECT * FROM students WHERE name NOT LIKE '%X%' SQL通配符就像是正则表达式的匹配符，在搜索数据库中的数据时，SQL通配符可以替代一个或者多个字符。SQL通配符必须与LIKE运算符一起使用。 在SQL中，可以使用以下通配符： 通配符 描述 % 替代一个或多个字符 _ 仅替代一个字符 [charlist] 字符列中的任何单一字符 [^charlist]或者[!charlist] 不在字符列中的任何单一字符 eg：从学生表中选择name以A或B或C开头的人 1SELECT * FROM students WHERE name LIKE '[ABC]%' eg：从学生表中选择name不以A或B或C开头的人 1SELECT * FROM students WHERE name LIKE '[!ABC]%' SQL IN 操作符IN操作符允许我们在WHERE字句中规定多个值 语法： SELECT * FROM 表名 WHERE 列名 IN (value1,value2,…) eg:从students表中选取name为ak和m4的人 1SELECT * FROM students WHERE name IN ('ak','m4') SQL BETWEEN 操作符BETWEEN 操作符在WHERE子句中使用，作用是选取介于两个值之间的数据范围。这些值可以是数值、文本或者日期。 语法： SELECT * FROM 表名 WHERE 列名 BETWEEN value1 AND value2 eg：从students表中选择id介于5和10之间的人： 1SELECT * FROM students WHERE id BETWEEN 5 AND 10 注意：返回的结果包括5但不包括10 eg：如果要选择上面范围之外的人，可以使用NOT操作符 1SELECT * FROM students WHERE id NOT BETWENN 5 AND 10 SQL Alias（别名）通过使用SQL，可以为列名称和表名称指定别名。 语法：表的别名 1SELECT * FROM 表名 AS 别名 列的别名 1SELECT 列名 AS 别名 FROM 表名 SQL JOINSQL join用于根据两个或多个表中的列之间的关系，从这些表中查询数据。 join和key：有时为了得到完成的结果，我们需要从两个或更多的表中获取结果。我们就需要执行join。 数据库中的表可通过键将彼此联系起来。主键是一个列，在这个列中每一行都是唯一的。在表中，每个主键的值都是唯一的。这样做的目的是在不重复每个表中的所有数据的情况下，把表间的数据交叉捆绑在一起。 请看 “Persons” 表： Id_P LastName FirstName Address City 1 Adams John Oxford Street London 2 Bush George Fifth Avenue New York 3 Carter Thomas Changan Street Beijing 请注意，”Id_P” 列是 Persons 表中的的主键。这意味着没有两行能够拥有相同的 Id_P。即使两个人的姓名完全相同，Id_P 也可以区分他们。 接下来请看 “Orders” 表： Id_O OrderNo Id_P 1 77895 3 2 44678 3 3 22456 1 4 24562 1 5 34764 65 请注意，”Id_O” 列是 Orders 表中的的主键，同时，”Orders” 表中的 “Id_P” 列用于引用 “Persons” 表中的人，而无需使用他们的确切姓名。 请留意，”Id_P” 列把上面的两个表联系了起来。 引用两个表：我们可以通过引用两个表的方式，从两个表中获取数据： eg：上面两张表，加入person是客户表，order是订单表，我们需要查询哪个客户订购了什么： 1SELECT Persons.Lastname,Persons.FirstName,Orders.OrderNo FROM Persons,Orders WHERE Persons.ID_P = Orders.ID_P 结果： LastName FirstName OrderNo Adams John 22456 Adams John 24562 Carter Thomas 77895 Carter Thomas 44678 除了上面的方法，我们也可以使用关键字JOIN来从两个表中获取数据。 如果我们希望列出所有客户的订单，可以使用下面的语句： 1SELECT Persons.LastName,Persons.FirstName,Orders.OrderNo FROM Persons INNER JOIN Orders IN Persons.ID_P ORDER BY Persons.LastName 不同的SQL JOIN:除了我们在上面的例子中实用的INNER JOIN(内连接)，我们还可以使用其他几种链接。 下面列出了您可以使用的 JOIN 类型，以及它们之间的差异。 JOIN: 如果表中有至少一个匹配，则返回行 LEFT JOIN: 即使右表中没有匹配，也从左表返回所有的行 RIGHT JOIN: 即使左表中没有匹配，也从右表返回所有的行 FULL JOIN: 只要其中一个表中存在匹配，就返回行 INNER JOIN在表中存在至少一个匹配时，INNER JOIN关键字返回行 语法： 1SELECT 列名1，列名2 FROM 表名1 INNER JOIN 表名2 ON 表名1.列名1=表名2.列名2 注释：INNER JOIN 和 JOIN 是相同的，SELECT 后面的列名可以是多个来自不同两张表的列名。 LEFT JOINLEFT JOIN 关键字会从左表（表1）那里返回所有航，即使在右表（表2）中没有匹配的行。 语法： 1SELECT 列名1，列名2 FROM 表名1 LEFT JOIN 表名2 ON 表名1.列名1=表名2.列名2 RIGHT JOINRIGHT JOIN 关键字会右表 (table_name2) 那里返回所有的行，即使在左表 (table_name1) 中没有匹配的行。 语法和LEFT JOIN 等一样。 FULL JOIN只要某个表中存在匹配，FULL JOIN 关键字就会返回行。 1234SELECT column_name(s)FROM table_name1FULL JOIN table_name2 ON table_name1.column_name=table_name2.column_name 注释：在某些数据库中， FULL JOIN 称为 FULL OUTER JOIN。 SQL UNION 和 UNION ALL 操作符SQL UNION操作符用于合并两个或多个SELECT语句的结果集。 请注意，UNION内部的SELECT语句必须拥有相同数量的列。列也必须拥有相似的数据类型。同时，每条SELECT语句中的列的顺序必须相同。 语法： 123SELECT 列名 FROM 表1UNIONSELECT 列名 FROM 表2 注释：默认地，UNION 操作符选取不同的值。如果允许重复的值，请使用 UNION ALL。 SQL UNION ALL语法： 123SELECT column_name(s) FROM table_name1UNION ALLSELECT column_name(s) FROM table_name2 复习时请看：W3SCHOOL SELECT INTOSELECT INTO 语句可用于创建表的备份文件。 SELECT INTO 语句从一个表中选取数据，然后把数据插入另一个表中。 SELECT INTO 语句常用于创建表的备份复件或者用于对记录进行存档。 语法：把所有列插入新表： 1SELECT * INTO new_table_name[IN externaldatabase] FROM old_table_name 或者只把希望的列插入新表： 123SELECT column_name(s)INTO new_table_name [IN externaldatabase] FROM old_tablename eg：制作Persons表的备份 1SELECT * INTO Persons_copy FROM Persons IN子句可以用于向另一个数据库表中拷贝表： 1SELECT * INTO Persons IN 'backup.mdb' FROM 如果我们希望拷贝某些列，可以在 SELECT 语句后列出这些域： 123SELECT LastName,FirstNameINTO Persons_backupFROM Persons SQL SELECT INTO实例-带有WHERE子句 我们也可以添加 WHERE 子句。 下面的例子通过从 “Persons” 表中提取居住在 “Beijing” 的人的信息，创建了一个带有两个列的名为 “Persons_backup” 的表： 1234SELECT LastName,FirstnameINTO Persons_backupFROM PersonsWHERE City='Beijing' SQL SELECT INTO 实例-被连接的表 从一个以上的白哦中选取数据也是可以做到的。 下面的例子会创建一个名为 “Persons_Order_Backup” 的新表，其中包含了从 Persons 和 Orders 两个表中取得的信息： 12345SELECT Persons.LastName,Orders.OrderNoINTO Persons_Order_BackupFROM PersonsINNER JOIN OrdersON Persons.Id_P=Orders.Id_P SQL CTEATE DATABASECREATE DATABASE用于创建数据库。 语法： 1CREATE DATABASE 数据库名 SQL CREATE TABLECREATE TABLE 用于创建数据库中的表 语法： 1CREATE TABLE 表名(字段1 数据类型，字段2 数据类型，字段3 数据类型，...) 数据类型（data_type）规定了列可容纳何种数据类型。下面的表格包含了SQL中最常用的数据类型： 数据类型 描述 integer(size)int(size)smallint(size)tinyint(size) 仅容纳整数。在括号内规定数字的最大位数。 decimal(size,d)numeric(size,d) 容纳带有小数的数字。”size” 规定数字的最大位数。”d” 规定小数点右侧的最大位数。 char(size) 容纳固定长度的字符串（可容纳字母、数字以及特殊字符）。在括号中规定字符串的长度。 varchar(size) 容纳可变长度的字符串（可容纳字母、数字以及特殊的字符）。在括号中规定字符串的最大长度。 date(yyyymmdd) 容纳日期。 SQL 约束约束用于限制加入表的数据的类型。 可以在创建表示规定约束（通过CREATE TABLE语句），或者在表创建之后通过（ALERT TABLE语句） 我们将主要探讨以下几种约束： NOT NULL UNIQUE PRIMARY KEY FOREIGN KEY CHECK DEFAULT NOT NULL(非空约束)NOT NULL 约束强制列不接受 NULL 值。 NOT NULL 约束强制字段始终包含值。这意味着，如果不向字段添加值，就无法插入新记录或者更新记录。 eg：创建students表，有3个字段（id,name,sex）并且id，name添加非空约束 1CREATE TABLE students(id INT NOT NULL,name VARCHAR(30) NOT NULL,sex VARCHAR(10) ) UNIQUE(唯一约束)UNIQUE约束唯一标识数据库中的每条记录。 UNIQUE 和 PRIMARY KEY 约束均为列或列集合提供了唯一性的保证，PRIMARY KEY 拥有自动定义的UNIQUE约束。每张表只能有一个PRIMARY KEY约束，但可以有多个UNIQUE约束。 下面的 SQL 在 “Persons” 表创建时在 “Id_P” 列创建 UNIQUE 约束： 123456789CREATE TABLE Persons(Id_P int NOT NULL,LastName varchar(255) NOT NULL,FirstName varchar(255),Address varchar(255),City varchar(255),UNIQUE (Id_P)) 如果需要命名 UNIQUE 约束，以及为多个列定义 UNIQUE 约束，请使用下面的 SQL 语法： 123456789CREATE TABLE Persons(Id_P int NOT NULL,LastName varchar(255) NOT NULL,FirstName varchar(255),Address varchar(255),City varchar(255),CONSTRAINT uc_PersonID UNIQUE (Id_P,LastName)) 当表已被创建时，如需在 “Id_P” 列创建 UNIQUE 约束，请使用下列 SQL： 12ALTER TABLE PersonsADD UNIQUE (Id_P) 如需命名 UNIQUE 约束，并定义多个列的 UNIQUE 约束，请使用下面的 SQL 语法： 12ALTER TABLE PersonsADD CONSTRAINT uc_PersonID UNIQUE (Id_P,LastName) 如果需要撤销UNIQUE约束，使用下面的SQL 1ALTER TABLE Persons DROP INDEX 列名 SQL PRIMARY KEY (主键约束)PRIMARY KEY 约束唯一标识数据库表中的每条记录。 主键必须包含唯一的值。 主键列不能包含 NULL 值。 每个表都应该有一个主键，并且每个表只能有一个主键。 再创建表的时候定义主键约束eg： 123456789CREATE TABLE Persons(Id_P int NOT NULL,LastName varchar(255) NOT NULL,FirstName varchar(255),Address varchar(255),City varchar(255),PRIMARY KEY (Id_P)) 如果需要命名 PRIMARY KEY 约束，以及为多个列定义 PRIMARY KEY 约束，请使用下面的 SQL 语法： 123456789CREATE TABLE Persons(Id_P int NOT NULL,LastName varchar(255) NOT NULL,FirstName varchar(255),Address varchar(255),City varchar(255),CONSTRAINT pk_PersonID PRIMARY KEY (Id_P,LastName)) 如果在表已存在的情况下为 “Id_P” 列创建 PRIMARY KEY 约束，请使用下面的 SQL： 12ALTER TABLE PersonsADD PRIMARY KEY (Id_P) 如果需要命名 PRIMARY KEY 约束，以及为多个列定义 PRIMARY KEY 约束，请使用下面的 SQL 语法： 12ALTER TABLE PersonsADD CONSTRAINT pk_PersonID PRIMARY KEY (Id_P,LastName) 注释：如果您使用 ALTER TABLE 语句添加主键，必须把主键列声明为不包含 NULL 值（在表首次创建时）。 如需撤销 PRIMARY KEY 约束，请使用下面的 SQL： 12ALTER TABLE PersonsDROP PRIMARY KEY FOREIGN KEY(外键约束)一个表中的FOREIGN KEY指向另一个表中的PRIMARY KEY。 让我们通过一个例子来解释外键。请看下面两个表： “Persons” 表： Id_P LastName FirstName Address City 1 Adams John Oxford Street London 2 Bush George Fifth Avenue New York 3 Carter Thomas Changan Street Beijing “Orders” 表： Id_O OrderNo Id_P 1 77895 3 2 44678 3 3 22456 1 4 24562 1 请注意，”Orders” 中的 “Id_P” 列指向 “Persons” 表中的 “Id_P” 列。 “Persons” 表中的 “Id_P” 列是 “Persons” 表中的 PRIMARY KEY。 “Orders” 表中的 “Id_P” 列是 “Orders” 表中的 FOREIGN KEY。 FOREIGN KEY 约束用于预防破坏表之间连接的动作。 FOREIGN KEY 约束也能防止非法数据插入外键列，因为它必须是它指向的那个表中的值之一。 eg:下面的 SQL 在 “Orders” 表创建时为 “Id_P” 列创建 FOREIGN KEY： 12345678CREATE TABLE Orders(Id_O int NOT NULL,OrderNo int NOT NULL,Id_P int,PRIMARY KEY (Id_O),FOREIGN KEY (Id_P) REFERENCES Persons(Id_P)) FOREIGN KEY (列名) REFERENCES 表名(列名) 一个表中的外键是指向另一个表中的主键。 如果需要命名 FOREIGN KEY 约束，以及为多个列定义 FOREIGN KEY 约束，请使用下面的 SQL 语法： 123456789CREATE TABLE Orders(Id_O int NOT NULL,OrderNo int NOT NULL,Id_P int,PRIMARY KEY (Id_O),CONSTRAINT fk_PerOrders FOREIGN KEY (Id_P)REFERENCES Persons(Id_P)) 如果在 “Orders” 表已存在的情况下为 “Id_P” 列创建 FOREIGN KEY 约束，请使用下面的 SQL： 123ALTER TABLE OrdersADD FOREIGN KEY (Id_P)REFERENCES Persons(Id_P) 如果需要命名 FOREIGN KEY 约束，以及为多个列定义 FOREIGN KEY 约束，请使用下面的 SQL 语法： 1234ALTER TABLE OrdersADD CONSTRAINT fk_PerOrdersFOREIGN KEY (Id_P)REFERENCES Persons(Id_P) 如需撤销 FOREIGN KEY 约束，请使用下面的 SQL： 1ALTER TABLE Orders DROP FORENGN KEY fk_perOrders CHECK(范围约束)CHECK约束用于限制列中的值的范围。 如果对单个列定义CHECK约束，那么该列只允许特定的值。 如果对一个表定义CHECK约束，那么此约束会在特定的乐众对值进行限制。 eg：下面的 SQL 在 “Persons” 表创建时为 “Id_P” 列创建 CHECK 约束。CHECK 约束规定 “Id_P” 列必须只包含大于 0 的整数。 123456789CREATE TABLE Persons(Id_P int NOT NULL,LastName varchar(255) NOT NULL,FirstName varchar(255),Address varchar(255),City varchar(255),CHECK (Id_P&gt;0)) 如果需要命名 CHECK 约束，以及为多个列定义 CHECK 约束，请使用下面的 SQL 语法： 123456789CREATE TABLE Persons(Id_P int NOT NULL,LastName varchar(255) NOT NULL,FirstName varchar(255),Address varchar(255),City varchar(255),CONSTRAINT chk_Person CHECK (Id_P&gt;0 AND City='Sandnes')) 如果在表已存在的情况下为 “Id_P” 列创建 CHECK 约束，请使用下面的 SQL： 12ALTER TABLE PersonsADD CHECK (Id_P&gt;0) 如果需要命名 CHECK 约束，以及为多个列定义 CHECK 约束，请使用下面的 SQL 语法： 12ALTER TABLE PersonsADD CONSTRAINT chk_Person CHECK (Id_P&gt;0 AND City='Sandnes') 如需撤销 CHECK 约束，请使用下面的 SQL： 12ALTER TABLE PersonsDROP CHECK chk_Person DEFAULT(默认值约束)DEFAULT 约束用于向列中插入默认值。 如果没有规定其他的值，那么会将默认值添加到所有的新记录。 下面的 SQL 在 “Persons” 表创建时为 “City” 列创建 DEFAULT 约束： 12345678CREATE TABLE Persons(Id_P int NOT NULL,LastName varchar(255) NOT NULL,FirstName varchar(255),Address varchar(255),City varchar(255) DEFAULT 'Sandnes') 通过使用类似 GETDATE() 这样的函数，DEFAULT 约束也可以用于插入系统值： 1234567CREATE TABLE Orders(Id_O int NOT NULL,OrderNo int NOT NULL,Id_P int,OrderDate date DEFAULT GETDATE()) 如果在表已存在的情况下为 “City” 列创建 DEFAULT 约束，请使用下面的 SQL： 12ALTER TABLE PersonsALTER City SET DEFAULT 'SANDNES' 如需撤销 DEFAULT 约束，请使用下面的 SQL： 12ALTER TABLE PersonsALTER City DROP DEFAULT SQL CREATE INDEX 语句CREATE INDEX 语句用于在表中创建索引。在不读取整个表的情况下，索引使数据库应用程序可以更快的查找数据。 您可以在表中创建索引，以便更加快速高效地查询数据。 用户无法看到索引，它们只能被用来加速搜索/查询。 注释：更新一个包含索引的表需要比更新一个没有索引的表更多的时间，这是由于索引本身也需要更新。因此，理想的做法是仅仅在常常被搜索的列（以及表）上面创建索引。 语法： 1CREATE INDEX index_name ON table_name(column_name) 注释：”column_name” 规定需要索引的列。 SQL CREATE UNIQUE INDEX 语法: 在表上创建一个唯一的索引。唯一的索引意味着两个行不能拥有相同的索引值。 12CREATE UNIQUE INDEX index_nameON table_name (column_name) CREATE INDEX 实例 本例会创建一个简单的索引，名为 “PersonIndex”，在 Person 表的 LastName 列： 12CREATE INDEX PersonIndexON Person (LastName) 如果您希望以降序索引某个列中的值，您可以在列名称之后添加保留字 DESC： 12CREATE INDEX PersonIndexON Person (LastName DESC) 假如您希望索引不止一个列，您可以在括号中列出这些列的名称，用逗号隔开： 12CREATE INDEX PersonIndexON Person (LastName, FirstName) SQL 撤销索引、表以及数据库通过使用DROP语句，可以轻松地删除索引、表和数据库。 我们可以使用DROP INDEX命令删除表格中的索引。语法： 1ALTER TABLE table_name DROP INDEX index_name DROP TABLE 语句用于删除表（表的结构、属性以及索引也会被删除）： 1DROP TABLE 表名称 DROP DATABASE 语句用于删除数据库： 1DROP DATABASE 数据库名称 如果我们仅仅需要除去表内的数据，但并不删除表本身，那么我们该如何做呢？ 请使用 TRUNCATE TABLE 命令（仅仅删除表格中的数据）： 1TRUNCATE TABLE 表名称 SQL ALTER TABLE(修改表)ALTER TABLE 语句用于在已有的表中添加、修改或删除列。 添加列如果需要在表中添加列，请使用下列语法： 1ALTER TABLE 表名 ADD 列名 数据类型 也可以在添加列时给定一个默认值 1ALTER TABLE 表名 ADD 列名 数据类型 DEFAULT 'test' 要删除表中的列，请使用下列语法： 12ALTER TABLE 表名 DROP COLUMN 列名 注释：某些数据库系统不允许这种在数据库表中删除列的方式 (DROP COLUMN column_name)。 要改变表中列的数据类型，请使用下列语法： 12ALTER TABLE table_nameALTER COLUMN column_name datatype Persons 表: Id LastName FirstName Address City 1 Adams John Oxford Street London 2 Bush George Fifth Avenue New York 3 Carter Thomas Changan Street Beijing SQL ALTER TABLE 实例现在，我们希望在表 “Persons” 中添加一个名为 “Birthday” 的新列。 我们使用下列 SQL 语句： 12ALTER TABLE PersonsADD Birthday date 请注意，新列 “Birthday” 的类型是 date，可以存放日期。数据类型规定列中可以存放的数据的类型。 新的 “Persons” 表类似这样： Id LastName FirstName Address City Birthday 1 Adams John Oxford Street London 2 Bush George Fifth Avenue New York 3 Carter Thomas Changan Street Beijing 改变数据类型实例现在我们希望改变 “Persons” 表中 “Birthday” 列的数据类型。 我们使用下列 SQL 语句： 12ALTER TABLE PersonsALTER COLUMN Birthday year 请注意，”Birthday” 列的数据类型是 year，可以存放 2 位或 4 位格式的年份。 DROP COLUMN 实例接下来，我们删除 “Person” 表中的 “Birthday” 列： 12ALTER TABLE PersonDROP COLUMN Birthday Persons 表会成为这样: Id LastName FirstName Address City 1 Adams John Oxford Street London 2 Bush George Fifth Avenue New York 3 Carter Thomas Changan Street Beijing SQL AUTO INCREMENT 字段AUTO INCREMENT 会在新记录插入表中时生成一个唯一的数字。 我们通常希望在每次插入新记录时，自动的创建主键字段的值。 我们可以在表中创建一个auto-increment 字段。 eg：下列 SQL 语句把 “Persons” 表中的 “P_Id” 列定义为 auto-increment 主键： 123456789CREATE TABLE Persons(P_Id int NOT NULL AUTO_INCREMENT,LastName varchar(255) NOT NULL,FirstName varchar(255),Address varchar(255),City varchar(255),PRIMARY KEY (P_Id)) MySQL 使用 AUTO_INCREMENT 关键字来执行 auto-increment 任务。 默认地，AUTO_INCREMENT 的开始值是 1，每条新记录递增 1。 要让 AUTO_INCREMENT 序列以其他的值起始，请使用下列 SQL 语法： 1ALTER TABLE Persons AUTO_INCREMENT=100 要在 “Persons” 表中插入新记录，我们不必为 “P_Id” 列规定值（会自动添加一个唯一的值）： 12INSERT INTO Persons (FirstName,LastName)VALUES (&apos;Bill&apos;,&apos;Gates&apos;) 上面的 SQL 语句会在 “Persons” 表中插入一条新记录。”P_Id” 会被赋予一个唯一的值。”FirstName” 会被设置为 “Bill”，”LastName” 列会被设置为 “Gates”。 SQL VIEW（视图）视图是可视化的表。 在SQL中，视图是基于SQL语句的结果集的可视化的表。 就像是通过基于某些条件创建了一张新表，这张新表保存在数据库的view子目录下 视图包含行和列，就像一个真实的表。视图中的字段就是来自一个或多个数据库中的表的真实字段。我们可以向视图添加SQL函数、WHERE以及JOIN语句，我们也可以提交数据，就像这些来自于某个单一的表。数据库的设计和结构不会受到视图中的函数、where或join语句的影响。 SQL CREATE VIEW 语法12CREATE VIEW view_name AS SELECT column_name(s) FROM table_name WHERE condition 视图总是显示最近的数据。每当用户查询视图是，数据库引擎通过使用SQL语句来重建数据。 实例：可以从某个查询内部、某个存储过程内部，或者从另一个视图内部来使用视图。通过向视图添加函数、join等等，我们可以向用户精确的提交我们希望提交的数据。 样本数据库Northwind 拥有一些被默认安装的视图。视图 “Current Product List” 会从 Products 表列出所有正在使用的产品。这个视图使用下列 SQL 创建： 1234CREATE VIEW [Current Product List] ASSELECT ProductID,ProductNameFROM ProductsWHERE Discontinued=No 我们可以查询上面这个视图： 1SELECT * FROM [Current Prodect List] Northwind 样本数据库的另一个视图会选取 Products 表中所有单位价格高于平均单位价格的产品： 1234CREATE VIEW [Products Above Average Price] ASSELECT ProductName,UnitPriceFROM ProductsWHERE UnitPrice&gt;(SELECT AVG(UnitPrice) FROM Products) 我们可以像这样查询上面这个视图： 1SELECT * FROM [Products Above Average Price] 另一个来自 Northwind 数据库的视图实例会计算在 1997 年每个种类的销售总数。请注意，这个视图会从另一个名为 “Product Sales for 1997” 的视图那里选取数据： 1234CREATE VIEW [Category Sales For 1997] ASSELECT DISTINCT CategoryName,Sum(ProductSales) AS CategorySalesFROM [Product Sales for 1997]GROUP BY CategoryName 我们可以像这样查询上面这个视图： 1SELECT * FROM [Category Sales For 1997] 我们也可以向查询添加条件。现在，我们仅仅需要查看 “Beverages” 类的全部销量： 12SELECT * FROM [Category Sales For 1997]WHERE CategoryName='Beverages' 语法讲解：CREATE VIEW 创建视图 AS 根据条件 上面的条件是从Products表中查询ProductID,ProductName字段其实就是一个SQL查询语句，这个AS后面可以跟很多条件，比如我们可以使用join语句从两张表中查询某些字段： 12CREATE VIEW test AS SELECT 列名1,列名2 FROM 表名1 INNER JOIN 表名2 ON 条件#条件比如可以是表1.列名1=表2.列名2 SQL 更新视图(好像没什么用)可以使用下面的语法来更新视图： 12SQL CREATE OR REPLACE VIEW SyntaxCREATE OR REPLACE VIEW 视图名 AS SELECT column_name(s) FROM table_name WHERE condition 现在，我们希望向 “Current Product List” 视图添加 “Category” 列。我们将通过下列 SQL 更新视图： 1234CREATE VIEW [Current Product List] ASSELECT ProductID,ProductName,CategoryFROM ProductsWHERE Discontinued=No SQL 撤销视图您可以通过 DROP VIEW 命令来删除视图。 12SQL DROP VIEW SyntaxDROP VIEW view_name SQL DATE(时间、日期)当我们处理日期时，最难的任务恐怕是确保所插入的日期的格式，与数据库中日期列的格式相匹配。 只要数据包含的只是日期部分，运行查询就不会出问题。但是，如果涉及时间，情况就有点复杂了。 在讨论日期查询的复杂性之前，我们先来看看最重要的内建日期处理函数。 Date函数下面的表格列出了 MySQL 中最重要的内建日期函数： 函数 描述 NOW() 返回当前的日期和时间 CURDATE() 返回当前的日期 CURTIME() 返回当前的时间 DATE() 提取日期或日期/时间表达式的日期部分 EXTRACT() 返回日期/时间按的单独部分 DATE_ADD() 给日期添加指定的时间间隔 DATE_SUB() 从日期减去指定的时间间隔 DATEDIFF() 返回两个日期之间的天数 DATE_FORMAT() 用不同的格式显示日期/时间 SQL Date数据类型MySQL 使用下列数据类型在数据库中存储日期或日期/时间值： DATE - 格式 YYYY-MM-DD DATETIME - 格式: YYYY-MM-DD HH:MM:SS TIMESTAMP - 格式: YYYY-MM-DD HH:MM:SS YEAR - 格式 YYYY 或 YY SQL 日期处理如果不涉及时间部分，那么我们可以轻松地比较两个日期！ 假设我们有下面这个 “Orders” 表： OrderId ProductName OrderDate 1 computer 2008-12-26 2 printer 2008-12-26 3 electrograph 2008-11-12 4 telephone 2008-10-19 现在，我们希望从上表中选取 OrderDate 为 “2008-12-26” 的记录。 我们使用如下 SELECT 语句： 1SELECT * FROM Orders WHERE OrderDate=&apos;2008-12-26&apos; 结果集： OrderId ProductName OrderDate 1 computer 2008-12-26 3 electrograph 2008-12-26 现在假设 “Orders” 类似这样（请注意 “OrderDate” 列中的时间部分）： OrderId ProductName OrderDate 1 computer 2008-12-26 16:23:55 2 printer 2008-12-26 10:45:26 3 electrograph 2008-11-12 14:12:08 4 telephone 2008-10-19 12:56:10 如果我们使用上面的 SELECT 语句： 1SELECT * FROM Orders WHERE OrderDate=&apos;2008-12-26&apos; 那么我们得不到结果。这是由于该查询不含有时间部分的日期。 提示：如果您希望使查询简单且更易维护，那么请不要在日期中使用时间部分！ SQL NULLNULL值是遗漏的未知数据。默认的表的列可以存放NULL值。 NULL如果表中的某个列是可选的，那么我们可以在不向该列添加值的情况下插入新纪录或更新现有的记录。这意味着该字段将以NULL值保存。 NULL值得处理方式与其他值不同。 NULL用作未知的或不是用的值得占位符。 注意：NULL值无法和0比较；他们是不等价的。 SQL 的 NULL值处理： 请看下面的 “Persons” 表： Id LastName FirstName Address City 1 Adams John London 2 Bush George Fifth Avenue New York 3 Carter Thomas Beijing 假如 “Persons” 表中的 “Address” 列是可选的。这意味着如果在 “Address” 列插入一条不带值的记录，”Address” 列会使用 NULL 值保存。 那么我们如何测试 NULL 值呢？ 无法使用比较运算符来测试 NULL 值，比如 =, &lt;, 或者 &lt;&gt;。 我们必须使用 IS NULL 和 IS NOT NULL 操作符。 IS NULL我们如何仅仅选取在 “Address” 列中带有 NULL 值的记录呢？ 我们必须使用 IS NULL 操作符： 12SELECT LastName,FirstName,Address FROM PersonsWHERE Address IS NULL 结果集： LastName FirstName Address Adams John Carter Thomas 提示：请始终使用 IS NULL 来查找 NULL 值。 IS NOT NULL我们如何选取在 “Address” 列中不带有 NULL 值的记录呢？ 我们必须使用 IS NOT NULL 操作符： 12SELECT LastName,FirstName,Address FROM PersonsWHERE Address IS NOT NULL 结果集： LastName FirstName Address Bush George Fifth Avenue SQL NULL函数SQL ISNULL()、NVL()、IFNULL()和COALESCE()函数请看下面的 “Products” 表： P_Id ProductName UnitPrice UnitsInStock UnitsOnOrder 1 computer 699 25 15 2 printer 365 36 3 telephone 280 159 57 假如 “UnitsOnOrder” 是可选的，而且可以包含 NULL 值。 我们使用如下 SELECT 语句： 12SELECT ProductName,UnitPrice*(UnitsInStock+UnitsOnOrder)FROM Products 在上面的例子中，如果有 “UnitsOnOrder” 值是 NULL，那么结果是 NULL。 微软的 ISNULL() 函数用于规定如何处理 NULL 值。 NVL(), IFNULL() 和 COALESCE() 函数也可以达到相同的结果。 在这里，我们希望 NULL 值为 0。 下面，如果 “UnitsOnOrder” 是 NULL，则不利于计算，因此如果值是 NULL 则 ISNULL() 返回 0。 SQL Server / MS Access 12SELECT ProductName,UnitPrice*(UnitsInStock+ISNULL(UnitsOnOrder,0))FROM Products Oracle Oracle 没有 ISNULL() 函数。不过，我们可以使用 NVL() 函数达到相同的结果： 12SELECT ProductName,UnitPrice*(UnitsInStock+NVL(UnitsOnOrder,0))FROM Products MySQL MySQL 也拥有类似 ISNULL() 的函数。不过它的工作方式与微软的 ISNULL() 函数有点不同。 在 MySQL 中，我们可以使用 IFNULL() 函数，就像这样： 12SELECT ProductName,UnitPrice*(UnitsInStock+IFNULL(UnitsOnOrder,0))FROM Products 或者我们可以使用 COALESCE() 函数，就像这样： 12SELECT ProductName,UnitPrice*(UnitsInStock+COALESCE(UnitsOnOrder,0))FROM Products MySQL 数据类型在 MySQL 中，有三种主要的类型：文本、数字和日期/时间类型。 Text 类型： 数据类型 描述 CHAR(size) 保存固定长度的字符串（可包含字母、数字以及特殊字符）。在括号中指定字符串的长度。最多 255 个字符。 VARCHAR(size) 保存可变长度的字符串（可包含字母、数字以及特殊字符）。在括号中指定字符串的最大长度。最多 255 个字符。注释：如果值的长度大于 255，则被转换为 TEXT 类型。 TINYTEXT 存放最大长度为 255 个字符的字符串。 TEXT 存放最大长度为 65,535 个字符的字符串。 BLOB 用于 BLOBs (Binary Large OBjects)。存放最多 65,535 字节的数据。 MEDIUMTEXT 存放最大长度为 16,777,215 个字符的字符串。 MEDIUMBLOB 用于 BLOBs (Binary Large OBjects)。存放最多 16,777,215 字节的数据。 LONGTEXT 存放最大长度为 4,294,967,295 个字符的字符串。 LONGBLOB 用于 BLOBs (Binary Large OBjects)。存放最多 4,294,967,295 字节的数据。 ENUM(x,y,z,etc.) 允许你输入可能值的列表。可以在 ENUM 列表中列出最大 65535 个值。如果列表中不存在插入的值，则插入空值。注释：这些值是按照你输入的顺序存储的。可以按照此格式输入可能的值：ENUM(‘X’,’Y’,’Z’) SET 与 ENUM 类似，SET 最多只能包含 64 个列表项，不过 SET 可存储一个以上的值。 Number 类型： 数据类型 描述 TINYINT(size) -128 到 127 常规。0 到 255 无符号*。在括号中规定最大位数。 SMALLINT(size) -32768 到 32767 常规。0 到 65535 无符号*。在括号中规定最大位数。 MEDIUMINT(size) -8388608 到 8388607 普通。0 to 16777215 无符号*。在括号中规定最大位数。 INT(size) -2147483648 到 2147483647 常规。0 到 4294967295 无符号*。在括号中规定最大位数。 BIGINT(size) -9223372036854775808 到 9223372036854775807 常规。0 到 18446744073709551615 无符号*。在括号中规定最大位数。 FLOAT(size,d) 带有浮动小数点的小数字。在括号中规定最大位数。在 d 参数中规定小数点右侧的最大位数。 DOUBLE(size,d) 带有浮动小数点的大数字。在括号中规定最大位数。在 d 参数中规定小数点右侧的最大位数。 DECIMAL(size,d) 作为字符串存储的 DOUBLE 类型，允许固定的小数点。 * 这些整数类型拥有额外的选项 UNSIGNED。通常，整数可以是负数或正数。如果添加 UNSIGNED 属性，那么范围将从 0 开始，而不是某个负数。 Date 类型： 数据类型 描述 DATE() 日期。格式：YYYY-MM-DD注释：支持的范围是从 ‘1000-01-01’ 到 ‘9999-12-31’ DATETIME() *日期和时间的组合。格式：YYYY-MM-DD HH:MM:SS注释：支持的范围是从 ‘1000-01-01 00:00:00’ 到 ‘9999-12-31 23:59:59’ TIMESTAMP() *时间戳。TIMESTAMP 值使用 Unix 纪元(‘1970-01-01 00:00:00’ UTC) 至今的描述来存储。格式：YYYY-MM-DD HH:MM:SS注释：支持的范围是从 ‘1970-01-01 00:00:01’ UTC 到 ‘2038-01-09 03:14:07’ UTC TIME() 时间。格式：HH:MM:SS 注释：支持的范围是从 ‘-838:59:59’ 到 ‘838:59:59’ YEAR() 2 位或 4 位格式的年。注释：4 位格式所允许的值：1901 到 2155。2 位格式所允许的值：70 到 69，表示从 1970 到 2069。 * 即便 DATETIME 和 TIMESTAMP 返回相同的格式，它们的工作方式很不同。在 INSERT 或 UPDATE 查询中，TIMESTAMP 自动把自身设置为当前的日期和时间。TIMESTAMP 也接受不同的格式，比如 YYYYMMDDHHMMSS、YYMMDDHHMMSS、YYYYMMDD 或 YYMMDD。 暂时先学习到这儿…… 学习]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>数据库</tag>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL使用记录]]></title>
    <url>%2F2018%2F11%2F12%2FMySQL%E4%BD%BF%E7%94%A8%E8%AE%B0%E5%BD%95%2F</url>
    <content type="text"><![CDATA[前言之前已经讲过MySQL的安装，这篇文章主要记录我在使用MySQL时遇到的各种问题和解决方法。 可视化工具的使用Navicat for MySQL是一套管理和开发MySQL的工具，实现了数据库可视化操作，对于新手来说安装一个可视化工具对于学习数据库有很大帮助。 Navicat for MySQL中文版，使用起来很方便。缺点就是这个软件收费，在网上看了一下正版1500；但是，早已经有人破解了这个软件。网上破解的方法有很多，我在这里就介绍一个最简单的方法： 下载链接：https://pan.baidu.com/s/1-6htt3CDzVlEIsurq8_fRw提取码：l6ho使用百度网盘下载上面文件，这里包含了Navicat安装包和破解程序，安装完成Navicat后运行PatchNavicat.exe选择navicat.exe 打开后破解就完成了。 使用安装完成后按照下图连接自己的MySQL 设置好了之后右键刚才新建的连接，然后点击打开连接。 我在做到这一步时出现了错误1251，大致是说不支持什么什么的，然后上网上查了一下，很快找到了解决方法： 在cmd登录到mysql然后执行： 123ALTER USER &apos;root&apos;@&apos;localhost&apos; IDENTIFIED BY &apos;password&apos; PASSWORD EXPIRE NEVER; #修改加密规则 ALTER USER &apos;root&apos;@&apos;localhost&apos; IDENTIFIED WITH mysql_native_password BY &apos;password&apos;; #更新一下用户的密码 FLUSH PRIVILEGES; #刷新权限 password可以修改成任意密码 还有一点要注意的是，在mysql命令行下，这些命令都要以;号结尾。 完成了之后再去Navicat打开连接就可以了 python连接mysql使用python连接mysql要首先下载mysql驱动： 1pip install mysql-connector 然后引入驱动操作mysql吧 12345678910# coding:utf-8__autor__ = 'ym'import mysql.connectorconn = mysql.connector.connect(user='root', password='password', database='test')cursor = conn.cursor()cursor.execute('CREATE TABLE student(id VARCHAR (20)PRIMARY KEY ,NAME VARCHAR (20))')cursor.execute("INSERT INTO test1 (id,name) VALUES ('1', '小绿')")cursor.execute("UPDATE student SET NAME='大蓝' WHERE (id='1')")conn.commit()cursor.close() 在上面的代码中，首先引入驱动 然后创建了连接 再创建了cursor 再执行SQL语句 然后和操作sqlite一样，提交事物，关闭游标。 （mysql语法需要多加练习，初次使用，报了很多错误。。。。准备下次专门写一篇记录mysql语法的文章。）]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>数据库</tag>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[理解HTML和XPath]]></title>
    <url>%2F2018%2F11%2F09%2F%E7%90%86%E8%A7%A3HTML%E5%92%8CXPath%2F</url>
    <content type="text"><![CDATA[HTML我们已经知道HTML是文本标记语言，那么HTML和浏览器有什么样的关系呢？ 当我们在浏览器中输入URL到浏览器显示出页面的过程一般包括四个步骤： 在浏览器输入URL。URL的第一部分(域名，比如baidu.com)用于在网络上找到合适的服务器，而URL以及cookie等其他数据则构成了一个请求，用于发送到那台服务器当中。 服务器端回应，向浏览器发送一个HTML页面。（也有可能发送的是json或者XML格式） 将HTML转换成为浏览器内部的树状表示形式：文档对象模型(Document Object Model,DOM) 基于一些布局规则渲染内部表示，达到我们在浏览器上看到的效果。 下面来看看这些步骤，以及他们所需要的文档表示。 URL对于我们而言，URL分为两个主要部分。第一个部分通过域名系统（DNS）帮助我们在网络上定位合适的服务器。比如挡在浏览器发送https://www.baidu.com/menu/x/xxx/#xx时，将会创建一个对baidu.com的DNS请求，用于确定合适的服务器IP地址，如117.123.42.12。从本质上来看，这个地址被翻译为https://117.123.42.12/menu/x/xxx/#xx。 URL剩余的部分对于服务器端理解请求是什么非常重要。它可能是一张图片、一个文档，或是需要触发某个动作的东西，比如向服务器发送邮件。 HTML文档服务器端读取URL，理解我们的请求是什么，然后回应一个HTML文档。该文档实质上就是一个文本文件，我们可以使用编辑器打开它。和大多数文本文档不同，HTML文档具有万维网联盟指定的格式。当我们在浏览器访问https://www.baidu.com的时候，可以右键选择查看源代码。 树表示法（DOM）每个浏览器都有其复杂的内部数据结构，凭借它来渲染网页。DOM表示法具有跨平台、语言无关性等特点，并且被大多数浏览器支持。 想要在Chrome中查看网页的树表示法，可以选择一个元素然后右键检查。 这个时候我们看到的这个东西就是HTML代码的树表示法。 HTML只是文本，而树表示法是浏览器内存里的对象。 浏览器HTML文本表示和树表示并不是向我们通常在浏览器上看到的那种视图。那么，树表示法是如何映射到我们在浏览器上看到的东西呢？答案就是框模型。正如DOM树元素可以包含其他元素或文本一样，默认情况下，挡在屏幕上渲染时，每个元素的框白哦是同样也都包含其嵌入元素的框表示。从某种意义上来说，我们在浏览器上所看到的是原始HTML文档的二维表示—-树结构也以一种隐藏的方式作为该表示的一部分。 使用XPath选择HTML元素前面已经介绍过XPath的基本语法：链接 在这儿就复习一下： XPath表达式：//标签1[@属性1 = “值”]//标签2[@属性2 = “值”]/…/text() //a[@href]用来选择包含href属性的所有链接， //a[@href = “www.baidu.com&quot;]用来选择href属性为特定值的链接。 不加text()或者@获得的是Element对象，可以对这个对象再次使用XPath，这也就是先抓大再抓小的策略。 提取文本使用text() 提取属性值用@属性 使用*符号来选择指定层级的所有元素 而在Scrapy中，我们在最后还要.extract这个属性才能提取出来元素。 接下来我们学习常见的XPath 重点：前面的XPath学习中我都不知道XPath还有这种语法： 对于大型文档，可能需要编写一个非常大的XPath表达式以访问指定元素。为了避免这一问题，可以使用”//语法”，它可以让你取得某一特定类型的元素，而无需考虑其所在的层次结构。比如，//p将会选择所有的p标签，而//a则会选择所有的链接。 //语法可以在层次结构中的任何地方使用，这非常有用。比如我们想找到div class = “test”下的p标签中的内容，这个div class = “test”下可能还有很多子标签，但我们需要的只是p标签的内容，就可以使用这个语法： //div[@class=”test”]//p/text() 我们也可以选择div test下的子div test1中的所有p标签中的内容 //div[@class=”test”]/div[@class=”test1”]//p/text() 这个语法非常有用，有点相见恨晚的感觉，再写爬虫的时候，经常需要使用XPath来提取有用的信息。这个XPath通常会费好大劲才能分析出来该怎么写，要搞清楚我们需要的信息属于哪个标签，通常在网页源代码中，这种嵌套关系可能有很多层。现在有个这个语法，我们只需要找到包含我们需要的信息的标签，然后直接使用//语法来获得我们需要的标签，这要省不少事。 更加有用的是，它还拥有找到href属性中以一个特定子字符串起始或包含的能力。 //a[starts-with(@href,”http://www&quot;)] //a[contains(@href,”baidu”)] //a[not(contains(@href,”baidu”))] 这些就是XPath的函数，starts-with()函数表示以特定值开头，contains()函数表示属性包含特定值，not(contains())表示不包含某特定值。XPath有很多像这样的函数，可以在百度上找到，不过这些函数不经常使用，记清楚基础的XPath语法才是重中之重。 常见XPath实例有一些XPath表达式，我们将会将常遇到： 获取id为test的h1标签下的span中的text。 //h1[@id=”test”]/span/text() 获取id为toc的div标签内的无序列表中所有的链接 //div[@id=”toc”]/ul//a/@href 获取class属性包含ltr以及class属性包含ltr1的任意元素内所有h1标签下的文本，这两个属性可能在同一个class中，也可能在不同的class中 //*[contains(@class,”ltr”) and contains(@class,”ltr1”)]//h1/text() XPath的contains函数可以让你选择包含指定类的所有元素。 选择class属性值为infobox的表格中的第一张图片的URL。 //table[@class=”infobox”]//img[1]/@src 选择class属性以reflist开头的div标签中所有连接的URL。 //div[starts-with(@class,”reflist”)]//a/@href 选择子元素包含文本test的元素之后的div元素中所有连接的URL //*[text()=”test”]/../following-sibling::div//a 请注意该表达式非常脆弱，并且很容易无法使用，因为他对文档结果做了过多假设。 获取页面中每张图片的URL。 //img/@src 更稳定的XPath我们在抓取网页时，网页经常会发生变化。有时网页结果也会发生变化，因为网站有人在维护。如果他们的HTML已某种方式发生变化时，我们要调整我们的XPath。我们在写XPath时尽量遵循以下原则，帮助我们减少重写XPath的可能性。 避免使用数组索引，例如： //*[@id=”posts”]/article/div/div[1]/p 我们从浏览器中copy出来的XPath中经常会包含大量数字，解决办法是找到一个最接近p标签的标签，找到一个可以使用的包含id或者class属性的元素，如: //div[@class=”post-body”]/p 类并没有那么好用 使用class属性可以更加容易的精确定位元素，不过这些属性一般是用于通过css影响外观的，新词可能会由于网站布局的微小变更而产生变化。 有意义的面向数据的类要比具体的或者面向布局的类更好 我们在使用类选择标签时，首先要选择与内容相关的类，因为这样的类更加可靠。 ID通常是最稳定的 通常情况下，id属性是针对一个目标的最佳选择，因为该属性既有意义又与数据相关。]]></content>
      <categories>
        <category>爬虫</category>
      </categories>
      <tags>
        <tag>爬虫</tag>
        <tag>HTML</tag>
        <tag>XPath</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[日记11.6]]></title>
    <url>%2F2018%2F11%2F06%2F%E6%97%A5%E8%AE%B011-6%2F</url>
    <content type="text"><![CDATA[懒惰和缺乏自控力是我最大的敌人。 我的脑子里只要一有懒惰的想法，那就完蛋啦！！！ 就像上周末一样，周六早上一来，躁动的心就开始无处安放了，就像心里长草了一样。然后周六正好是S8总决赛吗，不知怎么滴，我突然冒出来一个想法：想去找聂辉看总决赛。然后中午还没到吃饭的时候，就下去诳菜市场了。。。然后吃饭的时候，我就觉得今天我在班里坐不下去了。吃完饭就溜了，找个自行车就一路往地铁口奔去。骑一个多小时自行车也丝毫不觉得累，反而觉得很爽！！！回到学校，正好总决赛开始啦，看到IG夺冠那一刻真的挺开心的，怎么说LOL也是陪我度过了那么多时光。虽然有点恨这个游戏，带给我的影响太大了；但还是很开心能看到我们中国赛区的队伍能够拿到S赛总冠军。其实吧，与其说是游戏祸害了我们，不如说我们是自己祸害了自己。游戏没有过错，还是我们自己缺少自制力。原计划是周日晚上按时回寝室的，然后我想周一早上反正九点半才上课，不如周一早上再回去吧，就留了下来。晚上的时候，在425和他们聊天竟然聊到了三点，越聊越有精神，憋了好久突然打开了话匣子，从上这个培训班之后，我好久没有像这样和别人在坐在一起聊天聊这么久了，在培训班里，我估计我给大家的印象就是一个有自闭症的学霸！哈哈哈，我最终变成了自己最讨厌的样子—-在学校的时候，我最讨厌的就是这种人。。。在培训班里，我很少说话，别人跟我说话我也只是随便回答两句，以至于我现在连我右边的同桌是谁都不知道。。。。我佛啦，没想到啊 没想到，我竟然变成了这样子。可能是我真的爱学习吧，哈哈哈！在班里，我现在能叫的上来名字的人不超过十个，我佛了，这都快过去两个月了吧。这也算是一种改变吧，以我的性格，我其实跟什么人都能做朋友，以前每到新环境，总会很快找到新朋友，但是现在，在这里，在我心里，好像暂时还没有能够跟我称得上朋友的人。以前，我吃饭干什么的，甚至上厕所都要别人陪我一起去，现在，我每天都是自己一个人吃饭。我其实觉得这样挺好的，我自己一个人想吃什么就去吃什么，还不用等人，还不用请别人吃饭。哎~扯远了，刚才说到在寝室聊到了三点，大家都聊开心了，我就随便一说：明天上个几把课，不去了！然后。。。。周一早上我跟老师请了个假，又继续睡到了十一点。到了周一晚上我又呆到了八点多，心里差点又萌生出了不去上课的想法。。。。 其实从上次考试之后，我觉得我膨胀了，考了第二名。。。其实我心里觉得我是第一名的，因为我最先交卷，选做题全都作对了，那道最难的编程题好像只有我自己写出来了。结果选择题错了太多，选择题差了十几分…….. 不知怎么的，我真的放松了下来，如果我保持开始的那个劲头继续学的话，估计现在早已把爬虫学完了，这俩星期博客更新的还特别少。我真的不该膨胀，真正的大师永远都怀着一颗学徒的心！真的应该静下心来好好学习啦！争取早点毕业，早点工作，要学的东西还很多，时间真的不是那么充裕，应该争分夺秒来巩固自己所学过的知识，学习新知识。 唉！说起来烦心事真的挺多的，周六那天也是她考试的日子，我在前一天晚上给他打电话，结果人家说不需要。周六那天我发了好几条消息，都不回我，我都不知道发生什么了。那个什么双十一战队也给我退了，说都不说一声。搞得我一脸懵逼，是不是因为我那天没有完成战队任务啊，可是我真的很努力在做了，结果就是找不到，我能有什么办法呢。真想问问他到底怎么了，我一想如果他愿意告诉我的话，早都说了，再说又不是第一次这样对我了，总是突然对我冷落起来，我不都习惯了吗。虽然心里有点生气，有点烦，但是又能怎么办呢。忍着吧，别瞎几把想这些事了，你现在唯一要做的事情就是好好学习，然后找个好工作。可是，我特么要是能随心所欲的控制住自己该干什么不该干什么，还能有这么多烦心事吗。 有时候想想真的觉得这个世界太不公平了，我付出再多可能也不如别人一句话的分量足。心里真的觉得憋屈的慌，唉！没办法没办法没办法啊！ 算了，不想了，努力学习提升自己吧，你若盛开，清风自来！]]></content>
      <categories>
        <category>私密博客</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Hornil StylePix]]></title>
    <url>%2F2018%2F11%2F02%2FHornil-StylePix%2F</url>
    <content type="text"><![CDATA[Hornil StylePix 是一个图片编辑软件，跟ps相比他非常轻量，能够满足平时工作学习使用。安装起来也很方便下载地址 下面是教程 节省时间与直观的用户界面Hornil StylePix具有直观的用户界面。它的目的是调整所选功能简单，方便。即使你没有经验，你可以轻松地学习如何编辑图像和修饰您的照片。因此，Hornil StylePix直观的用户界面减少您的时间工作. 为了更好的速度编辑，Hornil StylePix的设计重点在于轻，功能强大。 Hornil StylePix运行在更少的资源，如网络，书籍和笔记本电脑或虚拟机的图像处理功能全(VMware公司虚拟框，虚拟PC等)的环境。我们一直在努力提高Hornil StylePix性能。 便携式支持 Hornil StylePix是一个轻量级的。一种便携式版本的运行Hornil StylePix从可移动存储设备如USB闪存驱动器，闪存卡，或软盘(媒体)。要安装Hornil StylePix便携式，只要下载便携包，然后解压缩。要启动Hornil StylePix便携，只需双击您的便携dirve StylePix.exe文件。 浏览图片和幻灯片浏览图像工具可以让你轻松地探索开放前的影像图像。你也可以打开，复制，删除和重命名的图像或目录。 幻灯片显示了选择的图片系列是在当前工作的全屏幕模式路径中。 支持的文件格式：JPEG，PNG，GIF等，tif格式和TGA，BMP和旅行商。 方便的工作环境有多个文件可以同时打开工作。打开的图像安排在MDI(多文档界面)的容器标签。 MDI的支持级联，瓷砖垂直，水平平铺，设置图标的安排。 快速的图像切换：画布窗口之间切换，按Ctrl+ Tab键。如果你想回去，按Ctrl+ Shift + Tab键。如果按上述键，切换窗口被弹出。然后，如果你想选择下一个画布，按Tab键。 放大/缩小和全屏幕视图和指南，尺子，电网的支持。标尺，网格和引导帮助您编辑。你可以显示/隐藏这些你需要的。缩略图，直方图和电流波形编辑图像的看法。 直方图显示的图像像素为图形的数量。该图的横轴代表语气和垂直轴代表的数量。 波形显示为一个不同于直方图图形图像的像素数量。 多层及分组支持 层是用于Hornil StylePix分开的画布不同的对象。图层就像是在另一个堆放胶片。每一层都可以有不同的对象。 Hornil StylePix支持四个对象类型(图像，文本和路径形状)和组对象。该组对象包含其他对象。此外，本集团可能包含其他组。您可以使用层管理层次。Hornil StylePix支持混合模式是用于确定如何两层互相融合。在StylePix，您可以使用21种混合模式。 # 选择工具 Hornil StylePix支撑区域如以下选择工具： 自动范围选择和色彩范围选择工具 方形，圆形选取工具 多边形，套索选择工具 您可以通过上述工具的区域选择具有以下模式：新，加，减和相交。 现有的区域选择可以进行修改操作：边界，扩展，合同和柔软性。 50种图像过滤器。颜色调节过滤器：自动水平，自动对比度，自动颜色平衡，级别，曲线，色彩平衡，亮度/对比度，色相/饱和度，伽玛校正，去色，反转，灰度，阈值，量化，直方图均化，色调分离。 锐化和模糊过滤器 像素化滤镜 渲染过滤器 噪声滤波器 扭曲过滤器 卷积过滤器 风格过滤器 形态滤波器 照片增强过滤器 绘图工具Hornil StylePix支持各种绘图工具如画笔，橡皮擦，直线，曲线，喷雾，克隆刷，洪水填充，渐变填充，路径和形状。 你可以画几个选项，比如使用大小，抗锯齿，不透明度和混合模式这些工具不同的照片 文字工具文本工具允许你在画布上键入文本。在文本字符串可以被修改，不仅在正常状态，但也不失旋转对象属性的状态。 变换和对齐转换工具允许你改变选择区域或对象。只有当区域选择启用存在。当变换工具被激活，可以旋转和调整大小。 所选择的对象可以被转换或安排如下命令：水平翻转，垂直翻转，旋转左，右旋转，旋转180度，置于顶层，发送到后，布林茨顶，发送至底部，左对齐，水平居中对齐，右对齐，上对齐，垂直对齐中心，底端对齐，水平居中对齐。 加强和还原工具 在提高工具允许您提高基础上的图像变暗，躲闪，模糊和锐化工具。 减轻(道奇)/变暗(燃烧)工具 模糊/锐化工具 还原工具允许你恢复的图像有划伤或红眼等 尘/点除尘工具 红眼移除工具… 裁剪工具 作物工具用于作物或剪辑图像。它适用于所有的形象，有形及无形的层面。 它提供了一些有用的比例，如4 × 3个半卡预设。预置分为横向和纵向。景观包含了有关设备，预置比如HDTV，宽屏等相反的水平轴垂直轴长，包含肖像肖像中经常使用的预置。如果您选择了预设一，风俗和价值观是汽车setted与高度自动调节或按预定的比例。 多级撤消，重做和行动清单 多级撤消，重做支持：行动清单记得你对我所做的你的形象，让你恢复到任何图像的早期版本。每次你选择，油漆和调整大小等，这些国家的每一个行动中单独列出清单。要恢复到以前的状态的图像，单击操作列表或按Ctrl + z的国家的名称 批处理 批次处理是一个非常有用的工具，过程，改变大小或图像文件类型的重复性等任务。 前缀，后缀和文件名称编号 调整大小，翻转或旋转的多图像 插入一个共同的标志和绘画 一些色彩调整滤镜 以上文章照抄：地址 欢迎抄袭~]]></content>
      <categories>
        <category>日志</category>
      </categories>
      <tags>
        <tag>ps</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL安装]]></title>
    <url>%2F2018%2F11%2F01%2FMySQL%E5%85%A5%E5%9D%91%2F</url>
    <content type="text"><![CDATA[介绍MySQL是当今世界上最流行的开源数据库，我在前面已经学习过非关系型数据库MongoDB。MongoDB的优点是快速、高扩展性，json的存储格式，就像python的字典一样，学习起来比较快；但缺点就是它是非关系型数据库，属于文档型数据库，不支持事物。 所以今天闲了没事就来学学MySQL。 安装与使用安装MySQL的强大在安装时就能体现出来（安装很麻烦。。。） 首先在官网上下载mysql（我这里下载的是最新版的8.0.13版本） 下载好了之后是个zip文件，找个地方解压就好了。 然后在解压后的文件夹里创建my.ini使用notepad++或其它编译器打开并输入以下代码： 123456789101112131415161718[mysql]# 设置mysql客户端默认字符集default-character-set=utf8 [mysqld]# 设置3306端口port = 3306# 设置mysql的安装目录basedir=C:/web/mysql-8.0.13-winx64datadir=C:/web/mysql-8.0.13-winx64/data# 设置 mysql数据库的数据的存放目录，MySQL 8+ 不需要以下配置，系统自己生成即可，否则有可能报错# datadir=C:\\web\\sqldata# 允许最大连接数# max_connections=20# 服务端使用的字符集默认为8比特编码的latin1字符集character-set-server=utf8# 创建新表时将使用的默认存储引擎default-storage-engine=INNODB 需要注意的是basedir和datadir要换成自己的安装目录和data目录。 弄好了之后这个文件夹差不长这样。 接下来就是启动数据库啦。 cmd下切换到到数据库安装目录\bin下： 然后输入如下命令初始化数据库。 1mysqld --initialize --console 注意啦，初始化完成之后这里会生成一个用户名和密码，这个很重要，用户名是root密码就是上面用红框标注的地方，这个一定要记下来，下面会用到。这个xx密码我也是佛了，就是这个东西坑了我半天。 然后输入以下命令，将mysql安装为Windows 服务 123mysqld install #如果出错试试下一个命令mysqld.exe -install mysql 再输入以下命令启动mysql服务 1net start mysql 登录MySQL当MySQL服务已经运行时，输入以下命令登录MySQL 可以先试试mysql -u root不使用密码登录，如果不行再使用: mysql -u root -p 然后输入之前生成的密码。 登录完成之后使用alter user &#39;root&#39;@&#39;localhost&#39; identified by &#39;xxx&#39; PASSWORD EXPIRE NEVER account unlock;修改密码(xxx) 登录成功的界面: -u 就是用户的意思 -p 表示用密码登录 还有一个-h属性，由于在这里mysql服务运行在本地，所以可以忽略 我在这个登录的过程中失败了N次，百度了一大堆没用的东西，当出现错误的时候首先检查mysql服务开启了没有，可以在计算机关机→服务 中查看，确定开启了之后，就别管其他的，一次两次没登进去就多试几次。就是这个密码，太麻烦了，一般都是密码没输对。 xxx就是新密码。一定要用这个命令！！！ 使用操作Mysql使用SQL语句，后面再更新。]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>数据库</tag>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【持续更新】常用知识点]]></title>
    <url>%2F2018%2F10%2F31%2F%E6%8C%81%E7%BB%AD%E6%9B%B4%E6%96%B0%E7%AC%94%E8%AE%B0-1%2F</url>
    <content type="text"><![CDATA[在很多时候，往往最基本最简单的知识能帮上大忙，在这儿就记录下经常用到的小知识点。希望以后再碰到问题的时候能够首先想到使用这些简单的方法来解决！ 字符串相关：我们几乎天天都在跟字符串打交道，字符串应该是python中最常见的数据类型了；但是对于字符串的基本知识掌握的还是不太牢固。 字符串切片字符串切片：切片操作（slice）可以从一个字符串中获取子字符串（字符串的一部分）。我们使用一对方括号、起始偏移量start、终止偏移量end 以及可选的步长step 来定义一个分片。 格式： [start：end:step] • [:] 提取从开头（默认位置0）到结尾（默认位置-1）的整个字符串• [start:] 从start 提取到结尾• [:end] 从开头提取到end - 1• [start:end] 从start 提取到end - 1• [start：end:step] 从start 提取到end - 1，每step 个字符提取一个• 左侧第一个字符的位置/偏移量为0，右侧最后一个字符的位置/偏移量为-1 几个特别的examples 如下： 提取最后N个字符： 123&gt;&gt;&gt; letter = 'abcdefghijklmnopqrstuvwxyz'&gt;&gt;&gt; letter[-3:]'xyz' 从开头到结尾，step为N： 12&gt;&gt;&gt; letter[::5]'afkpuz' 将字符串倒转(reverse)， 通过设置步长为负数： 12&gt;&gt;&gt; letter[::-1]'zyxwvutsrqponmlkjihgfedcba' 字符串常用方法分割： 12345str1 = 'safasf.jpg'alist = str1.split('.')print(alist)&gt;&gt;&gt;['safasf', 'jpg']#split方法的参数是一个字符，它以这个字符为分割点，把字符串分割为两部分，返回一个列表 替换： 12345str1 = 'safasf.jpg'str2 = str1.replace('.', '=')print(str2)&gt;&gt;&gt;safasf=jpg#replace方法接收两个参数，第一个想要替换的字符，第二个是新字符。返回的是字符串。 字符串拼接python列表中的所有值转化为字符串，然后拼接成一个字符串 123ls1 = ['a', 1, 'b', 2]ls2 = [str(i) for i in ls1]ls3 = ''.join(ls2) .join方法遍历列表中的所有项将所有项拼接成一个字符串。 爬虫相关我记得我在写知乎爬虫的时候碰到了问题，就是无论用什么解码得到的都是乱码。后来才知道是Accept-Encoding惹的祸。 Accept-Encoding主要表示浏览器支持的压缩编码有哪些。gzip是压缩编码的一种，deflate是一种无损数据压缩算法。 那浏览器压缩编码跟我们需要的HTML代码有什么关系呢？因为如果这个地段设置成gzip、deflate，那么从服务器返回来的是对应的gzip，deflate压缩的代码，此时没有进行解码，所以会出现乱码的情况，而一些常规浏览器中，从服务器返回对应的gzip、deflate压缩的代码后，浏览器可以自动进行解压缩，忽而不会出现乱码。解决的办法是直接忽略不写此字段或者把此字段值改为”utf-8”，”gbk” 还有一个问题，就是在开启了Fiddler后，所爬取的网址要以具体文件或者“/”结尾，如果没有具体文件，直接写该具体文件的网址即可，比如将要爬取的网址写为“http://news.163.com/16/0825/09/BVA89U500014ESH.html”这种写法是可以的，如果被爬网址是一个文件夹，比如要爬取“http://www.baidu.com”，此时爬取的是一个目录(文件夹)，所以需要以“/”结尾。 在使用requests爬取https网址时，需要添加一个参数： 12import requestshtml = requests.get("https://www.baidu.com" verify=False).content.decode() 就是这个verify，不然会报错。 eval()函数eval()函数十分强大，官方文档解释为：将字符串str当成有效的表达式来求职并返回计算结果。 具体用法请看以下实例 格式化字符串我们平时常用的两种格式化字符串方法： 1234str1 = "test1"print('test %s' % test1)str2 = "test2"print('test&#123;&#125;'.format(str2)) 这两种方法其实在平时使用的时候并没有什么觉得不好，但是当字符串变长，或是变量增加的时候就显得很冗长。好消息是，python3.6开始，有一种新的格式化字符串的方法： 12str3 = "test3"print(f'test&#123;str3&#125;') 这种方法看起来是不是更简洁一点呢。。。赶快用起来吧！ json在写爬虫的时候要经常跟json打交道，json是一种类似python字典的数据。 python中的json模块提供了一种很简单的方式来编码和解码JSON数据。其中两个主要的函数是json.dumps()和json.loads()，要比其他系列化函数库如pickle的接口少得多。下面演示如何将一个Python数据结构转换成 JSON： 123456789import jsondata = &#123; 'name' : 'ACME', 'shares' : 100, 'price' : 542.23&#125;json_str = json.dumps(data) 下面演示如何将一个JSON编码的字符串转回一个python的数据结构： 1data = json.loads(json_str) 如果你要处理的是文件而不是字符串，可以使用json.dump()和json.load()来编码和解码JSON数据，例如： 1234567# Writing JSON datawith open('data.json', 'w') as f: json.dump(data, f)# Reading data backwith open('data.json', 'r') as f: data = json.load(f) 总的来说，python数据转json用json.loads()，数据文件转json用json.load() json转python数据用json.dumps(),json文件转python数据用json.dump() 数据库相关sqlite在sqlite中想要使用变量批量插入数据，可以使用以下方法： 1234567891011121314import sqlite3connect = sqlite3.connect("learn1.db")cursor = connect.cursor()# cursor.execute('CREATE TABLE student1(id VARCHAR (20) PRIMARY KEY ,name VARCHAR(20))')for num1 in range(1, 20): aa = f'test&#123;num1&#125;' cursor.execute("INSERT INTO student1(id,name) VALUES ('&#123;&#125;','&#123;&#125;')".format(num1, aa))# cursor.execute('SELECT name FROM student')x = cursor.fetchall()cursor.close()connect.commit()connect.close() 主要代码就是 123for num1 in range(1, 20): aa = f'test&#123;num1&#125;' cursor.execute("INSERT INTO student1(id,name) VALUES ('&#123;&#125;','&#123;&#125;')".format(num1, aa)) 要注意标点符号的使用，占位符都要加引号，因为占位符也算是一个字符串，不是变量。这里可以使用的方法有两种，一种是%s占位符，一种是{}占位符，还有一种格式化的方法f’{}’在这里不能使用。 Git生成ssh key： 123456789设置git的user name和email：$ git config --global user.name &quot;xxx&quot;$ git config --global user.email &quot;xxx@gmail.com&quot;查看git配置：$git config --lis生成秘钥$ ssh-keygen -t rsa -C &quot;gudujianjsk@gmail.com&quot;按3个回车，密码为空这里一般不使用密钥。最后得到了两个文件：id_rsa和id_rsa.pub 删除远程仓库关联： 1git remote rm origin]]></content>
      <categories>
        <category>日志</category>
      </categories>
      <tags>
        <tag>爬虫</tag>
        <tag>数据库</tag>
        <tag>笔记</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[爬虫开发之requests库]]></title>
    <url>%2F2018%2F10%2F27%2F%E7%88%AC%E8%99%AB%E5%BC%80%E5%8F%91%E4%B9%8Brequests%E5%BA%93%2F</url>
    <content type="text"><![CDATA[介绍​ 我在前面的博客 爬虫入门链接 中已经介绍了python自带的网络库urllib库的基本用法和简单爬虫的基本流程。但是不知道你有没有觉得urllib库有点麻烦，语法臃肿。我今天就来介绍一个更间接地第三方库–requests库。我在第一次遇到requests库之后就果断弃用了urllib，这俩库一比起来高下立判。我曾经问过一个大佬为什么在写爬虫的时候只用requests库？他回答说“人生苦短，为什么不用高效的工具。” ​ requests是python的一个第三方HTTP库，它比python自带的urllib库更加简单、方便和人性化。requests库的作者这样介绍requests：HTTP for humans，这才是给人用的HTTP库。 安装与使用安装可以直接使用pip安装requests: pip install requests 或者手动安装打开：链接 下载到本地后解压，然后找到包含setup.py的文件夹，在此处打开命令行窗口后输入以下命令： python setup.py install 使用​ 使用浏览器来访问网页，看起来只需要输入网址就可以。经过前面的学习，我们知道网页有多种打开方式，最常见的是GET和POST方式。在浏览器里面可以直接通过输入网址访问的页面，就是使用了GET方式。还有一些页面，只能通过从另一个页面单击某个链接或者某个按钮以后跳过来，不能直接通过浏览器输入网址访问，这种网页就使用了POST方式。 GET 方式​ 对于使用GET方式访问的网页，在Python里面可以使用requests的get()方法获取网页的源代码： 1234import requestshtml = requests.get("网址")html_bytes = html.contenthtml_str = html_bytes.decode() ​ 在这四行代码中，第一行导入了requests库，这样代码才能使用。 第二行使用GET方法获取了网页，得到一个Response对象 第三行使用.content属性来显示bytes(字节)类型的网页源代码 第四行使用decode来解码字节。 大部分情况下，这四行代码我一般都合成两行来写： 12import requesthtml_str = request.get("网址").content.decode() 其实在解码的时候，我们会经常遇到很多错误。这个时候首先需要查看源网页的编码方式，一般在网页的头部会表明编码方式。 有时，即使解码方式和源网页保持了一致，还是会出错，比如网页源代码中包含了无法是别的字符。这时可以在decode()时加上第二个参数“ignore”，强制忽略无法识别的字符。 但是，问题往往没有这么简单，有的时候，你解码方式也对了，ignore参数也加了，但解码出来的网页还是一堆乱码。我就遇到过，郁闷了半天，然后一个大佬给我解决了。是因为在设置请求头的时候，请求头里面有一个Accept Encoding属性，他定义了网站接受什么解码方式，把这个属性给删除就行了。注意，这个Accept Encoding属性并不是每个网站都遵守的，所以在出现错误的时候在吧这个属性给删除了。 POST方式网页的访问方式除了GET方式以外，还有POST方式。有一些网页，使用GET和POST方式访问同样的网址，得到的结果是不一样的。还有一些网页，只能使用POST方式访问，如果使用GET方式访问，网站会直接返回错误信息。 POST方法的格式如下： 1234import requestsdata = &#123;'key':'value1', 'key2':'value2'&#125;html_formdata = request.post('网址'.data=data).content.decode() data这个字典的内容需要根据实际情况修改，key和value在不同的网站是不一样的。而做爬虫，构造这个字典是任务之一。 还有一些网址，提交的内容是JSON格式的，因此post()方法的参数需要进行一些修改： 1html_json = requests.post('网址',json=data).content.decode() 这样写代码，request可以自动将字典转换为JSON格式。 关于网页是什么访问方式，可以使用浏览器开发者工具，或者使用Fiddler分析出来。具体方法暂时不讲。 关于请求头​ 我们知道有些网站添加了反爬虫机制，请求头过滤就是最常见的一种发爬虫机制。我在前面的文章中已经介绍过urllib库添加请求头的方法，那么requests库怎么添加请求头呢？很简单，只需要加一行代码： 123headers = &#123;'user-agent':' Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/68.0.3440.106 Safari/537.36'&#125;html = requerst.get('网址', headers=headers).content.decode()#可以看到headers是python的字典形式 我在前面的博客中忘了说，我们在写爬虫的时候最好吧浏览器里面的headers全都添加进去，因为很多网站不是设置一个user-agent就能蒙混过关的。 看到这么多条属性要一个一个手动转换成python的字典形式是不是感到头皮发麻，还好我有神器！ 具体方法在我的:另一篇博客 requests库很强大，我先简单写这么多，等以后用到了再更新！]]></content>
      <categories>
        <category>爬虫</category>
      </categories>
      <tags>
        <tag>爬虫</tag>
        <tag>requests</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[HTML总结]]></title>
    <url>%2F2018%2F10%2F26%2FHTML%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[本篇博客介绍HTML的语法，还包括CSS等。 HTML介绍HTML：超文本标记语言，除了文本，还包括图片、视频、下载文件等内容。 标记语言： 变成有逻辑、变量、ifalse。标记语言相比比较简单，由信息和结构语法组成。 历史和版本xhtml：类似html但语法要求非常严格。 html4：就是我们要学习的内容。 html5：在html4的基础上添加了新功能和新语法。html5兼容html4目前最流行的就是html5 基本语法12345678910&lt;html&gt;&lt;head&gt; &lt;title&gt;helloworld &lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;p&gt;hello&lt;/p&gt; &lt;p&gt;world&lt;/p&gt;&lt;/body&gt;&lt;/html&gt; ## 常用标签： 标签名 用法 html 根标签 head 头部，元信息，引用css、jss和title title 标题 h1-h6 网页内容里的标题。六个级别。数字越大，标题越小 p 段落，输出完会换行。 br /br br/ 都表示换行 b 加粗 i 斜体 strong 加重语气 small 字体变小变细 hr 水平分割线 a 超链接标签 table 表格 img 图片 ul 无序列表 li 列表中的每一项 ol 有序列表 form 表单 select 下拉菜单 option 下拉菜单的每一项 textarea 文本域 submit 提交。会将数据传递到后台 标签嵌套：html标签是可以嵌套的 空元素：标签的内容可以为空。 ！DOCTYPE html：声明html类型，不容易出错，可以不写 meta charset=”UTF-8”元信息，作者，编码提、网页描述 属性和值为了定义标签的功能。 属性attribate:标签里的键值对里的键。 值 value: 标签里的键值对的值。只需要用双引号括起来。 常用属性 属性名 用法 algin 对齐。center,left,right style 样式，值是css语句 title 鼠标在热点区域停留时出现的提示信息。 name 一个标签的别名，可以用来描述标签，name可以重复 id 一个标签的识别符或别名，跟name的区别是不可重复 href 链接地址 target 链接打开方式，默认是self当前标签页打开 blank新标签页打开 src 图片资源地址 width 宽 height 高 action 定义请求地址 input下的 属性type： text 普通的文本输入框 password 密码输入框 radio 单选 checkbox 多选框 placeholder 占位符输出一些提示性信息 label 标签，写在input前面作为信息提示。 CSScss:层叠样式表。对html布局、字体、颜色进行精确的外观控制 语法css表达式实例: header{background-color:”black”} 上面的header是选择器，大括号包住语句块。每一句语句由声明和值构成，值用括号括住，冒号分割，分号结尾。 选择器：选择这句css声明具体作用在html文件的哪个部分。 引用样式的方式： 行内样式：直接写在html标签内的style属性上。 内部像是：css语句写在head标签下的style标签中。 外部样式：css语句写在xxx.css文件当中。link标签，rel目标文件夹种类，href目标文件地址，type文件类型。 优先级：不同引用样式方式作用于同一个标签。 行内样式优先级最高， 其次是内部样式，最后是外部样式 可读性易维护性：行内样式多之后html文件显得混乱 外部样式最易于维护，其次是内部样式，最后是行内样式。 css选择器： 派生选择器。外层的标签包含里层的标签，通过空格表示层级关系。 eg: li strong{color:red;} ID选择器。标签里实现定义好ID值，语法#开头跟ID名字。 eg: secondp{color:red;} 类class选择器。标签里定义好class值。css中语法，开头跟class值。 css常用标签： background 背景相关background-color 定义背景颜色的background-img:url(“”) 背景图片background-repeat:no-repeat; 背景图片是否可重复background-position:top;background-attachment:fixed;background-size:200px 300px;背景图宽高，长度可以是像素px 也可以用百分比 继承： 外层标签如果定义了一个样式，外层标签所包含的标签都会继承这个样式。 子标签重写一个相同的样式，子标签里的定义优先级更高。 盒子模型： padding:内容和边缘的距离 border:边缘，可以定义style、width、color margin:div块距离其他div块边缘的距离。两个div的外边距重合时，以大的为准。]]></content>
      <categories>
        <category>爬虫</category>
      </categories>
      <tags>
        <tag>HTML</tag>
        <tag>前端</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python自动安装第三方包]]></title>
    <url>%2F2018%2F10%2F26%2FPython%E8%87%AA%E5%8A%A8%E5%AE%89%E8%A3%85%E7%AC%AC%E4%B8%89%E6%96%B9%E5%8C%85%2F</url>
    <content type="text"><![CDATA[介绍昨天突然心血来潮想利用我目前学过的知识一个能自动安装python第三方包的小程序。你肯定想问了，我明明有pip可以实现自动安装第三方包了，为什么还要写这么个看似毫无卵用的东西呢？ 我也不知道，就是心血来潮吧。 但是这个小程序还是有好处的: 他首先是从第三方网站下载了第三方包到本地，然后在使用pip install xxxxx.whl在本地安装第三方包，所以更快，成功率更高。 过程步骤 使用爬虫爬取python第三方包网站， 从网站源代码中提取出所有包名字并存入数据库（使用MongoDB） 根据需求从数据库中查询关键字（也就是需要的包名） 根据包名构建get请求 发送get请求，得到文件 引入os包，执行命令os.system(“pip install 包名”) 遇到的问题 在写爬虫的时候，对XPath的使用还不是很清楚，导致我卡在爬虫这一环节很久。 就是提取包名这一行，想了很久。开始我以为像这样写XPath只能获取到网页源代码中第一个包名。原来，在没有指定特殊属性的时候，XPath会返回所有符合条件的信息，就像上面这个XPath，它返回的就是div class=”pylibs”标签下的li标签下的ul标签下的li标签下的a标签的所有文本信息。这句话虽然有点绕，但是没毛病哦铁汁。 在插入数据库的时候，首先要构造一个列表，然后使用for循环把上面提取到的信息（也就是提取到的包名）展开，然后构造字典，再然后将这些字典添加到列表中。最后使用collection.insert_many()插入到数据库中。 从数据库中查询包名，用到的是正则表达式查询（原来我还不会在MongoDB中使用正则查询。）。 这里find查询方法返回的是一个pymongo对象，使用for循环展开。 在数据库中查询到数据之后拿出来构造url，请求这个url的时候才并没有获得二进制文件 找了半天才发现原来从数据库中提取出来的数据有些特殊符号和我们平时使用的不太一样。这个不仔细看真的很难看出来。我发现从数据库中提取出来的数据中的“-”符号似乎短了一点。原来就是这个符号惹的祸。然后我使用了字符串的replace方法把这个符号替换成了正常的样子。 注意：字符串的replace方法并不是能修改源字符，他其实是一个函数，返回值是替换过后的字符串，所以需要用一个变量来接受它。 如何使用环境：需要安装MongoDB数据库。关于MongoDB怎么使用请看:我的另一篇博客 还需要lxml库和requests库。安装lxml库可以参看：另一篇博客 源代码： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455import requestsimport lxml.htmlfrom pymongo import MongoClientimport osclient = MongoClient()database = client['第三方包']collection = database['包名']def spiderdate(): url = "https://www.lfd.uci.edu/~gohlke/pythonlibs/?tdsourcetag=s_pctim_aiomsg" html = requests.get(url).content#获取网页源代码 selector = lxml.html.fromstring(html) content = selector.xpath('/html/body/ul[@class="pylibs"]/li/ul/li/a/text()')#提取包名 idnum = 1 namelist = [] for name1 in content: """构造字典，插入数据库""" namedict = &#123;'id': idnum, 'name': name1&#125; idnum = idnum+1 namelist.append(namedict) collection.insert_many(namelist)def datefind(): uip = input('请输入包名') content = collection.find(&#123;'name': &#123;'$regex': '&#123;&#125;.*?'.format(uip), '$options': 'i'&#125;&#125;, &#123;'_id': 0&#125;) # collection.fin(&#123;'name': &#123;'$regex': 'xxx', '$options' : 'i'&#125;&#125;) for i in content: print(i['name']) print('请根据自己的python版本和windows版本选择合适的安装包')def download(packname): headers = &#123;'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8', 'Accept-Encoding': 'gzip, deflate, br', 'Accept-Language': 'zh-CN,zh;q=0.9', 'Connection': 'keep-alive', 'Host': 'download.lfd.uci.edu', 'Referer': 'https://www.lfd.uci.edu/~gohlke/pythonlibs/', 'Upgrade-Insecure-Requests': '1', 'User-Agent': 'Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/68.0.3440.106 Safari/537.36'&#125; url = "https://download.lfd.uci.edu/pythonlibs/h2ufg7oq/"+packname print(packname) print(url) html = requests.get(url, headers=headers).content#获得文件二进制信息 with open(packname, "wb") as f:#打开文件 f.write(html)#写入二进制 os.system("pip install &#123;&#125;".format(packname))#使用os.system向发送安装指令。num = 1while num &gt; 0: if num == 1: spiderdate() datefind() packname = input('输入包名：') packname = packname.replace("‑", "-") download(packname) else: datefind() packname = input('输入包名：') packname = packname.replace("‑", "-") download(packname) num = num + 1 源代码直接复制到pycharm中，如果我没猜错的话，应该就能正常运行啦！ 总结虽然只有短短的五六十行代码，但这也能算得上是我写的第一个小程序了。收获还是有的呀！ 这五六十行代码就已经让我头皮发麻了，不敢想象以后写那么多代码的样子。]]></content>
      <categories>
        <category>爬虫</category>
      </categories>
      <tags>
        <tag>爬虫</tag>
        <tag>MongoDB</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[XPath学习]]></title>
    <url>%2F2018%2F10%2F24%2FXPath%E5%AD%A6%E4%B9%A0%2F</url>
    <content type="text"><![CDATA[XPath介绍​ XPath（XML Path）是一种查询语言，它在XML( Extensible Markup Language,可标记扩展语言)和HTML的树状结构中寻找节点。形象一点来说，XPath就是一种根据“地址”来”找人“的语言。 ​ 用正则表达式来提取信息，经常会出现不明原因的无法提取想要内容的情况。解决起来很麻烦，需要寻找的内容越复杂，构造正则表达式所需要花费的时间也就越多。而XPath却不一样，熟练使用XPath以后，构造不同的XPath，所需要的时间几乎一样，所以使用XPath从HTML源代码中提取信息可以大大提高效率。 ​ 在Python中，为了使用XPath，需要安装一个第三方库。 安装windows下的安装比较复杂，直接使用pip install lxml会很容易出问题，这是因为lxml的底层时使用C语言实现的，所以计算机上面需要安装Virtual C++运行库。但是即便安装好了运行库，还是有可能出问题。所以我们换一种方法。 打开链接 根据自己计算机的pyhton版本下载对应的whl包。下载完成后吧这个包放到python安装文件夹下的Lib\site-packages文件夹中然后在这个文件夹中打开命令行窗口，运行 pip install 文件名 文件名就是刚才下载的whl文件名，注意，要输入完整文件名包含后缀。 如果使用这种方法还不行的话，那就把whl文件后缀名改成zip然后使用压缩工具进行解压到当前文件夹就可以了。 XPath语法 XPath语句格式 核心思想就是写XPath就是写地址 获取文本： 1//[标签][@属性1=“属性值1”]/标签2[@属性2=“属性值2”]/.../text() 获取属性： 1//[标签][@属性1=“属性值1”]/标签2[@属性2=“属性值2”]/.../@属性n 其中[@属性=“属性值”]不是必须的。它的作用是帮助过滤相同的标签。在不需要过滤相同标签的时候可以省略 标签的选取 1234567891011121314151617181920212223242526import lxml.htmlsource = '''&lt;html&gt; &lt;head&gt; &lt;title&gt;测试&lt;/title&gt; &lt;/head&gt; &lt;body&gt; &lt;div class="useful"&gt; &lt;ul&gt; &lt;li class="info"&gt;我需要的信息1&lt;/li&gt; &lt;li class="info"&gt;我需要的信息2&lt;/li&gt; &lt;li class="info"&gt;我需要的信息3&lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;div class="useless"&gt; &lt;ul&gt; &lt;li class="info"&gt;垃圾1&lt;/li&gt; &lt;li class="info"&gt;垃圾2&lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;/body&gt;&lt;/html&gt;'''selector = lxml.html.fromstring(source)useful = selector.xpath('//div[@class="useful"]/ul/li/text()')#这个时候获取到的是useful标签里的内容 既然是写地址，很多人肯定好奇不是应该写成 /html/body/[@class=”usefli”]/ul/li/text() 实际上这么写也没有错，但是因为我们需要找的是class=”useful”标签里的内容，这个标签在整个HTML代码中已经足够特别了，没有必要再加上html，body标签了，就像我们写快递收货地址一样，没有人会写亚洲，中国，北京。因为大家都知道全世界只有一个北京，在中国。 写XPath最重要的就是找这个标志性的属性值。 那些属性可以省略呢 在上面的代码中因为ul标签本身就没有属性，所以可以省略，那li标签命名有属性为什么也省略了呢？ 这是因为li标签中的属性都一样，全都是li class=”info”所以可以省略 XPath的特殊情况 以相同字符串开头 123456789101112131415161718import lxml.htmlhtml1 = '''&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head lang="en"&gt; &lt;meta charset="UTF-8"&gt; &lt;title&gt;&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;div id="test-1-k"&gt;需要的内容1&lt;/div&gt; &lt;div id="test-2-k"&gt;需要的内容2&lt;/div&gt; &lt;div id="testfault-k"&gt;需要的内容3&lt;/div&gt; &lt;div id="useless"&gt;这是我不需要的内容&lt;/div&gt;&lt;/body&gt;&lt;/html&gt;''' 在上面的HTML代码中，我们需要抓取需要的内容1,2,3,如果不指定div标签的属性，那么就会把不需要的内容也提取出来。但是如果指定了div标签的属性就只能抓取一条信息了。这个时候，就需要用XPath提取所有id以test开头的div标签。 在XPath中，属性以某些字符串开头，可以写为： //标签[starts-with(@属性名,”相同的开头部分”)] 在上面的代码中就可以写成: //div[starts-with(@class,”test”)]/text() 属性值包含相同字符串 寻找属性值包含某些相同字符串的元素时，XPath的写法格式和上面的写法格式是相同的，只不过把关键字starts-with换成了contains。 对XPath返回的对象执行XPath XPath也支持先抓大在抓小，就是先把包含想要的信息的那一大部分内容先使用XPath提取出来，再使用XPath提取一次。 如上面的代码我们下吧div这一部分的标签全部都提取出来 1234selector = lxml.formstring(html1)useful = seletot.xpath('//body')#返回一个列表info_list = useful[0].xpath('div[class="useless"]/text()')print(info_list) 第一个XPath返回的是一个XPath对象在第二次对这个返回对象使用XPath的时候，开头不需要添加斜线，直接以标签名字开始即可。 不同标签下的文字 1234567891011121314151617181920212223242526272829303132html3 = '''&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head lang="en"&gt; &lt;meta charset="UTF-8"&gt; &lt;title&gt;&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;div id="test3"&gt; 我左青龙， &lt;span id="tiger"&gt; 右白虎， &lt;ul&gt;上朱雀， &lt;li&gt;下玄武。&lt;/li&gt; &lt;/ul&gt; 老牛在当中， &lt;/span&gt; 龙头在胸口。 &lt;/div&gt;&lt;/body&gt;&lt;/html&gt;'''#如果使用一般的办法，就会出现获取到的数据不完整的情况selector = lxml.html.fromstring(html3)# content_1 = selector.xpath('//div[@id="test3"]/text()')# for each in content_1:# print(each)# 使用string(.)就可以把数据获取完整data = selector.xpath('//div[@id="test3"]')[0]info = data.xpath('string(.)')print(info) 这段代码其实也是用了先抓大后抓小的方法，先把div标签取出来，但不提取信息，然后在对返回的XPath对象在使用一次XPath，提取这个XPath对象里面的所有字符串。这里用到了一个新的关键字string(.) 使用浏览器开发者工具辅助构造XPath在构造XPath的时候，需要寻找“标志性”的标签。但是网页的源代码往往是混乱的，这个时候依靠肉眼来找就很麻烦了。这时借助开发者工具来构造XPath就能大大提高效率啦！ 打开浏览器，找到我们想要获取的信息 比如我们要获取下图中图片的位置： 鼠标放在图片的位置，然后右键选择检查，就定位到了源代码中图片的位置。 然后右键点击源代码中的位置选择Copy→Copy XPath，然后粘贴下如下： //*[@id=”posts”]/article/div/div[1]/p[1]/a/img 这个XPath写法可以直接被lxml解析。方框中的数字代表这是第几个该标签。如div[1]/p[1]代表这是第一个div标签第一个p标签。这里的数字是从1开始的，可不是像编程语言中从0开始。 这个从浏览器中复制下来的XPath只能获取这一个标签的信息。如果我们想获得这一类标签的信息，例如得到所有图片，就需要将复制下来的XPath作为参考结合网页源代码的结构，手动构造范围更大的更容易读的XPath。]]></content>
      <categories>
        <category>爬虫</category>
      </categories>
      <tags>
        <tag>爬虫</tag>
        <tag>XPath</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Fiddler抓包工具总结]]></title>
    <url>%2F2018%2F10%2F24%2FFiddler%E6%8A%93%E5%8C%85%E5%B7%A5%E5%85%B7%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[前言我们使用计算机上的浏览器或者客户端软件要与外界进行通信，就必然会有数据的发送或接收，有的时候，我们需要对这些传递的数据进行分析，就需要截获这些传递的数据，其中对这些数据进行截获、重发、编辑、转存的过程叫做抓包。在写爬虫的时候，抓包分析用得相对来说也是较多的，要进行抓包，可以通过一些常见的抓包软件来实现，Fiddler就是一种常见的比较好用的抓包软件。 在写爬虫的时候借助Fiddler能够帮你你模拟出最真实的浏览器请求。 什么是FiddlerFiddler是一种常见的抓包分析软件，同时，我们可以利用Fiddler详细的对HTTP请求进行分析，并模拟对应的HTTP请求。目前抓包软件有很多，除了Fiddler之外，常见的还有： 浏览器自带的调试工具，按f12可以调出。缺点：比较轻量，不能支持一些复杂的抓包。 Wireshark，这是一款通用的抓包工具，功能比较齐全，正因为功能比较齐全，所以较为庞大，而我们写爬虫的时候主要是分析HTTP请求，所以这款软件的很多功能用不到。 爬虫和Fiddler的关系​ 网络爬虫是自动爬取网页的程序，在爬取的过程中必然涉及客户端与服务端之间的通信，自然也需要发送一些HTTP请求，并接受服务器返回的结果。在一些复杂的网络请求中，我们很难看到网址的变化规律，这就很难手动构造来请求来自动爬取网页了。 ​ 比如在浏览一些网页是，浏览到最下面的时候会出现一个‘’加载更多“的字样，此时点击就会加载出更多内容，然而我们观察浏览器中的网站并没有变化，便也无法分析出浏览器向服务器发送了什么数据。 ​ 此时可以使用Fiddler进行抓包，并对这些数据进行分析，这样就可以分析出实现”加载更多“的请求了。 安装和使用Fiddler下载地址从官网下载完成后安装，安装完成后打开 字段说明Fiddler想要抓到数据包，要确保Capture Traffic是开启，在File –&gt; Capture Traffic。开启后再左下角会有显示，当然也可以直接点击左下角的图标来关闭/开启抓包功能。Fiddler开始工作了，抓到的数据包就会显示在列表里面，下面总结了这些都是什么意思： Statistics 请求的性能数据分析随意点击一个请求，就可以看到Statistics关于HTTP请求的性能以及数据分析了 ## Inspectors 查看数据内容Inspectors是用于查看会话的内容，上半部分是请求的内容，下半部分是响应的内容： ## AutoResponder 允许拦截指定规则的请求AutoResponder允许你拦截指定规则的求情，并返回本地资源或Fiddler资源，从而代替服务器响应。 看下图5步，我将“baidu”这个关键字与我电脑“f:\Users\YukiO\Pictures\boy.jpeg”这张图片绑定了，点击Save保存后勾选Enable rules，再访问baidu，就会被劫持。AutoResponder有很多匹配规则： 字符串匹配（默认）：只要包含指定字符串（不区分大小写），全部认为是匹配 正则表达式匹配：以“regex:”开头，使用正则表达式来匹配，这个是区分大小写的Composer 自定义请求发送服务器Composer允许自定义请求发送到服务器，可以手动创建一个新的请求，也可以在会话表中，拖拽一个现有的请求Parsed模式下你只需要提供简单的URLS地址即可（如下图，也可以在RequestBody定制一些属性，如模拟浏览器User-Agent）Filters 请求过滤规则Fiters 是过滤请求用的，左边的窗口不断的更新，当你想看你系统的请求的时候，你刷新一下浏览器，一大片不知道哪来请求，看着碍眼，它还一直刷新你的屏幕。这个时候通过过滤规则来过滤掉那些不想看到的请求。勾选左上角的Use Filters开启过滤器，这里有两个最常用的过滤条件：Zone和Host Zone 指定只显示内网（Intranet）或互联网（Internet）的内容： Host 指定显示某个域名下的会话：如果框框为黄色（如图），表示修改未生效，点击红圈里的文字即可Timeline 请求响应时间在左侧会话窗口点击一个或多个（同时按下 Ctrl 键），Timeline 便会显示指定内容从服务端传输到客户端的时间：Fiddler 设置解密HTTPS的网络数据Fiddler可以通过伪造CA证书来欺骗浏览器和服务器。Fiddler是个很会装逼的好东西，大概原理就是在浏览器面前Fiddler伪装成一个HTTPS服务器，而在真正的HTTPS服务器面前Fiddler又装成浏览器，从而实现解密HTTPS数据包的目的。 解密HTTPS需要手动开启，依次点击： Tools –&gt; Fiddler Options –&gt; HTTPS 勾选Decrypt HTTPS Traffic 点击OKFiddler 抓取Iphone / Android数据包请参考我的另一篇博客 Fiddler 内置命令与断点Fiddler还有一个藏的很深的命令框，平时用的时候很容易忽略FIddler断点功能就是将请求截获下来，但是不发送，这个时候你可以干很多事情，比如说，把包改了，再发送给服务器君。还有balabala一大堆的事情可以做，就不举例子了。示例：?&lt;=@selectclsdump 断点命令断点可以直接点击Fiddler下图的图标位置，就可以设置全部请求的断点，断点的命令可以精确设置需要截获那些请求。如下示例：命令：bpafterbpsbpvg / go 本篇博客借鉴了：链接图片也来自：链接]]></content>
      <categories>
        <category>爬虫</category>
      </categories>
      <tags>
        <tag>爬虫</tag>
        <tag>Fiddler</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python爬虫入门]]></title>
    <url>%2F2018%2F10%2F24%2Fpython%E7%88%AC%E8%99%AB%E5%85%A5%E9%97%A8%2F</url>
    <content type="text"><![CDATA[爬虫基础爬虫是什么？爬虫是什么？一个自动化的数据收集程序爬虫分类？四类1.通用爬虫–什么内容都爬，比如搜索引擎，百度谷歌2.聚焦爬虫–爬取特定内容3.增量式爬虫-爬取更新的内容4.深层网络爬虫-爬取提交表单后的数据通用爬虫弊端： 通用搜索引擎返回太多没有用的数据 服务器资源有限，而网络数据资源无限 网络资源多样化，通用爬虫模型无法很好获取。 爬虫不是独立的技术–需要：前端开发基础知识 数据库基础 网络基础 抓包分析能力 爬虫框架 聚焦爬虫介绍：聚焦爬虫是有目的的爬取，可以节省大量的服务器资源和带宽资源，具有很强的实用性。流程：首先聚焦爬虫有一个控制中心，该控制中心负责对整个爬虫系统进行管理和监控，主要包括控制用户交互、初始化爬行器、确定主题、协调各模块之间的工作、控制爬行过程等方面。然后，将初始的URL集合传递给URL队列，页面爬行模块会从URL队列中读取第一批URL列表，然后根据这些URL地址从互联网中进行相应的页面爬取。爬取后，将爬取到的内容船到页面数据库中存储，同时，在爬行过程中，会爬取到一些新的URL，此时，需要根据我们所定的主题使用连接过滤模块过滤掉无关连接，再将剩下来的URL连接根据主题使用链接评价模块或内容评价模块进行优先级的排序。完成后，将新的URL地址传递到URL队列中，供页面爬行模块使用。另一方面，将页面爬取并存放到页面数据库后，需要根据主题使用页面分析模块对爬取到的页面进行页面分析处理，并根据处理结果机那里索引数据库，用户检索对应信息是，可以从索引数据库中进行相应的检索，并得到对应的结果。 网络爬虫可以干什么？ 爬取多站新闻，集中阅读 爬取金融信息，进行投资分析 制作搜索引擎 爬取图片 爬取网站用户公开的信息进行分析 自动去网页广告 爬取用户公开的联系方式 聚焦网络爬虫聚焦网络爬虫，由于其需要有目的的进行爬取，所以对于通用网络爬虫来说，必须要增加目标的定义和过滤机制，具体来说，此时其执行原理和过程需要比通用网络爬虫多出三步，即目标的定义、无关链接的过滤、下一步要爬取的URL地址的选取。常见的网络更新策略有三种：用户体验策略、历史数据策略、聚类分析策略聚类分析可以分解商品之间的共性进行相应的处理，将共性较多的商品聚为一类。在爬虫对网页爬取的过程中，爬虫需要必须需要访问对应的网页，此时，正规的爬虫会告诉网站站长其爬虫身份。网站的管理员则可以通过爬虫告知的身份信息对爬虫的身份进行识别，开发网络爬虫的语言有很多，常见的有python、java、PHP、Node.js、C++、Go语言等。 urllib库Urllib库是Python中的一个功能强大、用于操作URL，并在做爬虫的时候经常要用到的库。URL读取内容有三种方式：read；读取全部并且把内容赋给一个字符串变量、readline读取一行、readlines读取全部并且把内容赋给一个列表变量1234567imoprt urllib.requestfile=urllib.rqquest.urlopen("网址")data=file.read()print(data)#读取网站信息并打印file1 = open('保存路径及地址’,'wb')#将网页信息以网页的形式保存到本地。file1.write(data)#将变量data写入文件中file1.close#关闭文件 除了以上方法之外还可以使用urllib.request里面的urlretrieve()函数直接将对应信息写入本地文件。格式：urllib.request.urlretrieve(url,filename=本地文件地址)。例子:1234567urllib.request.urlretrieve("http://www.baidu.com",filename="D:/a/index.html)# 注：urlretrieve执行的过程中会产生一些缓存，我们要清除这些缓存信息，可以使用urlcleanup()进行清除eg：urllib.request.urlcleanup()# 除此之外urllib中还有一些常见的用法：file.info()#返回与当前环境相关的信息。file表示当前爬取的网页，file=urllib.request.urlopen(网址)flie.getcode()#返回状态码，若返回200为正确。file.geturl()#返回当前爬取的URL地址 url编解码:url标准中只会允许一部分ASCII字符，而其他的一些字符，比如汉字等，是不符合URL标准的。所以如果我们在URL中使用一些其它不符合标准的字符就会出现问题，此时西药进行URL编码方可解决。1234编码:urllib.request.quote()eg:a = urllib.request.quote("http://www.baidu.com")解码：urllib.request.unquote()eg:urllib.request.unquote(a) 浏览器的模拟——Headres属性当遇到无法爬取的网页时会用到headres属性，因为有些网站为了防止别人恶意采集信息进行了一些反爬虫的设置。这时候就可以设置一些Headres信息，模拟成浏览器去访问这些网站，模拟成浏览器可以设置User-Agent信息。获取User-Agent信息：打开任意一个网站F12调出开发者工具network，任意点击一个链接，使网页发生一个动作。观察下方的窗口会出现一些数据，随意点击一个数据在后侧Headres中可以看到对应的头信息，往下拖动，可以找到User-Agent字样的一串信息。例如：User-Agent: Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/68.0.3440.106 Safari/537.36爬虫模拟成浏览器访问页面的设置方法： 方法1,：使用build_opener()修改报头]由于urlopen()不支持一些HTTP的高级功能，所以，我们如果要修改报头，可以使用urllib.request.build_opener()进行eg: 123456import urllib.requesturl="要爬取的网址"headers=("User-Agent","Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/68.0.3440.106 Safari/537.36")opener = urllib.request.build_opener()opener.addheaders = [headers]data = opener.open(url).read() 上述代码中，首先，我们定义了一个变量url存储要爬取的网址，然后在定义一个变量headers存储对应的User-Agent信息，定义的格式为(“User-Agent”,具体信息)，具体信息我们已经从浏览器中获取了，该信息获取一次即可，以后再爬取其他网站的时候可以直接用。然后我们需要使用urllib.request.build_opener()创建自定义的opener对象并赋给变量opener，接下来，设置opener对象的addheaders，即设置对应的头信息，设置格式为：”opener对象名.addheaders=[头信息]”，设置好头信息之后，我们就可以使用opener对象的open()方法打开对应的网址了。此时，打开操作已经是具有头信息的打开操作行为，即会模仿为浏览器去打开，使用格式是：opener对象名.open(url地址)打开后再使用read()方法读取对应数据，并赋给data变量. 方法2：使用add_header()添加报头]import urllib.requesturl=网址req=url.request.Request(url)#创建Request对象并赋给变量reqreq.add.header(‘User-Agent’,’Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/68.0.3440.106 Safari/537.36’)#添加报头信息data=urllib.request.urlopen(req).read()#打开对应网址并读取网页内容赋给data 超时设置有的时候，我们访问一个网页，如果网页长时间未响应，那么系统就会怕短该网页超时了，即无法打开该网页。有的时候，我们需要根据自己的需要来设置超时的时间值。网站反应快就时间值就设置短一点，网站反应慢就设置长一点。eg：将网站超时时间设置为1 12345678import urllib.requestfor i in range(1,100): try: file=urllib.request.urlopen(&quot;http://www.baidu.com&quot;,timeout=1) data=file.read() print(len(data)) except Exception as e: print(&quot;出现异常--&quot;+str(e)) 上述代码循环了99次每次都输出获得数据的长度，执行之后可以发现有几次出现了异常，这是因为我们设置了超时，网站在1秒钟之内没有做出回应的话代码自动判定为超时异常，并输出异常信息。 HTTP协议请求HTTP协议请求主要分为6种类型： GET请求，GET请求会通过URL网址传递信息，可以直接在URL中写上要传递的信息，也可以由表单进行传递。如果使用表单进行传递，表单中的信息会自动转为URL地址中的信息，通过URL地址传递。 POST请求，可以向服务器提交数据，是一种比较主流也比较安全的数据传递方式，比如在登录时，经常使用POST请求发送数据。 PUL请求，请求服务器存储一个资源，通常要制定存储的位置。 DELETE请求，请求服务器删除一个资源 HEAD请求，请求获取对应的HTTP报头信息。 OPTIONS请求，可以获得当前URL所之气的请求类型。 get请求：我们可以构造一个url让代码去获取我们想要的信息。 123456789import urllib.requestkey="aa"url="http://www.baidu.com/s?wd="+key#构造urlreq=urllib.request.Request(url)#创建一个Request对象并赋给reqdata=urllib.request.urlopen(req).read()#获取网页信息并读取出来赋给data变量。print(len(data))file1=open("D:/a1/xx1.html","wb")file1.write(data)#将信息写入xx1.html文件。file1.close() 上述代码有不完善的地方，如果我们要检索的关键词是中文，就会报错。这时就可以用到urllib.request.quote()函数来编码解决。123key="中文"new_key=urllib.request.quote(key)url="http://www.baidu.com/s?wd="+new_key 总结：使用URL请求： 构造URL地址 构造Request对象 打开Request对象。 读取网页内容、将内容写入文件。如果参数中含有中文要使用quote函数对参数来编码。 post请求post请求常用于登录、注册页面 12345678910import urllib.requestimport urllib.parseurl = "http://www.iqianyue.com/mypost/"postdata = urllib.parse.urlencode(&#123;'name':'yudeqiang','pass':'123456'&#125;).encode('utf-8')#将数据使用urlencode编码处理后，使用encode()设置为utf-8编码req = urllib.request.Request(url,postdata)#构建Request对象参数包括url和要传递的数据#添加头信息模拟浏览器进行爬取req.add_header("User_Agent","Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/68.0.3440.106 Safari/537.36")data=urllib.request.urlopen(req).read()print(len(data)) 代理服务器的设置。有时使用同一个ip去爬取同一个网站上的网页，久了之后会被该网站服务器屏蔽，使用代理服务器就可以解决这个问题。eg： 12345678910def user_proxy(proxy_addr,url): import urllib.request proxy = urllib.request.ProxyHandler(&#123;'http':proxy_addr&#125;) opener = urllib.request.build_opener(proxy,urllib.request.HTTPHandler) urllib.request.install_opener(opener) data = urllib.request.urlopen(url).read().decode('utf-8') return dataproxy_addr = "14.215.194.75:34397"data = user_proxy(proxy_addr,"http://www.baidu.com")print(len(data)) 我们首先建立了一个名为use_proxy的自定义函数，该函数主要实现使用代理服务器来爬取某个URL网页的功能。在函数中，我们设置两个形参，第一个形参为代理服务的地址，第二个形参代表要爬取的网页的地址。然后，使用urllib.request.ProxyHandler()来设置对应的代理服务器信息，设置格式为：urllib.request.ProxyHandler({‘http’:代理服务器地址})，接下来，使用urllib.request.build_opener()创建了一个自定义的opener对象，第一个参数为代理信息，第二个参数为urllib.request.HTTPHandler类为了方便，可以使用urllib.request.install_opener()创建全局默认的opener对象，所以下面才可以直接使用urllib.request.urlopen()打开对应网址爬取网页并读取，编码后赋给变量data，最后返回data的值给函数。随后，在函数外设置好对应的代理IP地址，然后嗲用地应以函数use_proxy，并传递两个实参，跟别为使用的代理地址及要爬取的网址。将函数的调用结果直接赋值给变量data，并输出data内容的长度。或者也可以将data的值写进某个文件中存储起来。 DebugLog实战123456import urllib.requesthttphd = urllib.request.HTTPHandler(debuglevel=1)httpshd = urllib.request.HTTPHandler(debuglevel=1)opener = urllib.request.build_opener(httphd,httpshd)urllib.request.install_opener(opener)data=urllib.request.urlopen("http://edu.51cto.com") 如何开启DebugLog？思路如下： 分别使用urllib.request.HTTPHandler()和urllib.request.HTTPSHandler()将debuglevel设置为1 使用urllib.request.build_opener()创建自定义的opener对象，并使用1中设置的值作为默认参数。 用urllib.request.install_opener()创建全局默认的opener对象，这样在使用urlopen()时也会使用我们安装的opener对象 进行后续相应的操作。 异常处理神器——URLError实战程序再执行的过程中，难免会发生异常，常见的异常处理方法是try except1234567import urllib.requestimport urllib.errortry: urllib.request.urlopen("http://ww1w.baidu.com")except urllib.error.URLError as e: print(e.code) print(e.reson)]]></content>
      <categories>
        <category>爬虫</category>
      </categories>
      <tags>
        <tag>爬虫</tag>
        <tag>python</tag>
        <tag>urllib</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[HTTP理论基础]]></title>
    <url>%2F2018%2F10%2F24%2FHTTP%E7%90%86%E8%AE%BA%E5%9F%BA%E7%A1%80%2F</url>
    <content type="text"><![CDATA[HTTP理论基础在学习HTTP协议之前，我们首先需要了解计算机网络体系结构：OSI模型和TCP/IP参考模型，现在主流的计算机网络体系是TCP/IP，而HTTP协议则是TCP/IP应用层的协议，用于获取万维网上的网页信息。也是我们写爬虫必须要了解的协议~ 计算机网络体系结构OSI模型：osi参考模型讲计算机网络分为七层：（从低到高）物理层、数据链路层、网络层、传输层、会话层、表示层、应用层。TCP/IP参考模型：TCP IP 被分为4层模型，分别是：网络接口层、网际层、传输层、应用层。 它把OSI模型的应用层表示层会话层合成应用层、数据链路层和物理层合为网络接口层。 网络接口层：由物理层和数据链路层合并而成。这层定义了与不同的网络进行连接的接口，网络接口层负责吧IP数据包发送到网络传输介质(双绞线、光纤等) 上传输，以及从网络传输介质上接收数据并解封，取出数据包并交给上一层网际层。 网际层：主要功能是负责将数据封装成包，并从源主机发送到目的主机，解决如何进行数据包的路由选择、阻塞控制、网络互连等问题。IP协议：网间互联协议 网际层的核心协议，另外还有一些辅助协议，包括ARP(地址解析协议)、RARP(逆向地址解析协议)、ICMP(网间控制报文协议)以及IGMP(互联网组管理协议)协议等。负责ip数据报在网络间寻址。IP协议可以进行IP数据包的分割与封装，封装前在数据包前加上源主机的ip地址和目的主机的ip地址及其他信息。特点：只提供传输，不负责纠错。ARP:负责将IP地址解析为物理地址，以便按该地址发送和接收数据。RARP:负责将物理地址解析为IP地址。ICMP:用于在主机和路由器之间传递控制消息，指出网络不通、为用户群进行软件升级、共享白板式多媒体应用等，这些情况就是多播。IGMP:负责对IP多播组进行管理，包括多播组成员的加入和删除等。 传输层：负责在源主机和目的主机的应用进程之间提供端到端的数据传输服务。负责数据分段、数据确认、丢失和重传等。 TCP:传输控制协议 是一个可靠的、面向连接的端对端的传输层协议，由TCP提供的连接叫虚连接。在发送方，TCP将用户提交的字节流分割成 若干个数据段并传递给网际层进行打包发送；在接收方，TCP将所接收的数据包重新装配并交付给用户，它通过序列确认及包重发机制解决IP协议传输时的错误 UDP:用户数据报协议 是一个不可靠的、面向无连接的出传输层协议。使用UDP协议发送报文之后无法得知其是否安全到达。UDP协议将可靠性问题交给应用程序来 解决。UDP协议应用于对那些可靠性要求不高，但要求网络延迟较小的场合，如语音和视频数据的传送。 -端口：为了识别传输层之上的各个不同的网络应用进程，传输层引入了端口的概念。要进行网络通信的进程向系统提出申请，系统返回一个唯一的端口号，将 进程和端口号联系在一起，成为绑定。传输层使用其报文头中的端口号，吧收到的数据送到不同的应用程序。端口是一种软件结构，包括一些 数据结构和I/O缓冲区。一些端口经常会被黑客、木马病毒所利用。 应用层：TCPIP的应用层综合了OSI应用层、表示层、以及会话层的功能。应用层为用户的应用程序提供了访问网络服务的能力并定义了不同主机上的应用程序之间交换用户 数据的一系列协议。由于不同的网络对网络服务的需求各不相同，因此应用层协议非常丰富，并且不断有新的协议加入， 应用层的常用协议： 超文本传输协议：HTTP 用于获取万维网上的网页信息 文件传输协议：FTP 用于点对点的文件传输 简单邮件传输协议：SMTP 用于发送邮件以及在邮件服务器之间转发邮件 邮局协议：POP用于重邮件服务器上获取邮件 仿真终端协议：TELNET 用于远程登录到网络主机 域名系统：DNS 域名解析 用于将主机域名解析为IP地址 简单网络管理协议：SNMP 用于从网络设备（路由器、网桥、集线器等）中收集网络管理信息。 TCPIP总结网络体系结构：计算机网络的层次及各层协议和层间接口的集合被称为网络结构IP提供的主要功能：1、寻址与路由2、数据包分割和重组，在数据包前加上源主机和目的主机的IP地址。网络接口层负责吧IP数据包发送到网络传输介质上传输，以及从网络传输介质上接收数据并解析，取出数据包交给网际层，网际层负责将数据封装成包，并从源主机发送到目的主机，解决的是数据包的路由选择、阻塞控制和网络互连等问题传输层负责在源主机和目的主机的应用程序之间提端到端的数据传输服务，负责数据分段、数据确认、丢失和重传等。应用层为用户的应用程序提供了访问网络服务的能力并定义了不同主机的应用程序之间交换用户数据的一系列协议。简单来说就是网络接口层吧数据送到网络传输介质上（网线）再把数据取出交给网际层，网际层封装数据并发送，传输层确保传输的数据是正确的应用层使用传输的各种数据在用户的应用程序上进行数据的交换等。 书上的总结：TCP协议先把数据分成若干数据报，并给每个数据加上一个TCP信封，上面写上数据报的编号，以便在接收端吧数据还原成原来的格式。IP协议把每个TCP信封再套上一个信封，在上面写上接收主机的地址。有了IP信封就可以在物理网络上传送数据。IP协议还具有利用路由算法进行路由选择的功能。这些信封可以通过不同的传输途径（路由）进行传输，由于路径不同以及其他原因，可能出现顺序颠倒、数据丢失、数据重复等问题。这些问题由TCP协议来处理，其具有检查和处理错误的功能，必要时还可以请求发送端重发。因此可以说IP协议负责数据的传输，TCP协议负责数据的可靠传输。 HTTP是应用层的协议，用于获取万维网上的网页信息。当我们浏览器输入百度网址后： 客户端请求：浏览器访问网址 www.baidu.com DNS：找到网址对应的IP地址 HTTP：请求的资源+请求的内容+请求IP地址等。 TCP:HTTP报文拆装成多个TCP报文，TCP报文按照三次握手可靠的传输。 IP：网络传输过程中 选择路径、进行中转。 服务端接收到了多个TCP报文。 服务端把接收到的TCP报文合并了http报文。读取到了信息。 服务端接受信息并返回资源给客户端，过程跟上面步骤一致。 http超文本传输协议）是一个基于请求与响应模式的、无状态的、应用层的协议，常基于TCP的连接方式，HTTP1.1版本中给出一种持续连接的机制，绝大多数的Web开发，都是构建在HTTP协议之上的Web应用。 HTTP URL (URL是一种特殊类型的URI，包含了用于查找某个资源的足够的信息)的格式如下：http://host[&quot;:&quot;port][abs_path]http表示要通过HTTP协议来定位网络资源；host表示合法的Internet主机域名或者IP地址；port指定一个端口号，为空则使用缺省端口80；abs_path指定请求资源的URI；如果URL中没有给出abs_path，那么当它作为请求URI时，必须以“/”的形式给出，通常这个工作浏览器自动帮我们完成。eg:​ 输入：www.baidu.edu.cn​ 浏览器自动转换成：http://www.baidu.edu.cn/ HTTP协议–请求 http请求由三部分组成，分别是：请求行、消息报头、请求正文 请求方法（所有方法全为大写）有多种，各个方法的解释如下： GET 请求获取Request-URI所标识的资源 POST 在Request-URI所标识的资源后附加新的数据 HEAD 请求获取由Request-URI所标识的资源的响应消息 报头 PUT 请求服务器存储一个资源，并用Request-URI作为其标识 DELETE 请求服务器删除Request-URI所标识的资源 TRACE 请求服务器回送收到的请求信息，主要用于测试或诊断 CONNECT 保留将来使用 OPTIONS 请求查询服务器的性能，或者查询与资源相关的选项和需求​ HTTP协议–响应 在接收和解释请求消息后，服务器返回一个HTTP响应消息。 HTTP响应也是由三个部分组成，分别是：状态行、消息报头、响应正文 状态代码有三位数字组成，第一个数字定义了响应的类别，且有五种可能取值： 1xx：指示信息–表示请求已接收，继续处理 2xx：成功–表示请求已被成功接收、理解、接受 3xx：重定向–要完成请求必须进行更进一步的操作 4xx：客户端错误–请求有语法错误或请求无法实现 5xx：服务器端错误–服务器未能实现合法的请求常见状态代码、状态描述、说明： 200 OK //客户端请求成功 400 Bad Request //客户端请求有语法错误，不能被服务器所理解 401 Unauthorized //请求未经授权，这个状态代码必须和WWW-Authenticate报头域一起使用 403 Forbidden //服务器收到请求，但是拒绝提供服务 404 Not Found //请求资源不存在，eg：输入了错误的URL 500 Internal Server Error //服务器发生不可预期的错误 503 Server Unavailable //服务器当前不能处理客户端的请求，一段时间后可能恢复正常 ​ IP地址Internet网络中所有计算机均称为主机，ip地址由网络号和主机表示组成，目前使用的ipv4协议规定ip地址的长度为32位。一般以4个字节表示，每个字节用十进制表示，所以每个字节的取值是0-255，并且每个字节数之间用.割开，这种记录方法称为“点-分”十进制记号法。网络地址可分为五类 A类：分配给主要的服务提供商。IP地址的前八位二进制数代表网络类型 取值范围是0-127 B类：分配给拥有大型网络的机构。。。。。16。。。。。。。。。。。。。。。。128-191 C类：。。。。。。。。小型网络。。。。。24。。。。。。。。。。。。。。。。192-223 D类：为多路广播保留。取值224-239 E类：实验性地址，保留未用240-247 IP地址结构：网络类型+网络号+主机ID特殊IP：127.0.0.1 localhost本地主机 自己的电脑0.0.0.0 不是ip 请求这个地址代表所有请求被丢弃由于计算机的发展ipv4能表示的ip地址越来越紧张 且网络号即将用尽。所以产生了ipv6协议ipv6使用128位地址。支持的地址数是足够用的。 子网掩码子网掩码(subnet mask)：又叫网络掩码、地址掩码、子网络遮罩，它是一种用来指明一个IP地址的哪些位标识的是主机所在的子网，以及哪些位标识的是主机的位掩码。子网掩码不能单独存在，它必须结合IP地址一起使用。子网掩码只有一个作用，就是将某个IP地址划分成网络地址和主机地址两部分。子网掩码是一个32位地址，用于屏蔽IP地址的一部分以区别网络标识和主机标识，并说明该IP地址是在局域网上，还是在远程网上。子网掩码的设定必须遵循一定的规则。与二进制IP地址相同，子网掩码由1和0组成，且1和0分别连续。子网掩码的长度也是32位，左边是网络位，用二进制数字“1”表示，1的数目等于网络位的长度；右边是主机位，用二进制数字“0”表示，0的数目等于主机位的长度。这样做的目的是为了让掩码与ip地址做按位与运算时用0遮住原主机数，而不改变原网络段数字，而且很容易通过0的位数确定子网的主机数（2的主机位数次方-2，因为主机号全为1时表示该网络广播地址，全为0时表示该网络的网络号，这是两个特殊地址）。只有通过子网掩码，才能表明一台主机所在的子网与其他子网的关系，使网络正常工作。 网关网关(Gateway)：又称网间连接器、协议转换器。网关在网络层以上实现网络互连，是最复杂的网络互连设备，仅用于两个高层协议不同的网络互连。网关既可以用于广域网互连，也可以用于局域网互连。 网关是一种充当转换重任的计算机系统或设备。使用在不同的通信协议、数据格式或语言，甚至体系结构完全不同的两种系统之间，网关是一个翻译器。与网桥只是简单地传达信息不同，网关对收到的信息要重新打包，以适应目的系统的需求。同层–应用层。 DHCPDHCP协议：路由器自动为局域网下的客户端分配局域网ip。好处是比较方便不用手动设置ip。 DNS域名解析协议 将域名转化为ip地址 原创文章，转载请注明]]></content>
      <categories>
        <category>爬虫</category>
      </categories>
      <tags>
        <tag>HTTP</tag>
        <tag>TCP/IP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[日志2018.10.23]]></title>
    <url>%2F2018%2F10%2F23%2F%E6%97%A5%E5%BF%972018-10-23%2F</url>
    <content type="text"><![CDATA[问题： 上午在使用requests.Session()获取登录后的知乎首页时遇到了问题，知乎首页不知道用了什么编码，获取到数据后使用UTF-8/GBK都无法正常解码，都是一堆乱码。现在这个问题还没有解决，手足无措了。 下午学习scrapy框架时也遇到了很多问题，安装和运行都很麻烦，我打算在学习完这个框架之后再来总结。 收获： 在爬取知乎首页时，学习到了decode()的第二个参数，ignore 在获取到网页的数据后，有一些特殊字符导致不能使用decode解码 在这里我直接加上了ignore参数忽略了不能解码的特殊字符 scrapy: scrapy的安装是真的麻烦： 首先要安装Visual C++ Build Tools，因为接下来要安装的两个文件的底层是基于C语言开发的，所以需要C语言的编译环境 下载地址有可能会提示下载.NET Framework下载地址 安装pywin32,下载地址下载.whl文件后使用pip install 文件名(包含后缀) 安装Twisted,下载地址安装方法同上 然后就是pip install scrapy了 使用： 创建工程命令scrapy startproject 名称 cd 名称 scrapy genspider 爬虫名 要爬的网址 eg:scrapy genspider explam baidu.com 修改settings文件，修改ROBOTSTXT_OBEY=False python执行SCRAPY SHELL 提示DEF WRITE(SELF, DATA, ASYNC=FALSE)出错的问题解决： 只需要把python里面manhole.py文本的所有的async替换成其他名字就行，修改python\Lib\site-packages\twisted\conch\manhole.py文件 把这里的所有async改个名字就行了]]></content>
      <categories>
        <category>日志</category>
      </categories>
      <tags>
        <tag>日志</tag>
        <tag>学习</tag>
        <tag>Scrapy</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用Fiddler对手机APP抓包]]></title>
    <url>%2F2018%2F10%2F23%2F%E4%BD%BF%E7%94%A8Fiddler%E5%AF%B9%E6%89%8B%E6%9C%BAAPP%E6%8A%93%E5%8C%85%2F</url>
    <content type="text"><![CDATA[介绍Fiddler是一款抓包工具，具有很强大的功能，使用Fiddler不仅可以轻松抓取电脑端的数据包，还可以抓取手机、ipad的数据包。 使用在Fiddler官网下载并安装Fiddler，安装后打开界面如下： 因为fiddler抓包的原理就是通过代理，所以被测终端需要和安装fiddler的电脑在同一个局域网中。 开启Fiddler的远程连接，Fiddler 主菜单 Tools -&gt; Fiddler Options…-&gt; Connections页签，选中Allowremote computers to connect，并记住端口号为8888，等会设置手机代理时需要。设置好后重启fiddler保证设置生效。设置如下： 接下来要做的就是手机端的设置啦： 手机和电脑必须在同一个局域网内，然后打开wifi，进行以下设置： 代理服务器主机名就是电脑ip，端口就是Fiddler监听端口8888 然后在手机上点击任意app就可以看到有请求在Fiddler上面流动了 Fiddler的强大不止于此，Fiddler还能做很多事情，目前还在学习中。 原创文章，转载请注明出处！]]></content>
      <categories>
        <category>爬虫</category>
      </categories>
      <tags>
        <tag>爬虫</tag>
        <tag>Fiddler</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[学习记录2018.10.22]]></title>
    <url>%2F2018%2F10%2F22%2F%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%952018-10-22%2F</url>
    <content type="text"><![CDATA[随便写写现在已经晚上了，目前为止今天还没有学习新知识。不知道为什么，每次放完假回来就得一天时间来调整学习状态，说到底还是懒。。。 上个周末，英雄联盟s8全球总决赛已经来到了1/4决赛。对于我这个loler来说自然很关注，甚至周六上自习的时候都在偷偷看比赛直播。我玩英雄联盟差不多四年了，s4开始，现在已经s8了。我对这个游戏真是又爱又恨，恨的是自己在这个游戏上面投入了太多时间，说网瘾少年真的一点都不为过，但这个游戏也带给了我很多快乐，对于我们这样一群人来说，娱乐就是几朋友一块开黑玩几把，互相嘴臭。这届世界赛频频爆冷，世界第一赛区，从s3开始统治英雄联盟的最强赛区LCK竟然全部倒在了8强，而我们LPL也仅剩1支开始不被多数人看好的IG挺进了4强。分析这届总决赛，不难发现，传统的打法已经不适应版本了，而LCK，LPL的大多数队伍都还在固步自封，不肯接受新的东西，这才导致了这么多冷门的爆出。最令我失望的就是RNG了，这个从春天开始包揽所有冠军的队伍，竟然倒在了8强。当然我也不是喷子，我也不想喷RNG的表现有多糟糕，也没有心思去贴吧微博骂人。虽然这只是个在外人看来玩物丧志的游戏比赛，但是我从中也明白了很多。骄兵必败，这句话用来形容RNG在合适不过了，这支RNG今年拿了太多冠军，广告代言接到手软。就在S赛期间，UZI又拿到了NIKE的代言 这个英雄联盟的ADC选手越来越商业化了。RNG在今年也拿到了很多大牌赞助，奔驰，惠普，谷粒多，这或许也为今年的总决赛惨败埋下了伏笔。全员膨胀，自认为对手G2与自己实力天差地别，人家实力确实跟你有差距，但没有这么离谱吧，把把把对面不当人，从教练到选手。结果就是送给观众一场屎一样的BO5，也已RNG的惨败结束。RNG不是没有实力赢下G2，赛前大部分人（包括解说）都预测3:0带走对面的，结果队员无限膨胀，不认真对待比赛，以惨败收场。总结下来就是RNG输给了骄傲，输给了自己的态度。现在想想8强抽签时候的那副嘴脸真是充满了讽刺。 我突然想到了易大师说的话： 不要被骄傲遮蔽了双眼 真正的大师永远都怀着一颗学徒的心 其实关于这个比赛还有很多事情能给我们带来很多启示。 等等，我这个题目不是学习记录吗，怎么扯到游戏上了，我佛了。关于游戏，要是让我放开了讲，我能给你说一天一夜，我就不多BB了，毕竟学习现在才是我该干的事情。 记录下学习中遇到的问题吧今天我好像真的没有看一点新知识。那就记录下上周六写爬虫吧，上周六闲来无事，写了个小爬虫。在写这个爬虫的时候也是遇到了很多问题值得我记录下。首先，关于一个请求返回的数据，有些异步请求返回的是json数据，就像腾讯视频的视频评论就是json数据，这里就需要用到json解析数据才能作为Python的字典使用了，开始我一直想用正则表达式把这个jaon提取出来，因为在json数据之前还包含了一串没用的字符串导致这个数据不能直接使用json.loads()解析，正则表达式试了半天，就是无法剔除那个无关信息，还包括括号，正则表达式对于现在的我来说确实有点困难。不得已向前辈请教，他一语道破天机“为什么不试试字符串切片呢？”对啊，这个问题用个简单的切片就完事了，我还在苦苦寻求正则表达式，这也启示了我解决问题的方式。明明有简单的方法，怎么没想到呢；下次再遇到类似的问题先想想除了第一个想到的解决方法之外还有没有其他的方法。 还有就是我在把数据写进数据库的时候，提示错误，key不能包含 . 我又无奈了，还是去请教，大佬说replace可以吧 . 替换成其他字符，我一想replace不是字符串的方法吗，于是马上提出疑问，结果大佬一句话让我哑口无言，key不就是字符串吗？ 是啊，我咋又没想到呢？= =真的是醉了。希望自己吃一堑，长一智，能够记住这些问题吧。]]></content>
      <categories>
        <category>日志</category>
      </categories>
      <tags>
        <tag>学习</tag>
        <tag>生活</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用Seleniun获取A_JAX数据]]></title>
    <url>%2F2018%2F10%2F19%2Fa-jax%E8%8E%B7%E5%8F%96%E6%95%B0%E6%8D%AE%E7%9A%84%E5%8F%A6%E4%B8%80%E7%A7%8D%E6%96%B9%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[前言有一些网站在发起AJAX请求的时候，会带上特殊的字符串用于身份验证。这种字符串称为Token。比如说会带上时间戳，时间戳精确到毫秒。还会跟另一个属性存在某种一一对应的关系，虽然这种对应关系的算法会写在网站的某一个JavaScript文件中，但是要想读懂这种关系需要深厚的JavaScript功底。如果一个网站只需要爬一次，或者对爬取速度没有什么要求，那么可以通过另一种方式来解决这种问题。本文就来介绍这种方法是如何实现的! SeleniumSelenium介绍虽然网页的源代码中无法看到被异步加载的内容，但是Chrome浏览器开发者工具的’Elements’选项卡下却可以看到网页上的内容。这就说明Chrom开发者工具Elements选项卡里的HTML代码和网页源代码中的HTML代码是不一样的。在开发者工具中，此时显示的内容是已经加载完成的内容。如果能够获得这个被加载的内容，那么就能绕过手动构造Token的过程，可以直接使用XPath或者正则来获得想要的内容。这种情况下，就需要使用Selenium操作浏览器来解析JavaScript，在爬取被解析以后的代码。Selenium是一个网页自动化测试工具，可以通过代码来操作网页上的各个元素。Selenium是Python中的第三方库，可以实现用Python来操作网页。 安装pip install selenium下载ChromDriver，根据自己的系统选择合适的版本：下载下来的是一个zip文件，解压完成后得到一个exe文件接下来就是使用了 使用将上面解压得到的chromedriver.exe与代码放在同一个文件夹中以方便代码直接调用。初始化Selenium，导入selenium库，在指定WebDriver如果chromedriver与代码不在同一个文件夹中可以通过绝对路径来指定，需要注意的是在Windows中路径的分隔符’\’和Python中的转义字符’\’冲突，所以在指明绝对路径的时候可以在路径字符串左引号的左边加一个‘r’符号：1driver = webdriver.Chrome(r&apos;D:\user\asd\chromedriver&apos;) 这样Python就能正确处理反斜杠的问题。初始化完成以后下面第7行的代码就是使用selenium打开网页啦。代码运行以后会自动打开一个chrome浏览器窗口，并自动打开这个网址对应的页面。一旦被异步加载的内容出现在了这个窗口中，那么这是使用：1html = driver.page_source 就能得到在开发者工具中出现的HTML代码。如下图所示：上图中标明的第6行代码设置了一个5s的延迟，这是由于selenium并不会等待网页加载完成在执行后面的代码。它是向ChromeDriver发送了一个命令，让ChromeDriver打开某个网页。至于网页需要多久打开，多久才能完成异步加载，这些selenium并不管，所以才需要设置一个延迟等待异步加载完成之后再抓取网页信息。这样手动设置延迟的方式很浪费时间资源，并且如果在指定的延迟时间内网页还没有加载出来，那么就获取不到网页信息了。怎么让selenium智能化呢？请看以下代码1234567891011121314from selenium import webdriverfrom selenium.webdriver.support.ui import WebDriverWaitfrom selenium.webdriver.common.by import Byfrom selenium.webdriver.support import expected_conditions as ECdriver = webdriver.Chrome(&apos;./chromedriver&apos;)driver.get(&apos;http://exercise.kingname.info/exercise_advanced_ajax.html&apos;)try: WebDriverWait(driver, 30).until(EC.text_to_be_present_in_element((By.CLASS_NAME, &quot;content&quot;), &apos;通关&apos;))except: print(&apos;网页加载太慢&apos;)element = driver.find_element_by_xpath(&apos;//div[@class=&quot;content&quot;]&apos;)print(element.text) WebDriverWait(driver, 30).until(EC.text_to_be_present_in_element((By.CLASS_NAME, “content”), ‘通关’))WebDriverWait会阻塞程序的运行，30表示最多等待30s。在这30秒内，每0.5秒检查一次网页，直到expected_conditions（EC）期待条件，这个条件就是text_to_be_present_in_element((By.CLASS_NAME, “content”)，（注释：class为content的元素里面的文本中包含了通关两个子）出现。所以这行代码的完整意思就是等待网页加载，直到class为countent的元素里面包含了”通关”两个汉字。By除了指定class之外，还可以指定很多其他的属性，例如： By.ID By.NAME 当然，也可以使用XPth:1EC.present_of_element_located((By.XPATH,&apos;//div[@class=&quot;content&quot;])) 需要注意的是：”present_of_element_located”的参数是一个元组，元组第0项为By.XX，第1项为具体内容，”text_to_be_present_in_element”的参数有两个第一个参数为一个元组，元组第0项为By.XX，第1项为具体内容；第二个参数为部分或全部文本，又或者是一段正则表达式。 获取元素在网页中寻找需要的内容，可以使用XPath12element = driver.find_element_by_xpath(&apos;//div[@class=&quot;content&quot;]&apos;)print(element.text) driver.find_element_by_xpath如果有多个符合条件的返回第一个driver.find_elements_by_xpath以列表形式返回所有的符合条件的element推荐使用driver.find_elements_by_xpath因为driver.find_element_by_xpath返回的是一个Element对象，如果没有符合条件的元素，就会报错，而driver.find_elements_by_xpath返回的是一个Element对象列表，就算没有符合条件的元素也会返回一个空列表，不会报错。因为driver.find_element_by_xpath返回的是一个Element对象,通过它的.text属性才能获取到文本信息，当使用driver.find_elements_by_xpath得到了一个Element对象列表时，可以通过for循环展开这个列表然后在通过.text属性来获取到文本信息。一定要注意，不能直接在XPath的末尾加上text()，会报错。 原创文章，转载注明出处]]></content>
      <categories>
        <category>爬虫</category>
      </categories>
      <tags>
        <tag>爬虫</tag>
        <tag>学习</tag>
        <tag>a_jax</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[test]]></title>
    <url>%2F2018%2F10%2F19%2Ftest%2F</url>
    <content type="text"><![CDATA[test]]></content>
      <categories>
        <category>私密博客</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[hexo文章加密]]></title>
    <url>%2F2018%2F10%2F19%2Fhexo%E6%96%87%E7%AB%A0%E5%8A%A0%E5%AF%86%2F</url>
    <content type="text"><![CDATA[hexo文章简单加密访问方法来源于简书这里只介绍怎么实现，具体原理访问上面链接 实现找到themes-&gt;next-&gt;layout-&gt;_partials-&gt;head.swig文件。按道理是添加在任何地方都行，但是推荐加在所有的标签之后，个人建议，仅做参考。以下是原作者加的代码：12345678910&lt;script&gt; (function()&#123; if(&apos;&#123;&#123; page.password &#125;&#125;&apos;)&#123; if (prompt(&apos;请输入文章密码&apos;) !== &apos;&#123;&#123; page.password &#125;&#125;&apos;)&#123; alert(&apos;密码错误！&apos;); history.back(); &#125; &#125; &#125;)();&lt;/script&gt; 再写新博客的时候在顶部加上新属性如下图所示：description是描述password后就是自定义的密码了具体效果如下图所示： 原创文章，转载请注明出处！]]></content>
      <categories>
        <category>HEXO</category>
      </categories>
      <tags>
        <tag>hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python基础复习]]></title>
    <url>%2F2018%2F10%2F19%2Fpython%E5%9F%BA%E7%A1%80%E5%A4%8D%E4%B9%A0%2F</url>
    <content type="text"><![CDATA[基础复习基础类型控制语句基础类型： 整数型 int 浮点数 float 字符串 str 布尔值 True、Flase 空值 None 变量 变量在计算机中不仅可以是数字，还可以是任意数据类型，变量在称剧中就是用一个变量名表示 字符串详解===转义字符:因为一些特殊字符是python中的关键字或一些特殊的概念如换行。所以以特殊字符 \ 开头，构造转义字符。常见的转义字符：\n 换行 \t 制表符\’ 单引号 \” 双引号\ 反斜杠 遍历：for i in ‘abc’:​ print(i)‘a’,’b’,’c’ 下标访问：‘hello’[4]→o 搜索：(了解)’字符串’.count(子字符串) 搜索子串出现次数‘xyaxyaXY’.count(‘xy’)→ 2‘xyaxyaXY’.count(‘xy’, 2)(了解)判断字符串是否以某个字母开头→ 1‘abcd’.startswith(‘a’)→ True‘abcd’.endswith(‘d’)→ True 字符串.find(子串) 找到返回下标，未找到返回-1‘axyaXY’.find(‘xy’)→ 1‘aaXY’.find(‘xy’)→ -1index()方法与find()类似，区别是未找到的时候报错。 替换 ：字符串.replace(老子串，新字符串)‘aaXY’.replace(‘aa’, ‘bb’)‘bbXY’分隔：(了解)partition把一个字符串切成几块并返回，包含子串。‘xyaxyaXY’.partition(‘xy’)(‘’, ‘xy’, ‘axyaXY’) 字符串.split(子串)，根据子串分成几部分并返回列表，不包含子串。‘xyaxyaXY’.split(‘x’)[‘’, ‘ya’, ‘yaXY’] 连接：join()用一个字符串连接可迭代对象的各个项。‘-‘.join([‘小明’, ‘hong’, ‘li’])→ ‘小明-hong-li’ 删除：字符串.strip(要删除的子串)‘今天天气真好\n’.strip(‘\n’)→ ‘今天天气真好’ 大小写转换：‘aa AA’.lower()→ ‘aa aa’‘aa AA’.upper()→ ‘AA AA’‘hello world’.capitalize()→ ‘Hello world‘aa AA’.swapcase()→ ‘AA aa’ isxxx判断:判断是否字母‘a’.isalpha()→ True判断是否空格‘ ‘.isspace()→ True判断是否数字‘1’.isdigit()→ True判断是否合法的变量名‘a4’.isidentifier()→ True 填充：对齐的时候会用到‘’.center(填充后的字符串总长度，要填充的字符串)‘abc’.center(5, ‘_’)→ ‘abc‘右侧填充‘abc’.ljust(10, ‘_’)→ ‘abc_______’左侧填充‘abc’.rjust(10, ‘_’)→ ‘___abc’ （以上了解end） 判断变量类型 type()函数 判断变量类型 isinstance(值， 类型) 如果值属于类型的话返回True 数据类型转换 int(x) 将x转换为一个整数 long(x) 将x转换为一个长整数 float(x ) 将x转换到一个浮点数 complex(real) 创建一个复数 str(x ) 将对象 x 转换为字符串 repr(x ) 将对象 x 转换为表达式字符串 eval(str ) 用来计算在字符串中的有效Python表达式,并返回一个对象 tuple(s ) 将序列 s 转换为一个元组 list(s ) 将序列 s 转换为一个列表 chr(x ) 将一个整数转换为一个字符 unichr(x ) 将一个整数转换为Unicode字符 ord(x ) 将一个字符转换为它的整数值 hex(x ) 将一个整数转换为一个十六进制字符串 oct(x ) 将一个整数转换为一个八进制字符串 控制语句：if else语句12345678if 条件a: 执行1elif 条件b: 执行2elif 条件c: 执行3else： 执行4 循环for循环：123打印三次字符串for i in range(1,4): print(&apos;你好 我是你爸&apos;) while 循环1234567891011121314151617181920i = 1while i&lt;4: print(&apos;你好 我是你爸&apos;) i+=1#循环中也可以加入条件控制语句i = 0while i &lt;10: i = i+1 if i %2 == 0: continue#当i是偶数时跳过此次循环 print(i)#break语句：用来结束循环i = 0while i &lt;10: i = i+1 print(i) if i == 6: break 字典列表元组列表list：定义：原来的单值变量无法满足业务需求，需求一个”容器“来装内容列表存储一些列有序（有下标）数据。容器内可以保存整数、布尔、字符串、或其他容器语法：创建一个列表：list1 = [1,’a’]还可以通过类 内置关键字创建 list1 = list() 添加项： append()方法，添加新项到列表的末尾list.append(要添加的数据) insert()方法，可以根据索引值插入制定数据。list.insert(索引，要添加的数据) for 循环 +append,批量添加项。list1 = [1,2,3,4]for i in range(5, 8): list1.append(i)print(list1) 两个列表拼接，用加号list1 = [1,2,3]list2 = [4,5,6]list3 = list1 + list2 删除项： pop()list.pop(索引)，根据索引删除列表中的某一个元素，返回删除成功的元素。pop()不传索引参数的时候，默认删除列表最后一项。pop()函数相当于append和insert函数的逆运算。 remove()list.remove(想要删除的项目值) 根据项item的值value来删除 clear()清空列表lisr.clear() 清空所有项目，返回空列表。 del删除列表对象，根据索引删除元素list = [1,2,3,4]del list[0]表示删除的是1 访问查询：通过索引（下标）list[0] 修改：修改基于索引的。访问列表下标，然后等号赋值。list [索引] = 新值 遍历：列表是一个可迭代对象，通过for循环可以吧一个列表中的元素依次取出如果判断一个对象是可迭代对象：通过collections模块的Itearable类型来判断。from collections import Iterableisinstance(‘abc’,Iterable)#判断字符串abc是否可以迭代True#返回true代表可以迭代list = [1,2,3,4]for i in list:​ print(i)#循环遍历出列表所有元素。 切片：列表[索引开始：索引结束：步进]切割截取出来区间。切片参数为负数是，截取方向向右为正，步进为正式才能截取。步进与截取方向相反时，结果为空索引0可以省略list[0:2] 等同于 list[:2]反向reverse输出列表list[::-1] &gt;&gt;&gt; [5, 4, 3, 2, 1] 列表生成式（不常用）12345678list1 = []for i in range(1,5) list1.append(i)#同样是在列表中加入1,2,3,4也可以用列表生成式写：[i for i in range(1,5)]#列表生成式也可以加入条件判断[i for i in range(1,10) if i%2==0]输出偶数 字典字典也是一种容器，特点：键值对存储没有索引，是无序的。靠键来增删改查 创建： 内置类实例化创建dict1 = dict() 大括号，内容空dict1 = {} 创建时附初始值dict1 = {‘name’: ‘小明’, ‘age’: 13, ‘sex’: ‘male’} 查询： （常用）dict1[键key]dict1 = {‘name’: ‘小明’, ‘age’: 13, ‘sex’: ‘male’}dict1[‘name’] &gt;&gt; ‘小明’如果键不存在的话，报 KeyError错误。dict1[‘aaa’] &gt;&gt;&gt; KeyError:aaa get(键, 默认值)跟dict[键]非常相似，只不过多了个默认值。当键不存在的时候会报Nonedict1.get(‘name’) &gt;&gt;&gt; ‘小明’dict1.get(‘aaa’, None) &gt;&gt;&gt; None 添加：dict[新建] = 新值 修改：dict[键] = 新值 遍历：先dict.items() 转换为 大列表套小列表项的形式。再用 for 循环遍历出来。for k,v in 字典.items():​ print(k, v)dict.keys()吧字典中的key取出来dict.values()把字典中的value取出来 删除： 键访问，值设置为None, 键还在字典[键] = Nonedict1 = {‘name’: ‘小明’, ‘age’: 13, ‘sex’: ‘male’}dict1[‘name’] = Nonedict1[‘name’] &gt;&gt;&gt; None （常用）字典.pop(键) 根据键删除，返回删除成功的值，会把键和值都删除dict1 = {‘name’: ‘小明’, ‘age’: 13, ‘sex’: ‘male’}dict1.pop(‘name’) &gt;&gt;&gt; ‘小明’dict1 &gt;&gt;&gt; {‘age’: 13, ‘sex’: ‘male’} del 字典[键]， del关键字删除，没有返回值，会把键和值都删除 字典.clear() 删除所有内容dict1.clear()dict1 &lt;&lt;&lt; {} 其他的常用方法：dict.items() 返回一个列表，每一项是 键值对dict.keys() 返回一个列表，每一项是字典里的 键dict.values() 返回一个列表，每一项是字典里的 值dict.contains(key) 键存在的话返回True，不存在返回False 元组元组跟list非常相似，特点和区别是 “不可修改”。所以元组需要在创建的时候就指定数据。语法是小括号括起来，逗号分隔每一项 创建:tuple2 = tuple((10, 20, ‘张三’))（常用）tuple1 = (10, 20, ‘张三’)场景:元组由于不可变，适合定义 常量、配置、不需要改变的值。这样在复杂代码中就不用害怕因为bug误修改值。例如定义 中国的所有省份，一个注册登录表单中的下拉框选项 查询:有索引，通过下标访问tuple[index]tuple2 = (‘河南’, ‘云南’)tuple2[0] &gt;&gt;&gt; ‘河南’ 也支持切片:tuple2[0:1] &gt;&gt;&gt; (‘河南’,) 注意的一个地方元组有时只有一项的时候，后面仍有一个逗号。原创文章，转载请注明出处！]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[分享一种在markdown中插入图片的新方法]]></title>
    <url>%2F2018%2F10%2F18%2F%E5%88%86%E4%BA%AB%E4%B8%80%E7%A7%8D%E5%9C%A8markdown%E4%B8%AD%E6%8F%92%E5%85%A5%E5%9B%BE%E7%89%87%E7%9A%84%E6%96%B0%E6%96%B9%E6%B3%95%2F</url>
    <content type="text"><![CDATA[前言我在前面的hexo使用笔记中介绍过怎么插入图片，前面那种方法虽然能用，但还是有点麻烦，每次插入图片都要写一段markdown代码。每次创建新博客的时候都会新建一个md文件和一个文件夹，不仅麻烦而且还让博客文件夹变得不简洁。下面我介绍一种新的方法，既不用创建新的存放图片的文件夹，而且还自动生成markdown语法代码，再插入图片的时候直接ctrl+v就完事了，看起来是不是很方便呢？ 介绍下面进入正文，这种酷炫的新方法来自于大佬的git链接MarkdownPicPicker 是一个Markdown写作辅助工具。它能将剪贴板中的图片上传到网络图床中，并将markdown格式的图片链接(![]（&lt;图片地址&gt;))复制到剪贴板中。项目的readme中指明了安装使用方法下载链接下载完成后并解压，解压完成后得到一个MarkdownPicPicker.exe可执行文件和一个pic文件夹。 使用截图之后，比如我使用qq的快捷键截图（截图后点完成，不用保存），然后运行一下MarkdownPicPicker.exe，在你的编辑器中按下ctrl+v,神奇的事情就发生了，你会直接得到一段markdown插入图片的代码。是不是比上次的方法方便多了。如果你只想复制链接，不想让他变成这种形式，那么，你可以在命令行中输入markdownpicpicker.exe -linkonly （当前目录下按住shift点击右键选择在此处打开命令行窗口） 优化如果你觉得上面的方法还不够方便？是不是每次还要用鼠标来运行exe文件觉得很麻烦？没关系，还有一种方法可以优化这些步骤。官方文档说使用AutoHotKey来启动程序可以吧整个流程缩短到两秒钟 AutoHotkeyAutoHotKey是什么东西？我其实也是第一次听说这个什么软件，完全一脸懵比，上网上查了下才知道是干什么用的，在官网上下载之后然后运行出来发现是一份英文帮助文档，我也看不懂说的是什么。后面才知道这是个脚本程序，可以自定义快捷键来执行某个程序或某种命令。 ## 怎么使用呢？新建一个文本本件，名字随便起，然后把后缀名改为.ahk然后编辑这个文件输入以下代码： 1234#b::Run, D:\git第三方包和软件\MarkdownPicPicker_v1.0.0\markdownpicpicker.exeReturn!b::Run, D:\git第三方包和软件\MarkdownPicPicker_v1.0.0\markdownpicpicker.exe -linkonlyReturn 在鼠标右键点击run script即可运行。这里定义了两个快捷键，第一行代码表示按下键盘win+b键执行markdownpicpicker.exe第三行表示按下alt+b执行markdownpicpicker.exe -linkonly这和在命令行中的执行文件是一样的。关于autohotkey还有很多作用，请自行baidu,google。 原创文章，转载请注明出处！]]></content>
      <categories>
        <category>HEXO</category>
      </categories>
      <tags>
        <tag>markdown</tag>
        <tag>图片</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python与MongoDB]]></title>
    <url>%2F2018%2F10%2F18%2Fpython%E4%B8%8EMongoDB-1%2F</url>
    <content type="text"><![CDATA[MongoDB介绍：MongoDB是一款基于c++开发的开源文档数据库，数据在MongoDB中以Key-Value的形式存储，就像是python的字典一样。使用MongoDB的管理软件Robo3T可以实现数据库的可视化。 安装：首先下载并解压MongoDB:访问官网，从官网上下载：官网下载选择适合自己的版本和操作系统然后Download就可以了解压后把Bin下的文件辅助到新的文件夹（在c盘或者d盘创建MongoDB文件夹）并创建存储数据库的文件夹Data和日志文件夹Log并创建mongod.conf，操作完成后文件目录如下图所示：接下来就是编辑mongod.conf了使用notepad++或其他除了编辑器(除了记事本，因为YAML对格式要求很严格，使用记事本会出现错乱)打开mongod.conf然后将以下代码复制进去： 12345678910systemLog: destination: file path: D:\MongoDB\Log\mongo.log logAppend: truestorage: dbPath: D:\MongoDB\Datanet: bindIp: 127.0.0.1security: authorization: disabled 这里的path和dbpath根据设置成自己的路径，比如我的Log和Data是放在D盘MongoDB文件夹下的。然后在安装目录下启动命令行，输入： 1mongod.exe --config mongod.conf 即可启动Mongodb 将MongoDB安装为windows服务在安装目录下打开cmd，输入以下命令 mongod.exe --config &quot;D:\MongoDB\mongod.conf&quot; --install 这里的D:\MongoDB\mongod.conf换成自己的mongod.conf路径 这个界面就代表安装服务成功了，然后在计算机管理→服务里面找到MongoDB开启服务，mongodb会作为计算机服务一直运行，不用再输入命令手动启动服务啦！！ Robo 3T介绍Robo 3T是一个快平台的MongoDB管理工具，可以在图形界面中查询或者修改MongoDB 下载和安装访问官网下载robo3t选择Download robo3t等待安装完成后打开 使用单机create链接(如下图),如果monggodb在本地计算机上面运行，只需要在Name这一栏填一个名字就可(也可以不填使用默认名字)，单击save即可然后点击connect就可以连接MongoDB了可以看到，数据在MongoDB中是按照库(Database)——集合——文档的层级关系来存储的。文档就像是python中的一个字典，集合相当于一个包含了很多字典的列表；库相当于一个大字典，大字典里面的每一个键值对都对应了一个集合，key为集合的名字，Value就是一个集合。 PyMongo安装1pip install pymongo pymongo的使用使用pymongo初始化数据库连接12345from pymongo import MongoClientclient = MongoClient()database = client[&apos;库名&apos;]#创建一个库collection = database[&apos;集合名&apos;]#创建一个集合#这里的库名和集合名除了可以是字符串还可以是一个变量，当库名或者集合名是一个变量的时候，可以通过循环来批量操作数据库，比如要创建多个集合的时候，可以吧集合名先保存到一个列表中，然后通过循环穿件多个集合。 插入数据插入操作用到的方法为insert(参数)参数就是python的字典。 123456789101112131415from pymongo import MongoClientclient = MongoClient()database = client[&apos;Chapter6&apos;]collection = database[&apos;spider&apos;]data = &#123;&apos;id&apos;: 2, &apos;name&apos;: &apos;张三&apos;, &apos;age&apos;: 20, &apos;salary&apos;: 9999&#125;collection.insert(data)#插入一条数据#当然也可以一次插入多条数据，先把多条数据保存到一个列表中，然后直接使用insert()即可more_data = [ &#123;&apos;id&apos;: 3, &apos;name&apos;: &apos;张四&apos;, &apos;age&apos;: 20, &apos;salary&apos;: 999&#125;, &#123;&apos;id&apos;: 4, &apos;name&apos;: &apos;张五&apos;, &apos;age&apos;: 20, &apos;salary&apos;: 99&#125;, &#123;&apos;id&apos;: 5, &apos;name&apos;: &apos;张六&apos;, &apos;age&apos;: 20, &apos;salary&apos;: 9&#125;, &#123;&apos;id&apos;: 6, &apos;name&apos;: &apos;张七&apos;, &apos;age&apos;: 20, &apos;salary&apos;: 19999&#125;]collection.insert(more_data) 查找数据查找功能对应的方法是 12find(查询条件，返回字段)#返回所有符合的信息find_one(查询条件，返回字段)#返回一条符合的信息 在不写find方法参数的时候，表示获取指定集合中所有字段。返回字段的参数指定返回内容。这个参数也是一个字典，key就是字段的名称，value是0或1,0表示不返回这个字段，1表示返回这个字段。其中_id这个字段比较特殊，必须人工指定它的值为0，这样才不会返回。而对于其他数据，应该统一使用返回，或者不返回。eg: 1collection.find(&#123;&apos;age&apos;:20&#125;,&#123;&apos;_id&apos;:0&#125;)#查询所有age为20的记录，返回除了_id的所有字段 这里需要知道：find()方法返回的是一个pymongo对象，这个对象可以被for循环展开，展开之后可以得到很多个字典。pymongo也支持逻辑查询：它们对应的关键词如下所示： $gt great than 大于 $lt less than 小于 $gte Greater than equal to 大于等于 $lte less than equal to 小于等于 $eq equal to 等于 $ne not equal to 不等于eg: 12collection.find(&#123;&apos;age&apos;:&#123;&apos;$gt&apos;:19&#125;&#125;)#查询age&gt;19的记录collection.find(&#123;&apos;age&apos;:&#123;&apos;$gte&apos;:19,&apos;$lt&apos;:30&#125;&#125;)#查询19≤age&lt;30的记录 对查询结果进行排序排序的方法为sort(),这个方法一般和find()配合使用他有两个参数，第一个参数指明以那一项进行排序，第二个参数为1或者-1，1表示升序，-1表示降序。eg: 1collection.find(&#123;&apos;age&apos;:&#123;&apos;$gt&apos;:19&#125;&#125;).sort(&apos;age&apos;,-1)#查询所有age大于19并以age按照降序进行排序。 修改修改也有两个方法： 12collection.updata_one(参数1，参数2)#修改一条collection.updata_many(参数1，参数2)#修改多条 参数1和2都是字典形式具体使用如下： 1collection.upadta_many(&#123;&apos;name&apos;:&apos;张三&apos;&#125;,&#123;&apos;$set&apos;:&#123;&apos;age&apos;:30&#125;&#125;)#将姓名为张三的人年龄全部改为30 删除删除也有两个方法 12collection.delete_one(&#123;&apos;name&apos;:&apos;张三&apos;&#125;)#把第一个name是张三的记录删除collection.delete_many(&#123;&apos;name&apos;:&apos;张三&apos;&#125;)#把name是张三的记录全部删除 删除方法只有一个参数，是字典形式。至此,mongodb以及pymongo的使用暂时结束了！ 原创文章，转载请注明出处！]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>MongoDB</tag>
        <tag>数据库</tag>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[一键设置爬虫headers]]></title>
    <url>%2F2018%2F10%2F18%2F%E4%B8%80%E9%94%AE%E8%AE%BE%E7%BD%AE%E7%88%AC%E8%99%ABheaders%2F</url>
    <content type="text"><![CDATA[在写爬虫的时候我们经常需要设置headers属性来让爬虫模拟浏览器从而获得数据。在添加headers属性的时候，需要把浏览器所有的headers属性都写上去：这么长的headers如果复制下来然后手动把它设置成字典的形式太麻烦、太费时间。那么有没有办法一下把这些属性转为字典形式呢？带着这个疑问我向大佬请教：大佬不愧是大佬，分分钟解决我的问题好吧。下面介绍下这个方法：安装（输入以下命令）：pip install –upgrade git+https://github.com/kingname/CrawlerUtility.git使用：首先引入这个包然后把从浏览器复制下来的headers保存成长字符串。在使用ChromeHeaders2Dict解析一下就完事了是不是很简单！推荐：大佬的github 后记：我使用这个包的时候，是第一次使用别人手动写的第三方包，中间也遇到了很多问题。比如一开始我不知道怎么安装，然后在网上搜了一下怎么安装的资料。我这才知道安装第三方包原来有两种方式，我以前还以为只能手动下载安装呢。下面记录下两种安装方式：一、手动安装 在github上面下载包 然后解压该文件 在该文件夹按住shift+鼠标右键 在此处打开命令行窗口，然后输入python setup.py install 二、自动安装直接在命令行输入pip install 包eg:pip install pillow其实在每个github项目下都有README文件在这个文件里都会介绍怎么install，比如上面的这个项目：然后：问题又来了，在上面这些东西都弄好了之后我在pycharm上面引入的时候pycharm报错，对于我这样一个萌新来说瞬间又懵了。于是我又向大佬请教…这才知道pycharm原来还有一个加载时间，果然一小会过后，这个包就能正常使用了。不得不说，这个大佬人真的很好，身为这么大的一个大佬，对于我这个萌新的问题都很耐心的解答，再次表示感谢。这个大佬就是我最近看的一本爬虫书的作者技术过硬人又好！！！推荐去看看这本书，写的真不错，我这种死笨死笨的萌新都看的很明白！ 原创文章，转载请注明出处！]]></content>
      <categories>
        <category>爬虫</category>
      </categories>
      <tags>
        <tag>爬虫</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[hexo使用笔记]]></title>
    <url>%2F2018%2F10%2F17%2Fhexo%E4%BD%BF%E7%94%A8%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[创建新文件在D:/个人博客/BLOG/source/_posts文件夹下执行命令hexo new ‘新文件名字’ 在文本中添加图片 把主页配置文件_config.yml里的post_asset_folder:这个选项设置为true(如过以后不想生成同名的文件夹了改为false即可) 在hexo目录下执行mup install hexo_asset_image –save,这是下载安装上传本地图片的插件。 等待安装完成后，再运行上面创建新文件的命令来生成新md文件时，/source/_posts文件夹中除了xxx.md文件还有一个同名的文件夹。 最后在xxx.md中想引入图片时，先把图片复制到这个文件夹中，然后只需要在xxx.md中按照markdown的格式引入图片：ps:!后面没有空格，hexo使用笔记前可加/也可以不加，图片名字一定不要写错。在页面中添加超链接关于文章推送的问题之前由于不会弄，导致每次推送时都把git上面的CNAME文件弄丢了，每次推送完之后还要重新创建CNAME文件，这样很麻烦。通过查阅资料知道了把CNAME文件放在本地hexo目录下source的_posts文件夹下就可以解决这个问题了。关于云解析首先要有一个域名，我用的是腾讯云域名：www和@主机记录的记录值是自己的githubpage的地址然后本地文件中要有一个CNAME文件，这个文件只有一行：这样就行了 原创文章，转载请注明出处！]]></content>
      <categories>
        <category>HEXO</category>
      </categories>
      <tags>
        <tag>hexo</tag>
        <tag>笔记</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[HELL HEXO]]></title>
    <url>%2F2018%2F10%2F17%2FHELL-HEXO%2F</url>
    <content type="text"><![CDATA[This is my BLOG]]></content>
      <tags>
        <tag>hexo</tag>
        <tag>github</tag>
        <tag>npm</tag>
      </tags>
  </entry>
</search>
